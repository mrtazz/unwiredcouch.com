<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>unwiredcouch.com</title>
  <id>https://unwiredcouch.com/atom.xml</id>
  <updated>2019-11-28T09:38:47Z</updated>
  <subtitle>thoughts which have made it into written existence</subtitle>
  <link href="https://unwiredcouch.com/atom.xml" rel="self"></link>
  <author>
    <name>Daniel Schauenberg</name>
    <email>d@unwiredcouch.com</email>
  </author>
  <entry>
    <title>The Fallacy of needing a technical manager</title>
    <updated>2019-11-19T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2019,2019-11-19:/11/19/technical-manager.html</id>
    <content type="html">&lt;p&gt;One of the things I’ve come across most in my career in technology (and one that still persists) is the belief that as an engineer, your manager (or coach) needs to be fairly technical as well. Or at least it being a huge advantage if they are. And even though this might seem like a logical thing initially, most of the times I’ve seen that being actually the case were edge cases. In most other cases it’s been not particularly helpful or even harmful. As a sidenote, I&#39;m using the term &#34;non-technical manager&#34; here because it&#39;s the common way of talking about the topic. However I think this term makes as much sense as &#34;non-managing engineers&#34;.&lt;/p&gt;&#xA;&lt;p&gt;First let&#39;s get this part out of the way: here are the scenarios where I’ve seen having a technical manager being a big advantage:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;As a very junior engineer without any mentorship setups in place&lt;/li&gt;&#xA;&lt;li&gt;During onboarding where I didn’t have a good lay of the land or relationships to lean on to ask about system overviews yet&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;However these situations are edge cases to me which don’t pose actual problems. A good non-technical manager in this scenario will just make an introduction to an engineer who knows the answers and is willing to mentor a junior engineer or new hire. If there isn’t such an engineer, then there are much bigger problems in an organization than technical vs non-technical managers.&lt;/p&gt;&#xA;&lt;p&gt;And this actually ties into the main point why a technical manager is a silly requirement in my mind: As an engineer you’re already surrounded by a ton of people with deep technical knowledge (i.e. all the other engineers). It’s almost impossible to have a problem or question and there not being someone around to help.&lt;/p&gt;&#xA;&lt;p&gt;However it’s less of a likelihood to have someone around to help you with non-technical problems. How to structure work into plannable pieces, how to give feedback, how to put your work into the larger context, how to improve the team, etc, etc. And these are much less special and unique topics to technology where you need a strong technology background than most people think. In a healthy organization the senior engineers will also be able to help with this to some extent. But they will also need to have learned it from someone. And need to have an avenue to improve their non-technical skills.&lt;/p&gt;&#xA;&lt;p&gt;And as you become more and more senior, being able to excel in these non-technical areas becomes more and more crucial to be an effective engineer. With seniority comes problem solving on a larger scale that needs more breadth in impact and much less depth. Focusing on a specialist skillset of just technology will more and more limit you in being able to do this important kind of work. And at some point the only way to improve is working on your non-technical skills, for which you need a good non-technical manager.&lt;/p&gt;&#xA;&lt;p&gt;This doesn&#39;t mean that technical managers can&#39;t teach you these kind of things or are necessarily bad at it. But in my experience when you have technical managers who are good at it that’s the case despite their technical background and not because of it. It&#39;s way too common that the technical background actually gets in the way. That they consider themselves more as used-to-be-engineers than managers. That they are tying every conversation back to a technical topic and focus on that instead of the reports actual growth. And at worst they try to still write code themselves and debate technical decision making instead of taking a step back and let others grow on those challenges. And don&#39;t get me wrong, I know many great technical managers that don&#39;t do these kind of things and are great at their jobs. But what I value about them is exactly that. They are managers first.&lt;/p&gt;&#xA;&lt;p&gt;Requiring a strong technical skillset of managers is also a huge waste of resources. Given that a manager essentially ends up with two jobs that way, they will struggle to be able to do a good job in at least one of them (more likely in both). They are constantly having to shift focus from the management side of things to try and stay up to date on technical topics that they will never really have hands on experience on anyways. Taking time and energy away from their actual job: managing. And nobody really enjoys having a conversation with a manager who hasn&#39;t written production code in years yet still engages in technical problem solving and decision making conversations late at night because they think they have to also keep their technical chops up to date. While at the same time clouding their view of the higher level context because they get caught up in technology details.&lt;/p&gt;&#xA;&lt;p&gt;And it&#39;s not only about the manager. It already starts at hiring. Requiring technical aptitude from managers means that you waste precious interview time on technical questions that are even less related to what their work will be than any of the ridiculed inverting a binary tree whiteboard exercises every engineer groans about. Instead you could use all that time to talk extensively about management topics. And how they will help grow teams and organizations.&lt;/p&gt;&#xA;&lt;p&gt;At the end of the day management is a lot more removed from the actual day to day practice of writing code than most people think. And the problems to solve and challenges to tackle for managers at technology companies are much less unique to technology than we all like to think. A good manager (regardless of technical background) is able to recognize that and work with engineers to make them better by complementing the skills they already learn every day while doing &lt;em&gt;their&lt;/em&gt; main job.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2019/11/19/technical-manager.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;One of the things I’ve come across most in my career in technology (and one that still persists</summary>
  </entry>
  <entry>
    <title>Pen and Paper</title>
    <updated>2019-07-05T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2019,2019-07-05:/07/05/pen-and-paper.html</id>
    <content type="html">&lt;p&gt;A couple of years ago I went from working in an office to working remote mostly from home. A couple of months in I realized how my productivity had dropped significantly. For years everything I had to do and most of the planning around it has lived in &lt;a href=&#34;https://www.omnigroup.com/omnifocus&#34; title=&#34;Omnifocus&#34;&gt;Omnifocus&lt;/a&gt;. I have even written &lt;a href=&#34;https://unwiredcouch.com/2014/05/13/omnifocus.html&#34; title=&#34;Omnifocus post&#34;&gt;about it before&lt;/a&gt;. For the rest of planning and notes I kept a handful of markdown files in a git repo, held together by Makefiles and &lt;a href=&#34;https://github.com/mrtazz/vim-plan&#34; title=&#34;vim-plan plugin&#34;&gt;a vim plugin&lt;/a&gt;. But now it didn’t work for me anymore. I kept opening OmniFocus just to find myself aimlessly clicking and sorting things around. I redid the layout of my perspectives again. Restructured all the GTD contexts and areas of focus. But nothing actually changed. Looking at the app it just blurred with all the other open windows. All the other apps. It became kind of meaningless. I realized with 100% of work and interactions happening on my screen now, everything felt the same to me. I was unable to focus on what I wanted to do. Planning was an app switch away from coding was an app switch away from meetings was an app switch away from my todos. There were many times where I caught myself cycling from one thing to the other a couple of times within minutes. My attention was completely shot. Additionally I had so many Omnifocus integrations set up that were pulling in my JIRA tickets, my assigned code reviews, and even emails I needed to reply to at some point. The longer I wasn’t using Omnifocus the more it got cluttered with things that needed filing. Instead of helping me get organized it did the opposite. I had over engineered Omnifocus having succumbed to the idea that I&#39;d be more productive the more I automate and fine tune it.&lt;/p&gt;&#xA;&lt;h2 id=&#34;trying-something-new-ish&#34;&gt;Trying something new(-ish)&lt;/h2&gt;&#xA;&lt;p&gt;I needed to change things up. And the solution for this couldn&#39;t be another app. It needed to be different. And it turns out this is a pretty normal thing for humans. We link memories (which things to remember to do basically are) to locations via the hippocampus.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;This is the reason it&#39;s important to have a designated place for each of our belongings - the hippocampus does the remembering for us if we associate an object with a particular spatial location.&lt;/p&gt;&#xA;&lt;p class=&#34;cite&#34;&gt;&#xA;&amp;mdash; &lt;cite&gt;Daniel Levitin, The Organized Mind (p. 91)&lt;/cite&gt;&#xA;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;I’ve been carrying a Moleskine notebook with me since early 2008. Early on I had already used it as a todo organizer before switching to Things and eventually Omnifocus. I’ve used it on and off for random things (rarely enough for it to last 10 years). And it’s been the testing ground every time I wanted to get back to taking more analog notes. I’ve also backed the &lt;a href=&#34;https://unwiredcouch.com/2015/03/18/spark-notebook-omnifocus.html%20%22Spark%20Notebook%20post%22&#34;&gt;Spark Notebook&lt;/a&gt; on Kickstarter and used that with a lot of success for a while. So when I was looking to change things up from my digital routine I remembered having read about the &lt;a href=&#34;https://bulletjournal.com/&#34; title=&#34;Bullet Journal method&#34;&gt;Bullet Journal method&lt;/a&gt; and decided to give it a try.&lt;/p&gt;&#xA;&lt;h2 id=&#34;getting-started-with-a-bullet-journal&#34;&gt;Getting started with a Bullet Journal&lt;/h2&gt;&#xA;&lt;p&gt;For getting set up I started reading the website first and watched the canonical intro video linked from there. But being used to this elaborate GTD setup I wasn’t convinced that a minimalist way worked for me. I read a lot of fairly popular posts on getting started with bullet journaling from websites like &lt;a href=&#34;https://littlecoffeefox.com/&#34; title=&#34;Little Coffee Fox&#34;&gt;this&lt;/a&gt; and &lt;a href=&#34;https://www.tinyrayofsunshine.com&#34; title=&#34;Tiny Ray of Sunshines&#34;&gt;this one&lt;/a&gt; and a ton of other blog posts to understand how this is being used by different people. And then I bought a new notebook and some pens and started with my own.&lt;/p&gt;&#xA;&lt;p&gt;And I absolutely overdid it. I used a ton of color and differently sized pens to denote headlines, priorities, etc. I had 2 different systems (dot stickers and sticky labels) do denote important pages. And I added a ton of modules and collections like trackers for workout, meditation, water intake, and reading time. I had very elaborate monthly and weekly spreads, trying to recreate the organizational cockpit that I always wanted Omnifocus to be. I put way too many things to do in, areas of focus with color coded headings, and complicated time blocking details. My daily spread had a &lt;a href=&#34;https://medium.com/rohdesign/the-daily-plan-bar-357972361096&#34; title=&#34;Rohdesign Daily Plan bar&#34;&gt;daily plan bar&lt;/a&gt; that included all my meetings and time blocks for the day. My weekly spreads were as complicated and stuffed, at some point even including which days to take out the trash. Bringing me to up to an hour of just setting up my page to get started for the day. All to combat the feeling of not getting things done and falling of the wagon again.&lt;/p&gt;&#xA;&lt;p&gt;Of course once the initial excitement had worn off I fell back into seeing maintaining this complicated thing as a chore and neglected it. And I ran into the same problem I had with Omnifocus of having a layout that was very tuned to my workdays. On the weekend or when I was taking vacation, it wasn’t useful. And I hardly interacted with the journal. Leaving me again with the guilt of “having fallen off”. One important difference though was that on those weekend days and during time off where I couldn’t bother to get into my complicated setups, when I did use the journal it resembled a lot more the original idea of the Bullet Journal. And instead of giving up and changing back to Omnifocus, I stuck with it.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-my-bullet-journal-actually-looks-like-now&#34;&gt;What my Bullet Journal actually looks like now&lt;/h2&gt;&#xA;&lt;p&gt;One of those vacations was at the end of last year. During that time I reduced my usage of the journal to basically only a weekly spread. Mostly because there wasn&#39;t much to keep track of. And I realized it still worked for me. I still put all my todos and appointments in there. And it adapted to the difference in usage wonderfully. I was also about to start my third Bullet Journal, having journaled more than twice as much as the previous 10 years combined. I bought the official &lt;a href=&#34;https://bulletjournal.com/pages/book&#34; title=&#34;Bullet Journal Book&#34;&gt;Bullet Journal book&lt;/a&gt; to learn more about the ideas and philosophies behind the original approach given I had more belief it could work for me. And aside from all the other interesting things in the book, the thing that really changed the way I thought about it was that it&#39;s still supposed to be more like a journal than a GTD system.&lt;/p&gt;&#xA;&lt;p&gt;After finishing the book I slimmed down my Bullet Journal to the useful bare essentials. I kept the original monthly layout I had already been using but stripped down the monthly task list to a literal list instead of different areas with colored headlines. The 2 page weekly spread turned into a single page of tasks I want to get done over the course of the week. And the daily spread is no longer a plan bar for a meticulously planned out day. It now just starts with the date headline and serves 90% as a journal for recording the day rather than a pre-planned skeleton of how I think the day will go. Because one of the big reasons why I was often abandoning the journal was because they day almost never turned out as planned. Making me feel like the journal was less useful.&lt;/p&gt;&#xA;&lt;p&gt;I kept marking the future log (which for me is the combined &lt;a href=&#34;https://bulletjournal.com/blogs/bulletjournalist/future-log-inspiration%20%22Calendex%20Alistair%20Hybrid%20Future%20Log%22&#34;&gt;calendex/alistair&lt;/a&gt; method), monthly and weekly spreads, as well as important collections with dot stickers. That way I can quickly find e.g. the page with the last monthly spread if I want to look something up.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/pen-and-paper/dot-stickers.jpeg&#34; title=&#34;Dot Stickers&#34; alt=&#34;dot stickers for bookmarks&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;And another big insight from the book was that I’m now leaning on &lt;a href=&#34;https://bulletjournal.com/blogs/bulletjournalist/migration&#34; title=&#34;Bullet Journal Migrations&#34;&gt;migrations&lt;/a&gt; a lot more than I used to even though I don’t do daily migrations anymore. I scan the last pages for the current week in the morning for things that still need to get done and if they are a priority I move them to the current day. However that rarely happens and it mostly a measure for me to not forget about priorities. I do weekly and monthly migrations where I thoroughly go through the pages and migrate items, add additional context, put things into the future log (or the topic specific collections for things like personal, work, apartment, etc that serve as a sort of backlog). But otherwise I really just start a new headline every morning and start journaling.&lt;/p&gt;&#xA;&lt;h2 id=&#34;in-closing&#34;&gt;In Closing&lt;/h2&gt;&#xA;&lt;p&gt;Switching to paper for organizing my todos, thoughts, events, and planning things has been absolutely wonderful for my stress levels and mental health. Especially after trimming the process down to the minimum. I’m no longer stressing about the perfect setup, but use the journal in the way that makes the most sense for me in the moment. I still use a reminders list on my phone for things on the go or when I don’t have the journal with me to migrate over later. I’m much more focused and calm about organizing things when I’m able to close my laptop and just open the journal, it feels much less noisy. Using pen and paper so much every day also lead me to occasionally doodle on pages and discover my interest in drawing and art which has been another huge source of joy for me.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2019/07/05/pen-and-paper.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A couple of years ago I went from working in an office to working remote mostly from home. A coup</summary>
  </entry>
  <entry>
    <title>Factors of Confidence</title>
    <updated>2019-04-02T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2019,2019-04-02:/04/02/factors-of-confidence.html</id>
    <content type="html">&lt;p&gt;I&#39;ve been having a lot of discussions about delivery of software lately and especially about the deployment part of it. This made me think about the last couple of years of working on deployment and development tooling and the approach I take there.&lt;/p&gt;&#xA;&lt;p&gt;I&#39;ve come to view this from a perspective of formulating a hypothesis and establishing factors of confidence to confirm or refute this hypothesis. This sounds very abstract and theoretical at first. But bear with me for a moment here. The basis for all delivery is a change (or patch, diff, commit, change set, whatever you wanna call it). This change is meant to improve something. Add a feature (or establish the base for one), fix a bug, improve performance, increase visibility, or just clean up some technical debt. This means you&#39;re going to production to make the world better. However given the complex nature of the systems we deploy software to, you won&#39;t actually know if your change is a net positive until it&#39;s running in production. And even then you often only know a couple of hours or even days later. So all you have when you&#39;re in front of your editor writing some code is an idea about what will make the word better. A hypothesis.&lt;/p&gt;&#xA;&lt;p&gt;The job of a delivery pipeline now is to help you get confidence. Confidence that your hypothesis holds. Or confidence when you have to refute it. However all of the complex interactions of systems means you don’t get to have that single unified proof that your code is what you want it to be. Your ability to make a decision about your change is based on many small factors of confidence. And the delivery pipeline should give you tools along the way to acquire those factors of confidence in reasonable time and effort. It usually starts with a very quick feedback loop and something akin to a unit test. You can write them quickly and they can be verified quickly (individually that is. Running large numbers of unit tests on CI is still a not so easy problem). You then usually move on to test that are more expensive with a longer feedback loop. Like an integration test. Maybe a QA environment. A staging environment. Smoker tests in production. Canary deploys. And so on. All of those things (and this is hardly an exhaustive list) are intended to give you confidence in something. That your logic is correct, that your code works well with other API endpoints, that it interacts with other code on the site in a way that doesn’t break the whole thing, that it doesn’t put too much load on downstream systems, etc, etc. And ideally all these things in place will give you a nice set of guardrails that make deploying to production an enjoyable experience.&lt;/p&gt;&#xA;&lt;p&gt;However given these tools are merely a snapshot of your understanding of the system at the time and what confidence is needed to make a change to it, the delivery pipeline needs to be constantly maintained and re-evaluated. Maybe system growth now means that the trade off of running a large array of unit tests and the time it takes, doesn’t pay off in the confidence it provides. Or maybe it does and this means you need to think of something to make running unit tests faster. Maybe a new additional service means you now need to add a set of smoker tests. Whatever it is, the most important thing is that you know &lt;em&gt;why&lt;/em&gt; any of these tools to assert confidence are in place. &lt;em&gt;Who&lt;/em&gt; are they for and &lt;em&gt;what&lt;/em&gt; are they telling you? The last couple of years have seen the rise of a huge number of fantastic delivery systems. Often highly opinionated or infinitely configurable. Sometimes both. It’s easy to just take one of them and cargo cult what they bring with it. And if you don’t already have an established system, this is a fine approach that will certainly make you end up with a better setup than you had before. However I encourage you to look closely what your delivery pipeline is made up of. And what kind of things it gives you confidence in. Do you often see failures after deploys because of surprises in your logic? Maybe you’re missing some unit tests. Are you spending tons of time on unit tests that essentially only re-test the framework code of the tool you’re using? Maybe you don’t need those tests and can free up a lot of engineering time. Whatever it is, your delivery pipeline needs to give you confidence in changes in &lt;em&gt;your&lt;/em&gt; stack. You know best what kind of things need to go in there. And spending some time to think about that will give you a lot of insight and pay off when it comes to improving your delivery pipeline. And it’s also tons of fun!&lt;/p&gt;&#xA;&lt;p&gt;PS: I’ve had many discussions about those things with many people over the years. And they all helped me figure out how I think about delivery and make sense of my rambling thoughts. So if you&#39;ve ever chatted with me about deployment and/or delivery, I&#39;m extremely grateful you took the time and I really enjoyed our chat.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2019/04/02/factors-of-confidence.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I&#39;ve been having a lot of discussions about delivery of software lately and especially about the </summary>
  </entry>
  <entry>
    <title>Capacity planning for Etsy’s web and API clusters</title>
    <updated>2018-10-23T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2018,2018-10-23:/10/23/capacity-planning-etsy.html</id>
    <content type="html">&lt;p&gt;I wrote about how we do capacity planning for our web and API clusters on Etsy&#39;s &lt;a href=&#34;https://codeascraft.com&#34;&gt;engineering blog&lt;/a&gt;. You can find the post &lt;a href=&#34;https://codeascraft.com/2018/10/23/capacity-planning-for-etsys-web-and-api-tiers/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2018/10/23/capacity-planning-etsy.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I wrote about how we do capacity planning for our web and API clusters on Etsy&#39;s &lt;a href=&#34;https:/</summary>
  </entry>
  <entry>
    <title>Learning to have an engineering vision</title>
    <updated>2018-01-03T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2018,2018-01-03:/01/03/engineering-vision.html</id>
    <content type="html">&lt;p&gt;Saying that the last 18 months or so were stressful and full of changes would be a colossal understatement. Work wise I switched to a new team after over 4 years on the same team, which was then dismantled as part of a big structural reorg that was actually part 1 of 2. Part 2 consisted of a larger restructuring that meant my new team also ceased to exist in its then current form after only 10 months. These changes were incredibly important and long overdue. However after a couple of pretty stable years this also meant I had to get out of my comfort zone in a lot of new ways. On both newly created teams I was one of the more senior engineers which meant for me thinking long and hard about how I want to contribute to building up a new team and what my place should and can be there. This meant building up and getting used to new routines, schedules, way of communication and urgencies in work. All muscles I had not really needed to exercise in a while and to a large degree not ever. And besides the build up of technical knowledge about the services we were now providing as a team, the non-technical side of things was where I really grew as an engineer. Specifically the most positive impact on how I view work has been to finally get a better grasp and think hard about what vision means for an infrastructure/systems engineering team.&lt;/p&gt;&#xA;&lt;p&gt;I&#39;ve gone through the process of thinking about vision for a team before. At Etsy we use a structure called &#34;VMSO - Vision, Mission, Strategy, Objectives&#34;, to organize and structure teams and departments in what their purpose is within the company and what they contribute to the business. It draws a lot of inspiration from the ideas in this blog post by LinkedIn CEO Jeff Weiner called &lt;a href=&#34;https://www.linkedin.com/pulse/20121029044359-22330283-to-manage-hyper-growth-get-your-launch-trajectory-right&#34;&gt;&#34;From Vision to Values: The Importance of Defining Your Core&#34;&lt;/a&gt;. The rough overview is that vision is the 30 000 foot view, the high level idea on the horizon that (almost) never changes. The world we want to see exist. The mission is derived from it and describes what the team does to get towards the vision. And then it gets more concrete with strategies how to get there and concrete objectives we want to fulfill. It&#39;s not an easy process and definitely takes a whole of brainstorming, suggestions, throwing away suggestions, refining and merging ideas, and consensus building to get there.&lt;/p&gt;&#xA;&lt;p&gt;Before this season of change, on my old team, when we were tasked with creating a VMSO for ourselves we always got hung up on the vision. It was always that high level thing that never quite matched the work we were doing. We would meet once or twice and always seemed to end at the same dead ends: &#34;Our work is too multifaceted to be captured by a single statement&#34;, &#34;It&#39;s hard to explain what we do&#34;, &#34;We do anything that needs doing&#34;, &#34;We keep things running&#34;. If you&#39;re working on a general purpose infrastructure team, this might sound familiar to you. It seemed like it was just impossible to come up with a single vision for the team, so we always left it at a half baked, cheesy feeling idea. And of course at that point we didn&#39;t manage to derive a good mission from the vision either. Not to speak of strategy or objectives. I didn&#39;t feel too bad about that at the time. As we had a fairly broad vision statement, it let us basically take on anything we wanted. And to be honest, I &lt;em&gt;loved&lt;/em&gt; working on that team. Although we were always working on separate things, we were a bunch of engineers with the same mindset and approach to work. We had a great team dynamic and our team meetings were a ton of fun. I couldn&#39;t imagine working on a different team.&lt;/p&gt;&#xA;&lt;p&gt;And in the middle of this work the first part of the reorg happened and our team got dissolved. I was really upset. While I was fully onboard with the reasoning and goals of the reorg, I couldn&#39;t understand why our team got ended and most of our roadmap dropped. It felt like our work had gone completely unvalued. But then I had a long 1-on-1 with my then &lt;a href=&#34;http://twitter.com/attackgecko&#34;&gt;Engineering Director Jason Wong&lt;/a&gt;. We talked about all of it, he gave me a ton more context. And he made me understand how a team that does &#34;a little bit of everything&#34; is really hard to fit in organizationally. He asked me flat out what the purpose and vision of the team was in the org. Where was the team going? What would it look like in 2 years? And I couldn&#39;t give him a straight, simple answer. I was a very senior engineer on the team and I had no answer. This was the moment where I managed to connect (some of) the dots. And tie together our lack of a comprehensive vision to the downsides of our operating model. We ended up supporting way more things than we could, leading to long periods of maintenance work and almost none of the iterative improvements we planned for at the beginning of the year. We had no way of saying no to work because we didn&#39;t have a good reason to reject the work. We had weeks where our work summary would basically just be &#34;clean up&#34;. Which I love doing and is valuable work, but not if it takes up 90% of someone&#39;s time. We agreed on a vision that was defined by the work we were already doing and not by what we wanted the work to be.&lt;/p&gt;&#xA;&lt;p&gt;And at the time I failed to see the big downside of this: it let us take on anything we wanted. While this sounds like fun at first, it makes a lot of things really hard. We continuously worked on 6 different projects as a team of 7 engineers. There was hardly any collaboration possible and we ended up with single points of failure because single engineers would end up being the only ones knowing about a particular system. Once we had hit the limit of reports for a manager (7 at the time), we needed to hire another manager but had a really hard time figuring out how to split the team because there was no clear structure. And boy was it hard to give the elevator pitch for the team in those interviews. We were a team that was ever expanding its work areas to catch things and never managed to retract back and focus on our core. We were aware of those problems and we always thought we will figure them out with time. For the time being it felt better to keep fixing things and worry about the rest later. Succumbing to the always existing, intriguing feeling that something that you can fix needs to be fixed right now.&lt;/p&gt;&#xA;&lt;p&gt;And in the middle of 2016, all of this was suddenly gone. And after that very intense and honest 1-on-1 with Jason I felt I knew what I had to do. I joined a new team. I kept thinking about team focus and organizational structure. And when we set up to create a VMSO I went full in and went with the process. I talked a lot to &lt;a href=&#34;http://twitter.com/dbness&#34;&gt;Vanessa Hurst&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/lara_hogan&#34;&gt;Lara Hogan&lt;/a&gt;, both also Engineering Directors at the time, about VMSOs, team structure and direction. Both of them know incredibly well how to build engineering organizations and gave me so much insight and food for thought how to approach this task. I thought hard and good about what &lt;em&gt;I&lt;/em&gt; as an engineer on the team wanted the team to be. And what I don&#39;t want it to be. What were the things that I wanted this team to contribute to the business? What did I not want to bring around anymore and let stay in the past? I wanted to have a vision that I can align goals and work to that would provide focus and effectiveness for the team. And after a week or two with many, many VMSO meetings we ended up with a result that I was really happy with. It was also the first thing we delivered as a newly created team which helped immensely with team identity building. And in the following months to come I found myself often referring to the vision when the question came up of whether our team should be doing a particular bit of work or take over a certain ticket.&lt;/p&gt;&#xA;&lt;p&gt;Since then I&#39;ve also worked on the VMSO for our whole organization of Systems Engineering. And it was an even harder challenge to find something that matches the purpose of a dozen teams and gives them something to align their work to. But it was again a valuable lesson and a time spent building the structure for something I really want to be part of and make contribution to the business.&lt;/p&gt;&#xA;&lt;p&gt;These past 18 months have been an incredibly intense learning period for me. Most of the things we did on my old team were the right things to do at the time. We worked on a lot of exciting and important projects that enabled others to build on top. And we were incredibly successful. But we also missed the point where the team needed to change to a different operating model to grow with the business. To align it to where the infrastructure needed to go. I learned to not think about work on an infrastructure team as just &#34;keeping the lights on&#34;, &#34;fixing broken things&#34; or &#34;administering the machines everything else runs on&#34;. But actually take the time to think about what to really contribute to engineering. What the state is I can see on the horizon and not just the work I know needs to get done right now. The two or three things that will make a difference over a laundry list of things that would be nice to do.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2018/01/03/engineering-vision.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Saying that the last 18 months or so were stressful and full of changes would be a colossal under</summary>
  </entry>
  <entry>
    <title>Make and Go for Fun and Profit</title>
    <updated>2016-05-31T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2016,2016-05-31:/05/31/go-make.html</id>
    <content type="html">&lt;p&gt;I&#39;ve been somewhat interested in Go for quite a while now. It&#39;s gotten to the point where it has replaced Ruby for me in those places where I write command line utilities which are too involved for them to make sense to be a shell script. I don&#39;t have too many opinions about the language itself, but I like the static type system and that it&#39;s a compiled language. And to be honest, the build system and how to utilize it have been the most interesting bits for me so far. One thing I especially like is the fact that go provides a bunch of tooling to do different things but how you tie them together is up to you. So this gives rise to some fun use cases for a nice Makefile.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-basics&#34;&gt;The Basics&lt;/h3&gt;&#xA;&lt;p&gt;Every project I start gets this Makefile with some basic setups and variable definitions that I always want.&lt;/p&gt;&#xA;&lt;pre class=&#34;make&#34;&gt;&lt;code&gt;export GO15VENDOREXPERIMENT = 1&#xA;&#xA;# variable definitions&#xA;NAME := coolthings&#xA;DESC := a nice toolkit of helpful things&#xA;PREFIX ?= usr/local&#xA;VERSION := $(shell git describe --tags --always --dirty)&#xA;GOVERSION := $(shell go version)&#xA;BUILDTIME := $(shell date -u +&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;)&#xA;BUILDDATE := $(shell date -u +&amp;quot;%B %d, %Y&amp;quot;)&#xA;BUILDER := $(shell echo &amp;quot;`git config user.name` &amp;lt;`git config user.email`&amp;gt;&amp;quot;)&#xA;PKG_RELEASE ?= 1&#xA;PROJECT_URL := &amp;quot;https://github.com/mrtazz/$(NAME)&amp;quot;&#xA;LDFLAGS := -X &amp;#39;main.version=$(VERSION)&amp;#39; \&#xA;           -X &amp;#39;main.buildTime=$(BUILDTIME)&amp;#39; \&#xA;           -X &amp;#39;main.builder=$(BUILDER)&amp;#39; \&#xA;           -X &amp;#39;main.goversion=$(GOVERSION)&amp;#39;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;For the most part this just defines a whole bunch of meta data that gets compiled into the binaries via linker flags. This is a pattern I have seen in a lot of Go projects and I really like that this is somewhat of a standard thing to do. Especially with the static nature of Go binaries, the more helpful information you can compile into the binary the better it is when you have to figure out where a binary comes from.&lt;/p&gt;&#xA;&lt;p&gt;I also always have a handful of tasks defined that are helpful for running tests and such, especially to have a uniform and documented way how they are run locally and on CI.&lt;/p&gt;&#xA;&lt;pre class=&#34;make&#34;&gt;&lt;code&gt;# development tasks&#xA;test:&#xA;    go test $$(go list ./... | grep -v /vendor/ | grep -v /cmd/)&#xA;&#xA;PACKAGES := $(shell find ./* -type d | grep -v vendor)&#xA;&#xA;coverage:&#xA;    @echo &amp;quot;mode: set&amp;quot; &amp;gt; cover.out&#xA;    @for package in $(PACKAGES); do \&#xA;        if ls $${package}/*.go &amp;amp;&amp;gt; /dev/null; then  \&#xA;        go test -coverprofile=$${package}/profile.out $${package}; fi; \&#xA;        if test -f $${package}/profile.out; then \&#xA;        cat $${package}/profile.out | grep -v &amp;quot;mode: set&amp;quot; &amp;gt;&amp;gt; cover.out; fi; \&#xA;    done&#xA;    @-go tool cover -html=cover.out -o cover.html&#xA;&#xA;benchmark:&#xA;    @echo &amp;quot;Running tests...&amp;quot;&#xA;    @go test -bench=. $$(go list ./... | grep -v /vendor/ | grep -v /cmd/)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;These make heavy use of &lt;code&gt;go list&lt;/code&gt; to determine existing packages to run tests for. The rules also exclude the vendor folder as I don&#39;t want to run those tests and the cmd folder which I will describe more in the next section.&lt;/p&gt;&#xA;&lt;h3 id=&#34;structure-for-multiple-binaries&#34;&gt;Structure for multiple binaries&lt;/h3&gt;&#xA;&lt;p&gt;Go has this defacto standard of how to structure code if your build produces multiple executables. Since your main entry point in the app is always the main package and there can only be one per directory (which is also true for any other package btw) you need to separate different executables by directory. The pattern here is basically to have a &lt;code&gt;cmd&lt;/code&gt; folder that contains subfolders for each executable which in turn just contain a &lt;code&gt;main.go&lt;/code&gt; file. This is a pretty nice pattern, once you get used to it and is a convention that lets you easily create make rules for building those executables via the make wildcarding support.&lt;/p&gt;&#xA;&lt;pre class=&#34;make&#34;&gt;&lt;code&gt;CMD_SOURCES := $(shell find cmd -name main.go)&#xA;TARGETS := $(patsubst cmd/%/main.go,%,$(CMD_SOURCES))&#xA;&#xA;%: cmd/%/main.go&#xA;    go build -ldflags &amp;quot;$(LDFLAGS)&amp;quot; -o $@ $&amp;lt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This piece just finds all &lt;code&gt;main.go&lt;/code&gt; files under the cmd folder and creates targets from them located at the top level of the repo. Then there is a rule to build those targets via a rule that ties them back to the source file via wildcarding again and runs &lt;code&gt;go build&lt;/code&gt; with the linker flags from before.&lt;/p&gt;&#xA;&lt;p&gt;Of course it&#39;s good habit to provide man pages for your tools. So we can rig up a similar set of rules for building man pages for each executable:&lt;/p&gt;&#xA;&lt;pre class=&#34;make&#34;&gt;&lt;code&gt;MAN_SOURCES := $(shell find man -name &amp;quot;*.md&amp;quot;)&#xA;MAN_TARGETS := $(patsubst man/man1/%.md,%,$(MAN_SOURCES))&#xA;&#xA;%.1: man/man1/%.1.md&#xA;    sed &amp;quot;s/REPLACE_DATE/$(BUILDDATE)/&amp;quot; $&amp;lt; | pandoc -s -t man -o $@&#xA;&#xA;all: $(TARGETS) $(MAN_TARGETS)&#xA;.DEFAULT_GOAL:=all&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This lets us write man pages in markdown under the &lt;code&gt;man/man1/&lt;/code&gt;folder named as &lt;code&gt;${cmd}.1.md&lt;/code&gt; and again uses wildcards in make to generate them top level via an implicit rule. I also added an &lt;code&gt;all&lt;/code&gt; target there which is the default and builds all binaries and man pages.&lt;/p&gt;&#xA;&lt;p&gt;Over time I&#39;ve come to the conclusion that it&#39;s really a good practice to have your &lt;code&gt;main.go&lt;/code&gt; files be as slim as possible. Ideally all they should be concerned with is flag parsing, calling a method from your library packages, and formatting and printing the output to the terminal. Any actual logic should live in library modules somewhere else in your repo. This maintains a good code layout to extend, makes sure code is reusable, and provides good conventions for testing.&lt;/p&gt;&#xA;&lt;h3 id=&#34;installation&#34;&gt;Installation&lt;/h3&gt;&#xA;&lt;p&gt;So now that we have rules to build the binaries, we also want to be able to install them to the &lt;code&gt;PREFIX&lt;/code&gt; we have defined at the top. Go comes with an install command already (&lt;code&gt;go install&lt;/code&gt;) which will put binaries in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; but there is no need to have to rely on that. Plus on a multi user system you want to provide tools for everyone anyways. Also let&#39;s be real, &lt;code&gt;go install&lt;/code&gt; is not a replacement for a real package manager. Just because go builds are fast and produce a static binary doesn&#39;t mean it&#39;s not a good idea to be able to build packages. Plus you want your man pages to be installed with your software as well of course. So let&#39;s write some generic install commands:&lt;/p&gt;&#xA;&lt;pre class=&#34;make&#34;&gt;&lt;code&gt;INSTALLED_TARGETS = $(addprefix $(PREFIX)/bin/, $(TARGETS))&#xA;INSTALLED_MAN_TARGETS = $(addprefix $(PREFIX)/share/man/man1/, $(MAN_TARGETS))&#xA;&#xA;# install tasks&#xA;$(PREFIX)/bin/%: %&#xA;    install -d $$(dirname $@)&#xA;    install -m 755 $&amp;lt; $@&#xA;&#xA;$(PREFIX)/share/man/man1/%: %&#xA;    install -d $$(dirname $@)&#xA;    install -m 644 $&amp;lt; $@&#xA;&#xA;install: $(INSTALLED_TARGETS) $(INSTALLED_MAN_TARGETS)&#xA;&#xA;local-install:&#xA;    $(MAKE) install PREFIX=usr/local&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;We&#39;re adding the &lt;code&gt;PREFIX&lt;/code&gt; to all targets and man targets here to generate the paths to install. Then we write another implicit wildcarding rule that has the original targets as dependencies and performs install commands to put them into the prefix. This is a quick and easy way to have a generic &lt;code&gt;make install&lt;/code&gt; target and also lets us easily add a local install target that we can use as a dependency for building packages later on.&lt;/p&gt;&#xA;&lt;h3 id=&#34;dependencies-oh-my&#34;&gt;Dependencies, Oh My!&lt;/h3&gt;&#xA;&lt;p&gt;If you&#39;ve spent time with Go and make before, you will maybe have noticed a flaw in the building step of the Makefile so far. To revisit, we are building binaries from the source in the cmd folder with this implicit rule.&lt;/p&gt;&#xA;&lt;pre class=&#34;make&#34;&gt;&lt;code&gt;%: cmd/%/main.go&#xA;    go build -ldflags &amp;quot;$(LDFLAGS)&amp;quot; -o $@ $&amp;lt;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;However this only tells make about the first level of direct dependencies for the binary to the cmd source. Chances are you are using library and vendored code in those. This means while &lt;code&gt;go build&lt;/code&gt; technically knows about all dependencies, make doesn&#39;t. And it will refuse to rebuild the binaries if something other than the cmd source changes. This is annoying but fortunately also fixable. A simple fix would be to just not have dependencies in make for the executables and mark them as &lt;code&gt;.PHONY&lt;/code&gt; so that they are always regarded out of date. This pushes all dependency resolution back to the go tool chain which is nice, but kinda defeats half of the purpose of a Makefile as it will just run all the commands all the time. To be clear, in practice this is a fine solution and the downsides are mostly academic with the speed of a usual go build.&lt;/p&gt;&#xA;&lt;p&gt;However it&#39;s fun to figure out how to make things work and while we&#39;re here already, lets utilize make to its full extent and make it aware of all dependencies. The details for the make side of things I got from &lt;a href=&#34;http://make.mad-scientist.net/papers/advanced-auto-dependency-generation/&#34;&gt;this awesome blogpost&lt;/a&gt; which gives a great overview over automatic dependency management in makefiles. So now all we need is a way to get a list of all dependencies for a go source file. And of course, &lt;code&gt;go files&lt;/code&gt; to the rescue again! As it not only lets us print packages for passing to the test runner, but also can print out all dependencies of a file. And with its &lt;code&gt;-f&lt;/code&gt; parameter it also supports basic templating for printing out the results. Utilizing that we only need to do a small amount of post processing to print it in make dependency format and we are good to go.&lt;/p&gt;&#xA;&lt;pre class=&#34;make&#34;&gt;&lt;code&gt;# source, dependency and build definitions&#xA;DEPDIR = .d&#xA;$(shell install -d $(DEPDIR))&#xA;MAKEDEPEND = echo &amp;quot;$@: $$(go list -f &amp;#39;{{ join .Deps &amp;quot;\n&amp;quot; }}&amp;#39; $&amp;lt; | awk &amp;#39;/github/ { gsub(/^github.com\/[a-z]*\/[a-z]*\//, &amp;quot;&amp;quot;); printf $$0&amp;quot;/*.go &amp;quot; }&amp;#39;)&amp;quot; &amp;gt; $(DEPDIR)/$@.d&#xA;&#xA;$(DEPDIR)/%.d: ;&#xA;.PRECIOUS: $(DEPDIR)/%.d&#xA;&#xA;-include $(patsubst %,$(DEPDIR)/%.d,$(TARGETS))&#xA;&#xA;%: cmd/%/main.go $(DEPDIR)/%.d&#xA;    $(MAKEDEPEND)&#xA;    go build -ldflags &amp;quot;$(LDFLAGS)&amp;quot; -o $@ $&amp;lt;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The makedepend command here grabs all dependencies that come from github (which was a good enough approximation for me to filter out the std lib), cuts off the project prefix and appends &lt;code&gt;/*.go&lt;/code&gt; to each dependency. With the go rules of having a package per folder, this also is pretty accurate most of the time and only occasionally serves false positives to result in a rebuild. We then adapt the implicit build rule to require the dependency file as well but also rebuild it on each build. And BOOM our Makefile knows almost perfectly a out all source dependencies.&lt;/p&gt;&#xA;&lt;h3 id=&#34;packaging-and-documentation&#34;&gt;Packaging and Documentation&lt;/h3&gt;&#xA;&lt;p&gt;I always aim for providing packages and good documentation for my Go projects. But I&#39;ve already written about those things more generally &lt;a href=&#34;https://unwiredcouch.com/2016/01/12/coding-pride.html&#34;&gt;here&lt;/a&gt;, so if you&#39;re interested in the details of it, give that blog post a read. The important part is that the Makefile also holds the logic for building docs and packages, so they can be easily triggered from CI.&lt;/p&gt;&#xA;&lt;h3 id=&#34;cleanup&#34;&gt;Cleanup&lt;/h3&gt;&#xA;&lt;p&gt;Since it&#39;s also always good to make it easy to clean up artifacts and generated intermediate and output files, all makefiles also get some clean up tasks.&lt;/p&gt;&#xA;&lt;pre class=&#34;make&#34;&gt;&lt;code&gt;# clean up tasks&#xA;clean-docs:&#xA;    rm -rf ./docs&#xA;&#xA;clean-deps:&#xA;    rm -rf $(DEPDIR)&#xA;&#xA;clean: clean-docs clean-deps&#xA;    rm -rf ./usr&#xA;    rm $(TARGETS)&#xA;    rm $(MAN_TARGETS)&#xA;&#xA;.PHONY: all test rpm deb install local-install packages govendor coverage docs jekyll deploy-docs clean-docs clean-deps clean&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Equipped with those Make tricks I&#39;ve been having tons of fun building Go code. Some of that is surely more involved than it has to be and especially the dependency resolution stuff is very bonus round. But it&#39;s been super interesting to rig it up and I learned a lot of things about Make. And in the end that&#39;s what it&#39;s all about for me. (Besides having projects with a super nice to use structure :)&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2016/05/31/go-make.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I&#39;ve been somewhat interested in Go for quite a while now. It&#39;s gotten to the point where it has </summary>
  </entry>
  <entry>
    <title>Optimize for Mutability and the Present</title>
    <updated>2016-05-02T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2016,2016-05-02:/05/02/mutability-present.html</id>
    <content type="html">&lt;p&gt;I recently read &lt;a href=&#34;https://twitter.com/lusis&#34;&gt;John Vincent&#39;s&lt;/a&gt; very interesting and honest blog post about &lt;a href=&#34;http://blog.lusis.org/blog/2016/04/28/the-flaw-in-all-things/&#34;&gt;being paralyzed because of seeing all the flaws in systems&lt;/a&gt;. At first I decided to just put it away as it&#39;s not a problem I encounter a lot. But in the last paragraph he asked how others deal with this. And that was the point in which I started thinking about why this doesn&#39;t bother me as much. And it occupied my brain in those precious shower and dish washing moments thinking about why this - although I know the feeling well - is the case. I more or less thought about it all weekend and this is my attempt to give my perspective on it in a somewhat coherent form. I hope it&#39;s in any way helpful and you should absolutely read John&#39;s post first to understand the context of this post.&lt;/p&gt;&#xA;&lt;p&gt;The short answer is that I optimize for the present and for mutability, which in itself is probably a completely useless answer. So let me try to elaborate what I mean by this. My day job is working in infrastructure engineering, specifically on a team that works on making writing code and deploying it as much fun as possible. This means while I&#39;m technically a software engineer, the lines between software engineering and operations are blurry at best in my day to day work (which is a good thing and I very much enjoy it). I have worked on a bunch of systems, designed some of them, see almost all of them break in various ways and participate in as many architecture reviews as possible to give input on other people&#39;s system designs. The main goal of my work however is to contribute to engineering happiness. This means I&#39;m very aware of the intersection of technology and humans using it. In addition to that, working mostly on internal things means when the things I work on break, a lot of my coworkers are blocked from getting their stuff done. This can be petrifying. When I set out to write a new thing or fix up an existing one, I can test it out for my workflow but can also inevitably see how it could and will break for someone with a different workflow, editor, or set of dotfiles. And what makes it worse is that I won&#39;t notice immediately and when it breaks for someone I might be in a meeting, unable to help right away. And I really &lt;a href=&#34;https://unwiredcouch.com/2016/03/18/breaking-things.html&#34;&gt;hate breaking things&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;So there I have 2 choices. Ship a thing that&#39;s gonna break in some way. Or don&#39;t ship anything. And the way I make myself be ok with shipping something that is flawed is by of course making sure I do a reasonably extensive attempt of testing it. But also make it as easy as possible to change or adapt later, to decide whether my original trade offs are still the right way to go and to rip things out if not. But not necessarily by trying to cater for all possible future use cases (the famous &#34;premature optimization&#34;) and sure as hell not by writing throw away code. Because everybody can tell you the only thing harder than building something is decommissioning it, and that goes doubly so for throw away code. How I try to achieve this is by dropping all of my context into &lt;a href=&#34;https://twitter.com/mrtazz/status/724734135831547905&#34;&gt;documentation and automation&lt;/a&gt; in some form. This means code comments. Documenting my thought process on the JIRA ticket that relates to it. Writing thorough &lt;a href=&#34;https://twitter.com/mrtazz/statuses/661618547295129600&#34;&gt;detailed commit message&lt;/a&gt; about my change. Writing unit tests that are being run on CI. A proper README. A thought through Chef recipe. A Makefile with all important tasks. A runbook. Those kinds of things. So that when someone else has to go and fix something (that could be future me or a coworker), they don&#39;t have to spend minutes to hours to get up to speed on the context, decisions, and trade-offs I had and made to understand why I opted for this solution to the problem. So I&#39;m very happy to write a 20 line commit message that links to the ticket and the CI/try run and mentions the people I consulted while working on this - even for a single line of change. I&#39;m excited to add unit tests even when I&#39;m &#34;only&#34; writing a vim plugin or a shell script. And I&#39;m excited when I get to write man pages.&lt;/p&gt;&#xA;&lt;p&gt;Because if I&#39;m honest, yes I can see how things are flawed and can break in the future. But I don&#39;t think I can accurately judge the impact of that flaw down the line. How severe will it be to reboot a bunch of things for a security update? How annoyed is the developer really gonna be about this tooling change? How pissed is my coworker gonna be to get paged for the thing I built? But also, what is someone gonna be able to build on top of or inspired by this? What am I free to do until the flaw really becomes a problem? And is my coworker gonna be ok with with all of this as they have learned something from it and had all the context available to fix it and make it better? Because the one thing I do know about current me is that there are gonna flaws in any solution. And I know one thing for sure about future me or my coworker encountering the flaw in the system: If they have the same context as I had when I deployed it, they are gonna be a lot happier, more empathetic as to why I made those choices, and be able to more quickly build on the existing solution. And if documentation, automation, and tests are in place it looks a lot less like some thrown together piece of code but more like the thought through project and honest attempt to fix a problem that had to make trade offs that it is. And up until now they trade offs were good ones and enabled a lot of other things that were impossible to tell before the fact.&lt;/p&gt;&#xA;&lt;p&gt;So I guess the way I work through those feelings of overwhelming and paralysis is by making sure I can be damn &lt;a href=&#34;https://unwiredcouch.com/2016/01/12/coding-pride.html&#34;&gt;proud&lt;/a&gt; of the work I&#39;m doing in the present. And make sure it&#39;s as easily adaptable as possible when the future comes around.&lt;/p&gt;&#xA;&lt;p&gt;Of course this is just my personal way of dealing with it. And it is highly influenced by my character and the team I get to work with. And I hope I didn&#39;t deviate too much from John&#39;s original point in the blog post and that this post makes sense in some way. None of this actually makes the reality of flaws and dread of having to deal with them go away. But it gives me an anchor in the present and something to focus on to get things done. And a way to feel more prepared when the flaws &lt;em&gt;do&lt;/em&gt; surface. Because I&#39;d like to think of change as inevitable but also a good thing. Change you&#39;re not prepared for however is when it feels most like a flaw.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2016/05/02/mutability-present.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I recently read &lt;a href=&#34;https://twitter.com/lusis&#34;&gt;John Vincent&#39;s&lt;/a&gt; very interesting and hones</summary>
  </entry>
  <entry>
    <title>Bash Unit Testing from First Principles</title>
    <updated>2016-04-13T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2016,2016-04-13:/04/13/bash-unit-testing-101.html</id>
    <content type="html">&lt;p&gt;In the last couple of months I&#39;ve done a foray into unit testing the shell scripts I write. This is mostly a conglomerate of things I&#39;ve learned and a talk I&#39;ve given to our ops team about unit testing 101 for infrastructure tools last year.&lt;/p&gt;&#xA;&lt;p&gt;In August last year I decided to finally scratch an itch I had for quite a while. The details aren&#39;t super important here, just that it&#39;s a shell script and that there was no sort of of pressure around it which made me take the time to write unit tests for it. That meant for me researching what existed in terms of frameworks and how people are generally approaching this. And unsurprisingly I found a number of ready to use unit testing frameworks, most of them modeled after the familiar patterns you can find in test frameworks for other languages. However I was also curious what a minimal testing framework for bash would look like. After all, all my script would be doing is create some files and directories on disk with some specific content. So I could verify it all with &lt;code&gt;grep&lt;/code&gt; and &lt;code&gt;test&lt;/code&gt;. So I decided to also use this side project to try and write my own minimal bash unit test setup. And while I mostly ended up doing integration testing for the script, it still made me think quite a bit about the basics of unit testing.&lt;/p&gt;&#xA;&lt;h3 id=&#34;unit-testing-101&#34;&gt;Unit Testing 101&lt;/h3&gt;&#xA;&lt;p&gt;One of the first questions I always get when someone hasn&#39;t really come across a lot of &lt;a href=&#34;https://en.wikipedia.org/wiki/Unit_testing&#34;&gt;unit testing&lt;/a&gt; is &#34;what is a unit?&#34;. And while technically you can probably argue for a unit being a lot of things, the most helpful one I&#39;ve always found to be:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;a unit is a function&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;This simultaneously gives a very concrete answer and also a starting point of what to do. When writing unit tests, start testing functions. This of course occasionally leads to the next question &#34;what is a function?&#34; and more often to the debate of how to make a function testable. For the first question I&#39;ve again found this very reductionist answer to be the most helpful:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;a function is a reusable piece of code that turns defined input into defined output&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;This is somewhat close to what you learn in school about functions in math and has helped me a lot with how I think about writing code.&lt;/p&gt;&#xA;&lt;h3 id=&#34;writing-our-first-tested-bash-code&#34;&gt;Writing our first tested Bash code&lt;/h3&gt;&#xA;&lt;p&gt;Now with those definitions out of the way, there&#39;s a plan on how to make a shell script unit testable:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Refactor your code into functions&lt;/li&gt;&#xA;&lt;li&gt;Write tests for those functions&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;There&#39;s a bit of a lesson to learn about &lt;a href=&#34;https://en.wikipedia.org/wiki/Side_effect_(computer_science)&#34;&gt;side effect free functions&lt;/a&gt; but we can short circuit that by saying the only things your functions should rely on are variables passed into it. And it should always echo its results to STDOUT. This heavily reduces the possibility for side effects in bash functions but also limits the functions that absolutely have to do something other than just taking input and printing results to an absolute minimum. Your logic can live in the other functions most of the time. And those are the ones you can unit test. So now let&#39;s write some functions and tests for them.&lt;/p&gt;&#xA;&lt;p&gt;Let&#39;s say we want a function to output the number of characters in a string. It could look something like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt; num_chars&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${1}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;wc&lt;/span&gt; -c&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;It&#39;s a very contrived example and you&#39;re basically testing that &lt;code&gt;wc&lt;/code&gt; works correctly. But it&#39;s a useful example here to show some things. Notice how the function only acts on variables passed into it and prints the result to STDOUT.&lt;/p&gt;&#xA;&lt;p&gt;Now let&#39;s write a unit test for it.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt; test_num_chars&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;res=$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;num_chars&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${res}&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-ne&lt;/span&gt; 3&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;failed to assert that &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${res}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; is 3&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-6&#34;&gt;&lt;a href=&#34;#cb2-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;And that&#39;s it. That&#39;s all you really need to do to write a simple unit test in bash.&lt;/p&gt;&#xA;&lt;p&gt;Of course adding more tests now generates a lot of repetitive work. So we can write a helper function to do the assertion part of the test.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt; assert&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34;&gt;&lt;/a&gt; &lt;span class=&#34;bu&#34;&gt;eval&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${1}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34;&gt;&lt;/a&gt; &lt;span class=&#34;kw&#34;&gt;if [[&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$?&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-ne&lt;/span&gt; 0&lt;span class=&#34;kw&#34;&gt; ]]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34;&gt;&lt;/a&gt;   &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${FUNCNAME[1]}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;: failed&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34;&gt;&lt;/a&gt; &lt;span class=&#34;kw&#34;&gt;else&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-6&#34;&gt;&lt;a href=&#34;#cb3-6&#34;&gt;&lt;/a&gt;   &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${FUNCNAME[1]}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;: passed&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-7&#34;&gt;&lt;a href=&#34;#cb3-7&#34;&gt;&lt;/a&gt; &lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-8&#34;&gt;&lt;a href=&#34;#cb3-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This helper function takes an argument which is a statement to evaluate. And depending on whether the eval exits with 0 or not, the test is regarded as passing or failing. It then prints out the result accordingly. &lt;code&gt;FUNCNAME&lt;/code&gt; in bash is an array that holds the current execution call stack. And thus the first entry in it is the current function and the next one is the calling function. This gives us a nice way to determine which test is being executed and make it part of the output message.&lt;/p&gt;&#xA;&lt;p&gt;And with this helper function in place, our test now looks like this.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt; test_num_chars&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;res=$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;num_chars&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;ex&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;[ &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${res}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; -ne 3 ]&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Now we can already define a couple of tests and run them by calling the functions we defined. However that also gets very repetitive fast and you always have to remember to actually call the function when you define a new test. So let&#39;s also write a helper function to do this for us.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt; run_test_suite&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-2&#34;&gt;&lt;a href=&#34;#cb5-2&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;testcase&lt;/span&gt; in &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt;declare&lt;/span&gt; -f &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;grep&lt;/span&gt; -o &lt;span class=&#34;st&#34;&gt;&amp;quot;^test[a-zA-Z_]*&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-3&#34;&gt;&lt;a href=&#34;#cb5-3&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;va&#34;&gt;${testcase}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-4&#34;&gt;&lt;a href=&#34;#cb5-4&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;done&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-5&#34;&gt;&lt;a href=&#34;#cb5-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This helper gets all the currently declared functions (via &lt;code&gt;declare -f&lt;/code&gt;), looks for the ones starting with &#34;test&#34;, and then simply executes them.&lt;/p&gt;&#xA;&lt;p&gt;Now all you have to do is call &lt;code&gt;run_test_suite&lt;/code&gt; at the end of your file and all new test functions are automatically picked up as long as they start with &#34;test&#34;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;fixtures-for-tests&#34;&gt;Fixtures for Tests&lt;/h3&gt;&#xA;&lt;p&gt;Now a lot of times in shell scripts you actually want to interact with files on the file system. And it&#39;s not really feasible to always have everything just be variables to be passed in. In this case you can adapt your script by setting the base of where the files are you want to interact with. Something like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;FILEBASE=${FILEBASE:-&lt;/span&gt;/usr/local/foo&lt;span class=&#34;va&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-2&#34;&gt;&lt;a href=&#34;#cb6-2&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-3&#34;&gt;&lt;a href=&#34;#cb6-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt; list_files_with_a&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-4&#34;&gt;&lt;a href=&#34;#cb6-4&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ls&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${FILEBASE}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/a*&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-5&#34;&gt;&lt;a href=&#34;#cb6-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Now you can set the variable in your test suite before you source your shell script with the functions to test. That way &lt;code&gt;FILEBASE&lt;/code&gt; will already be set and the functions use it as their base. If you know create a directory for those fixtures in your tests directory, you can easily mock out file system details in a controlled way and test for them.&lt;/p&gt;&#xA;&lt;h3 id=&#34;dependency-injection-in-bash&#34;&gt;Dependency Injection in Bash&lt;/h3&gt;&#xA;&lt;p&gt;One of the most important things for me to get better at unit testing in general was understanding &lt;a href=&#34;https://en.wikipedia.org/wiki/Dependency_injection&#34;&gt;dependency injection&lt;/a&gt;. Writing code in a at that would let me completely drive function behavior based solely on what I&#39;m passing in. And if I have to call an external resource make it so I can pass in the expected return value and only if it&#39;s not set, call the external resource. A simple example could look like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt; get_url&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-2&#34;&gt;&lt;a href=&#34;#cb7-2&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;url=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${1}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-3&#34;&gt;&lt;a href=&#34;#cb7-3&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;local&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;res=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${2}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-4&#34;&gt;&lt;a href=&#34;#cb7-4&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-5&#34;&gt;&lt;a href=&#34;#cb7-5&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-z&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${res}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;]; then&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-6&#34;&gt;&lt;a href=&#34;#cb7-6&#34;&gt;&lt;/a&gt;    res=&lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;curl&lt;/span&gt; -s &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${url}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-7&#34;&gt;&lt;a href=&#34;#cb7-7&#34;&gt;&lt;/a&gt;  fi&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-8&#34;&gt;&lt;a href=&#34;#cb7-8&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Now you can use this function as you would normally do with &lt;code&gt;&#39;get_url &#34;https://unwiredcouch.com&#34;&lt;/code&gt;. However in tests you can also pass in a second argument which will be used as a locked out response instead of actually curl-ing the URL.&lt;/p&gt;&#xA;&lt;h3 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h3&gt;&#xA;&lt;p&gt;In this short set of examples I hope it got somewhat clear that it can be straightforward to write a quick unit testing setup for shell scripts from built in functionality and start writing tests. I&#39;ve also shown some techniques to write more testable bash to begin with. If you&#39;re interested in reusing the code if pushed the (slightly more improved) version of this I use to &lt;a href=&#34;https://github.com/mrtazz/minibashtest&#34;&gt;GitHub&lt;/a&gt;. It provides nicer output, more details and properly returns a non-zero exit code if something failed, so you can run it on CI. If you want more functionality or more advanced testing support, I&#39;ve listed some alternatives in the &lt;a href=&#34;https://github.com/mrtazz/minibashtest#advanced-testing&#34;&gt;README&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;And on a slightly related note, you should start using &lt;a href=&#34;http://www.shellcheck.net/&#34;&gt;shellcheck&lt;/a&gt; when writing bash. It&#39;s such an awesome way to get feedback about how to write better shell scripts and I&#39;ve learned tons already just from the errors, warnings, and suggestions popping up in my VIM quickfix list.&lt;/p&gt;&#xA;&lt;p&gt;But the most important part is that testing isn&#39;t magic and doesn&#39;t have to be complicated. You can get started immediately with just the basics of any language. And especially starting to write tests for shell scripts is lots of fun.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2016/04/13/bash-unit-testing-101.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;In the last couple of months I&#39;ve done a foray into unit testing the shell scripts I write. This </summary>
  </entry>
  <entry>
    <title>I don&#39;t like Breaking Things</title>
    <updated>2016-03-18T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2016,2016-03-18:/03/18/breaking-things.html</id>
    <content type="html">&lt;p&gt;I don&#39;t like breaking things. I never have. I hate it. When I was a kid and we got our first computer I was completely &lt;a href=&#34;https://twitter.com/mrtazz/statuses/611190610964430848&#34;&gt;afraid of breaking it&lt;/a&gt;. It was a super expensive item at the time and I had no idea how it worked. And I didn&#39;t know if I would completely break it and we didn&#39;t really have the money to get a new one if I did. Sure I was curious and I was fascinated by it. I wanted to do cool things on this computer. But I didn&#39;t want to break it. My sister was also using it and playing games on there and I didn&#39;t have the hubris that I definitely would be able to put it back together if I broke it. Looking at the trade-off between probably learning something but also ruining my sister&#39;s day it just wasn&#39;t worth it. It wasn&#39;t that I didn&#39;t want to know how it worked, it was &lt;a href=&#34;https://twitter.com/mrtazz/statuses/611190760734650368&#34;&gt;about respect&lt;/a&gt;. And it&#39;s not like I never broke the computer or anything on it. But I never approached it lightly and was very uncomfortable when it happened. And I sure wasn&#39;t proud of it.&lt;/p&gt;&#xA;&lt;p&gt;Fast forward 25 years or so I have gone to a bunch of LAN parties as a kid, went to university to study computers and eventually got a master&#39;s degree in computer science. I&#39;m running &lt;a href=&#34;https://unwiredcouch.com/2013/10/30/uncloud-your-life.html&#34;&gt;most of my own infrastructure&lt;/a&gt;, have built my own home router, had DNS servers from a Dutch ISP take zone transfers from a &lt;a href=&#34;https://www.flickr.com/photos/mrtazz/214028839/in/album-72157594235164764/&#34;&gt;computer running in a camper van toilet&lt;/a&gt;, and upgraded PHP on a big e-commerce website without downtime. It&#39;s fair to say I&#39;ve learned a couple of things and know my way around computers most of the time. And yet I am still deeply uncomfortable breaking things.&lt;/p&gt;&#xA;&lt;h3 id=&#34;whats-wrong-with-breaking-things&#34;&gt;What&#39;s wrong with breaking things?&lt;/h3&gt;&#xA;&lt;p&gt;Ironically I now work in an industry that basically worships breaking things. From famous company mottos like &#34;move fast and break things&#34; to phrases that get quoted out of context like &#34;ask for forgiveness, not permission&#34; everybody seems to love being able to break stuff. What it doesn&#39;t take into account is that breaking things doesn&#39;t happen in a vacuum. Your actions always impact others. Even if you&#39;re on-call, the nature of our complex systems means that nobody has a perfect overview over all interactions. And nobody can be sure they will be the only one to get paged and not someone else downstream who is just sitting down to eat with their family. And claiming you can is in my opinion more an unhealthy sign of hubris than healthy engineering. More likely than not it&#39;s gonna ruin someone else&#39;s day.&lt;/p&gt;&#xA;&lt;p&gt;In addition the romantic picture of the engineer who is not afraid of breaking things and thus disrupting whole industries on the way is not an evenly distributed one. As &lt;a href=&#34;https://twitter.com/katelosse&#34;&gt;Kate Losse&lt;/a&gt; already wrote in &lt;a href=&#34;https://medium.com/@katelosse/the-unbearable-whiteness-of-breaking-things-521cb394fda2#.pujsyenre&#34;&gt;&#34;the unbearable whiteness of breaking things&#34;&lt;/a&gt; it&#39;s usually just the white men again who are able to get away with it. For everyone else this is likely gonna end less well.&lt;/p&gt;&#xA;&lt;p&gt;It&#39;s also a very unhealthy and non-collaborative way of approaching things. It assumes a very negative default instead of working together. And it keeps reinforcing a stereotype that only works because there&#39;s a team of people picking up the pieces once the magic disruptive engineer is done.&lt;/p&gt;&#xA;&lt;h3 id=&#34;but-its-the-only-way-to-learn&#34;&gt;But it&#39;s the only way to learn&lt;/h3&gt;&#xA;&lt;p&gt;Now you might say &#34;Hold up there. Breaking things is the only way to learn. You don&#39;t know a technology until you&#39;ve seen it break.&#34; And I partly agree with you there. However there is a big difference between doing gamedays where things are turned off and shut down in a controlled environment, where everybody got a heads up this is going on, and systems are observed as a team to learn how they behave. This is a great way to learn about technology. And I encourage everyone to do this. Equally if things &lt;em&gt;do&lt;/em&gt; break it&#39;s paramount to investigate those incidents in a blameless way to maximize the things to learn from it.&lt;/p&gt;&#xA;&lt;p&gt;However: Just testing in prod. Not bothering to write unit tests. Not going through staging before going to prod. Rolling out a change to all servers at once just to save some time. Those are the things no one learns a lot from. Other than the fact that you can quickly make a day awful for a bunch of people. And that you might be a shitty coworker.&lt;/p&gt;&#xA;&lt;p&gt;Let me be very explicit. I don&#39;t think you can &lt;em&gt;prevent&lt;/em&gt; every failure from happening. I don&#39;t think people should be punished if something breaks during their daily work. Things break. There&#39;s nothing you can do about that. What I don&#39;t condone is approaching everything with the attitude that it&#39;s ok to actively break things. That it should be the default. That your need of changing something is more important than someone else&#39;s need of not being interrupted. That it&#39;s ok to lean all the way towards efficiency and away from thoroughness. This is not disruption it&#39;s just lack of empathy. The default should always be to try and not break anything. There should be a way to make it as easy as possible to catch errors early on. To test things before they go to prod. To get confidence in something without disrupting someone else&#39;s day. And if there isn&#39;t, maybe this is something to spend time on making better first. It beats breaking things by a long shot. And is actually something to be proud of.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2016/03/18/breaking-things.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I don&#39;t like breaking things. I never have. I hate it. When I was a kid and we got our first comp</summary>
  </entry>
  <entry>
    <title>Take Pride in Your Code</title>
    <updated>2016-01-12T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2016,2016-01-12:/01/12/coding-pride.html</id>
    <content type="html">&lt;p&gt;If you&#39;re working as a software engineer, you have very likely already heard about &lt;a href=&#34;https://en.wikipedia.org/wiki/Egoless_programming&#34;&gt;&#39;egoless programming&#39;&lt;/a&gt;. The notion that you should detach your code from your ego. That criticizing your code is not a personal attack and that at some point your code is going to get deleted. Maybe you have even gone as far as seeing a lot of your work as &#34;throw away code&#34;, because most things are supposed to help you in the moment and not last forever. And these are all good things to learn and internalize. And definitely traits every programmer should have. However as I &lt;a href=&#34;https://twitter.com/mrtazz/status/674229082389938176&#34;&gt;tweeted some weeks ago&lt;/a&gt;, I&#39;m convinced the biggest trick the devil ever pulled there is convincing everyone you shouldn&#39;t take pride in your code. Which so often leads to half finished proof of concepts stuffed into a git repo. Repositories whose README might as well just say &#34;works for me&#34;. And of course most of the time there aren&#39;t any tests, so when you want to make things better, you have no idea where to start. And often enough the justification is just something like &#34;I needed this code and maybe it&#39;s useful to someone else&#34; or &#34;it&#39;s pretty simple, it would have taken me longer to write tests than the actual code&#34;.&lt;/p&gt;&#xA;&lt;p&gt;And I think this doesn&#39;t have to be. All of this talk about egoless programming and throwaway code doesn&#39;t mean you can&#39;t take pride in what you create. As a programmer (and that includes ops people, security engineers, designers, etc - if you commit to a repo, you&#39;re a programmer; don&#39;t let anyone take this away from you) you now have access to a myriad of wonderful tools and services that make it &lt;a href=&#34;https://twitter.com/mrtazz/status/673585181001928704&#34;&gt;so much fun to write and use software&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-readme&#34;&gt;The README&lt;/h3&gt;&#xA;&lt;p&gt;I almost feel like this goes without saying, but you should take some time to write a proper README. It might take 15 or 30 minutes for you to write it. But if 2 other people don&#39;t have to spend 10-20 minutes figuring out how your project is supposed to be used or if it even solves their problem, it has already saved time. The usual things like usage examples and installation instructions should go in there. Plus as you probably know, GitHub shows READMEs very prominently in a nicely rendered way. So your project already feels a lot nicer to use.&lt;/p&gt;&#xA;&lt;p&gt;And while you&#39;re there, also create a &lt;code&gt;CONTRIBUTING.md&lt;/code&gt;. GitHub will show it whenever someone is creating a pull request. So you can put some information in there how you would like to receive contributions which can act as some helpful guidelines and make it a lot less scary and awkward to contribute.&lt;/p&gt;&#xA;&lt;h3 id=&#34;unit-tests-and-code-coverage&#34;&gt;Unit Tests and Code Coverage&lt;/h3&gt;&#xA;&lt;p&gt;It&#39;s &lt;a href=&#34;https://twitter.com/mrtazz/statuses/665167264971415552&#34;&gt;no&lt;/a&gt; &lt;a href=&#34;https://twitter.com/mrtazz/statuses/667097579465875456&#34;&gt;secret&lt;/a&gt; that I&#39;m a fan of writing tests. And it has really become more fun over the last years as frameworks and best practices have improved. In basically all languages there exists now at least one unit testing framework that is easy to use. Some languages even come with one in their standard library. So there is no real reason to not write tests. After all you are already testing your changes manually. Why not have the computer do the tedious work? If you&#39;re looking for some introductory material on testing, we have open sourced our &lt;a href=&#34;https://codeascraft.com/2014/08/20/teaching-testing-our-testing-101-materials/&#34;&gt;Testing 101&lt;/a&gt; material we use at Etsy to teach testing. The point here is not that you will never have bugs in your code because you write tests. You are gonna reduce the number of bugs for sure. But more importantly it provides &lt;em&gt;some&lt;/em&gt; confidence factors for contribution and sets a visible expectation of what things are being automatically tested. Beyond that it provides example code for how to use your code and codifies the intent you had while writing the original functions. It also automatically serves as a first client for your API outside of the intended use case the code was written for. Thus often uncovering a good chunk of design problems.&lt;/p&gt;&#xA;&lt;p&gt;And while you&#39;re at it, add code coverage as well. Coverage is one of those tools that most people either love or hate. But the main point for me is that it sets expectations for which parts of your code are regularly exercised through tests. Not more not less. It&#39;s also not a simple way to make sure you never have bugs. It can&#39;t, as it&#39;s a tool that is concerned with syntax and not semantics of your code. But what it can do is make you think about code paths more explicitly. And through that make you think more about how to test things. And also add instructions about how to run the tests into the &lt;code&gt;CONTRIBUTING.md&lt;/code&gt; file so prospective contributors don&#39;t have to guess or search.&lt;/p&gt;&#xA;&lt;h3 id=&#34;continuous-integration&#34;&gt;Continuous Integration&lt;/h3&gt;&#xA;&lt;p&gt;Once you have tests, the next logical step is to run them on a continuous integration service. I love &lt;a href=&#34;https://travis-ci.org&#34;&gt;Travis CI&lt;/a&gt; for this but there are many others out there. Most services now support GitHub pull request status updates which makes it so much less work to maintain external contributions to your project as you&#39;ll immediately see whether or not the pull request passes tests. But the most important bit about hooking up a CI system to run your tests are the fact that you&#39;ll know it works somewhere else besides your laptop. Plus it gives you a platform to trigger many other useful things (which I will talk about in a bit) after your tests have successfully run. And for that you can even just use the Jenkins setup you probably already have at work or any other CI setup really.&lt;/p&gt;&#xA;&lt;h3 id=&#34;code-style-and-static-analysis&#34;&gt;Code style and Static Analysis&lt;/h3&gt;&#xA;&lt;p&gt;Another thing I really enjoy is the renewed rise of static code analysis tools. And I&#39;ll just throw code style checkers in that same bucket. I&#39;ve met quite a lot of people who hate coding style checkers. The arguments usually go like this: &#34;if you can&#39;t read an if statement with a missing space before the curly brace I don&#39;t want you to write production code anyways&#34;. It&#39;s amazing how many people have strong opinions on things they claim to not matter. The point here is not so much the correct way of writing code but rather a consistent way. Chances are your code is being read by a good number of people, depending on how important/popular it is. Having a consistent style makes it easier to read. Code without style guidelines can be like reading a book where every page was printed in a different font. It doesn&#39;t matter for functionality but it would be a lot more annoying to read. Plus there is literally almost no overhead. Most languages have editor plugins now that will format text for you, some languages even come with tooling. But what it shows is that you care about this code to be readable and accessible. And that you have an easy way of making these coding styles visible and applicable. Static analysis is usually a less contestant topic. There are usually a lot of things that aren&#39;t immediate problems but are helpful fixes. And it&#39;s as well a sign of you caring about the quality of your code.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://codeclimate.com&#34;&gt;Codeclimate&lt;/a&gt; is a wonderful service I use to do this. It has static analysis plugins for a lot of languages and is super easy to set up. It integrates with the Github status API and shows changes for every commit and pull request. That way you can have a computer enforce things like indents, formatting, and problems that a static analyzer can find and you can concentrate on the logic and spirit of the change.&lt;/p&gt;&#xA;&lt;h3 id=&#34;packaging-and-deployment&#34;&gt;Packaging and Deployment&lt;/h3&gt;&#xA;&lt;p&gt;These are topics very dear to my heart. A good packaging and deployment setup makes the user experience of software so much better. Not having to think about where to copy that one file, no need to curlbash some weird script, having things come from the package manager you already use. All those things make it a wonderful experience to get started on a piece of software. And the state of things there also only has gotten better over the years. A lot of the language specific package managers now have nice tooling around creating and uploading install packages for their platform. Some like &lt;a href=&#34;https://packagist.org/&#34;&gt;packagist&lt;/a&gt; even go so far as to just fetch things for you from GitHub and create releases on tags automatically. There is literally no reason to not have your PHP project on there. But even ruby gems and Python modules you can upload easily in an automatic way from your CI system. Travis CI has a whole section on deployments and integrations with most of the popular services. So do other CI platforms. &lt;a href=&#34;https://github.com/jordansissel/fpm&#34;&gt;fpm&lt;/a&gt; has made it ridiculously easy to build packages for Linux. And with &lt;a href=&#34;https://packagecloud.io/&#34;&gt;packagecloud&lt;/a&gt; you can host them in an amazingly accessible and user friendly way. You can even have your packages built and uploaded from your CI system as well with something like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;NAME=&lt;/span&gt;restclient-cpp&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;VERSION&lt;/span&gt; = &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;shell&lt;/span&gt; git describe --tags --always --dirty&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;BUILDER&lt;/span&gt; = &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;shell&lt;/span&gt; echo &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; config user.name&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &amp;lt;&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; config user.email&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-4&#34;&gt;&lt;a href=&#34;#cb1-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;PKG_RELEASE&lt;/span&gt; ?= 1&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-5&#34;&gt;&lt;a href=&#34;#cb1-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;PROJECT_URL=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;https://github.com/mrtazz/&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;NAME&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-6&#34;&gt;&lt;a href=&#34;#cb1-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;FPM_FLAGS=&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;--name&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;NAME&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt; --version &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;VERSION&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt; --iteration &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;PKG_RELEASE&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt; \&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-7&#34;&gt;&lt;a href=&#34;#cb1-7&#34;&gt;&lt;/a&gt;           --epoch 1 --license MIT --maintainer &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;BUILDER&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-8&#34;&gt;&lt;a href=&#34;#cb1-8&#34;&gt;&lt;/a&gt;           &lt;span class=&#34;ex&#34;&gt;--url&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;PROJECT_URL&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt; --vendor mrtazz \&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-9&#34;&gt;&lt;a href=&#34;#cb1-9&#34;&gt;&lt;/a&gt;           --description &lt;span class=&#34;st&#34;&gt;&amp;quot;C++ client for making HTTP/REST requests&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-10&#34;&gt;&lt;a href=&#34;#cb1-10&#34;&gt;&lt;/a&gt;           &lt;span class=&#34;ex&#34;&gt;--depends&lt;/span&gt; curl usr&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-11&#34;&gt;&lt;a href=&#34;#cb1-11&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-12&#34;&gt;&lt;a href=&#34;#cb1-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# build rpm and deb&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-13&#34;&gt;&lt;a href=&#34;#cb1-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;fpm&lt;/span&gt; -t rpm -s dir &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;FPM_FLAGS&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-14&#34;&gt;&lt;a href=&#34;#cb1-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;fpm&lt;/span&gt; -t deb -s dir &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;FPM_FLAGS&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-15&#34;&gt;&lt;a href=&#34;#cb1-15&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-16&#34;&gt;&lt;a href=&#34;#cb1-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# deploy to package cloud&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-17&#34;&gt;&lt;a href=&#34;#cb1-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;package_cloud&lt;/span&gt; push mrtazz/&lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;NAME&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;/el/7 *.rpm&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-18&#34;&gt;&lt;a href=&#34;#cb1-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;package_cloud&lt;/span&gt; push mrtazz/&lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;NAME&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;/debian/wheezy *.deb&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-19&#34;&gt;&lt;a href=&#34;#cb1-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;package_cloud&lt;/span&gt; push mrtazz/&lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;NAME&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;/ubuntu/trusty *.deb&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Or use their integrated &lt;a href=&#34;https://docs.travis-ci.com/user/deployment/packagecloud&#34;&gt;deployment provider&lt;/a&gt; which his even less setup work.&lt;/p&gt;&#xA;&lt;h3 id=&#34;documentation-deploy&#34;&gt;Documentation Deploy&lt;/h3&gt;&#xA;&lt;p&gt;And speaking of automatic build and deploy. The same goes for documentation. One of the most genius features of GitHub in my mind is the fact that every repository can have a &lt;code&gt;gh-pages&lt;/code&gt; branch whose contents are getting published as a website under &lt;code&gt;http://username.github.io/reponame&lt;/code&gt;. This makes it extremely easy to host a documentation page for your project. And with GitHub&#39;s CNAME support you can even have a custom domain for your project point to it. The fact that it&#39;s just another branch in your repository means that you can easily automate the deployment of docs alongside your code for example from (you probably guessed it by now ) your CI system. Thanks to GitHub pages this is as easy as:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# generate docs&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;install&lt;/span&gt; -d docs&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;projecturl: &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;PROJECT_URL&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/_config.yml&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;basesite: http://www.unwiredcouch.com&amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/_config.yml&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;markdown: redcarpet&amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/_config.yml&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-6&#34;&gt;&lt;a href=&#34;#cb2-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;---&amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;&amp;gt;&lt;/span&gt; docs/index.md&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-7&#34;&gt;&lt;a href=&#34;#cb2-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;layout: project&amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/index.md&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-8&#34;&gt;&lt;a href=&#34;#cb2-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;title: &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;NAME&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/index.md&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-9&#34;&gt;&lt;a href=&#34;#cb2-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;---&amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/index.md&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-10&#34;&gt;&lt;a href=&#34;#cb2-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;cat&lt;/span&gt; README.md &lt;span class=&#34;op&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/index.md&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-11&#34;&gt;&lt;a href=&#34;#cb2-11&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-12&#34;&gt;&lt;a href=&#34;#cb2-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# deploy to github&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-13&#34;&gt;&lt;a href=&#34;#cb2-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;cd&lt;/span&gt; docs&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-14&#34;&gt;&lt;a href=&#34;#cb2-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; init&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-15&#34;&gt;&lt;a href=&#34;#cb2-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; remote add upstream &lt;span class=&#34;st&#34;&gt;&amp;quot;https://&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${GH_TOKEN}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;@github.com/mrtazz/&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;NAME&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;.git&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-16&#34;&gt;&lt;a href=&#34;#cb2-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; submodule add https://github.com/mrtazz/jekyll-layouts.git ./_layouts&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-17&#34;&gt;&lt;a href=&#34;#cb2-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; submodule update --init&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-18&#34;&gt;&lt;a href=&#34;#cb2-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; fetch upstream &lt;span class=&#34;kw&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; reset upstream/gh-pages&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-19&#34;&gt;&lt;a href=&#34;#cb2-19&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; config user.name &lt;span class=&#34;st&#34;&gt;&amp;#39;Daniel Schauenberg&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-20&#34;&gt;&lt;a href=&#34;#cb2-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; config user.email d@unwiredcouch.com&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-21&#34;&gt;&lt;a href=&#34;#cb2-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;touch&lt;/span&gt; . &lt;span class=&#34;kw&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; add -A .&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-22&#34;&gt;&lt;a href=&#34;#cb2-22&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; commit -m &lt;span class=&#34;st&#34;&gt;&amp;quot;rebuild pages at &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;ex&#34;&gt;VERSION&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-23&#34;&gt;&lt;a href=&#34;#cb2-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; push -q upstream HEAD:gh-pages&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;If you run this from Travis CI with an encrypted GH_TOKEN environment variable, make sure to suppress command echo-ing for the &lt;code&gt;git remote add&lt;/code&gt; command as it will otherwise write your token to the log in plain text.&lt;/p&gt;&#xA;&lt;p&gt;And even if you just start with publishing your README, you have a nice website in place already to build upon. Maybe add doxygen or other reference generation to it. Add a better getting started guide. Maybe someone else contributes their notes. It&#39;s more likely the easier it is to do. And it makes documentation contributions look more like the first class contribution they are. And less like a nice side addition. Which is something almost every project can benefit from.&lt;/p&gt;&#xA;&lt;h3 id=&#34;build-and-automation&#34;&gt;Build and Automation&lt;/h3&gt;&#xA;&lt;p&gt;With all those wonderful things in place and hooked up, you also want to optimize for the common part of contributing. The local feedback loop. So while it is awesome to have all those services hooked up, it should also be obvious how to run and test them while working on something. This is where build automation via a tool like &lt;code&gt;make&lt;/code&gt; comes into play. If you don&#39;t have to look at your Travis config how to run tests but instead can just run &lt;code&gt;make test&lt;/code&gt; or &lt;code&gt;make coverage&lt;/code&gt; to get coverage information or even &lt;code&gt;make packages&lt;/code&gt; to have debs and rpms build locally it&#39;s a lot more fun to contribute. And it&#39;s not that much more work. When you hook up those things anyways, you can then just run the make commands from your CI system as well. Which also makes it a lot easier to debug if it goes wrong.&lt;/p&gt;&#xA;&lt;h3 id=&#34;show-it-off&#34;&gt;Show it off&lt;/h3&gt;&#xA;&lt;p&gt;And finally please let everyone know that you have all those things in place for your project. Most CI systems and other services now support an HTML embedded badge that shows the build status, code coverage percentage or static analysis results in a little image. It is green when things are ok and red or yellow otherwise. Which lets everyone know the current status of your project immediately when loading the README on GitHub or the website of your project. For everything else there is &lt;a href=&#34;http://shields.io/&#34;&gt;shields.io&lt;/a&gt; which lets you create custom badges via a simple URL structure so you can have the license you use, the location of the packages and other things that are not red/green right up there.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/coding-pride/yagd_badges.png&#34; alt=&#34;yagd badges&#34; /&gt; &lt;img src=&#34;/images/coding-pride/pocketcleaner_badges.png&#34; alt=&#34;pocketcleaner badges&#34; /&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;do-i-really-have-to-do-all-of-this&#34;&gt;Do I really have to do all of this?&lt;/h3&gt;&#xA;&lt;p&gt;I&#39;ve given a lot of examples for things you can or should do to make your project nicer to use. And there are a myriad more, Heroku deploy buttons, npm dependency checkers, slack links, etc. I&#39;ve mostly focused on a very specific set of things I use regularly for my projects. And it&#39;s also very much focused on open source repositories or at least repositories hosted on Github.&lt;/p&gt;&#xA;&lt;p&gt;I&#39;m very aware that not all of these things always apply to or make sense for a project. Some languages don&#39;t have the support of your coverage platform. You want to use another CI service. Your code is hosted in your corporate network and you don&#39;t think you have the time to set all of these things up.&lt;/p&gt;&#xA;&lt;p&gt;The real answer here is to always try to strive for this. A lot of setups can literally be copy and pasted once you&#39;ve done it for one project. And again while all the services mentioned are public ones, there are a lot of integrations you can emulate in house with your existing CI and deployment system and some HTML. If you only do a third of the things I described here your project will already be in much better shape. And people will be more happy to (have to) use your code. Which in my mind is something to be proud of.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2016/01/12/coding-pride.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;If you&#39;re working as a software engineer, you have very likely already heard about &lt;a href=&#34;https</summary>
  </entry>
  <entry>
    <title>My 2015 Reading List</title>
    <updated>2015-12-31T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-12-31:/12/31/reading-list.html</id>
    <content type="html">&lt;p&gt;This year has been really good for reading for me. Starting off from &lt;a href=&#34;https://unwiredcouch.com/2014/12/31/reading-list.html&#34;&gt;last year&#39;s list&lt;/a&gt; and the 5-ish books I read in 2014, I made it to 16 this year. Some of them were very short but nonetheless an improvement. One of my goals for 2015 was to read more and I definitely managed to accomplish that. My goal for 2016 is to read more than 20 books. If you&#39;re interested in keeping up to date over the year, I usually post my progress and reviews on &lt;a href=&#34;https://www.goodreads.com/mrtazz&#34;&gt;Goodreads&lt;/a&gt; as well.&lt;/p&gt;&#xA;&lt;p&gt;So without further ado, here&#39;s my reading list for 2015:&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-whole-womanwhole_woman-by-germaine-greer&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Whole-Woman-Germaine-Greer-ebook/dp/B0026LTNDG&#34;&gt;The Whole Woman&lt;/a&gt; by Germaine Greer&lt;/h3&gt;&#xA;&lt;p&gt;As mentioned &lt;a href=&#34;https://unwiredcouch.com/2014/12/31/reading-list.html&#34;&gt;last year&lt;/a&gt; I started reading this book in 2014 and finished it early 2015. I overall liked it and it was really good in giving me different ways to think about feminism and how the whole system works together to enable sexism and exploitation. It&#39;s also a good resource to understand better how closely related feminism and capitalism really are. However it comes with a really serious trigger warning. Germaine Greer is known to have very transphobic/cissexist views and this book is no exception. It is restricted to one chapter but those opinions - which I don&#39;t share at all - are definitely in there. So if this is a trigger for you, it&#39;s probably better to skip this book.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The pattern of devaluing women&#39;s contribution is as old as human civilization&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;feminism-is-for-everybodyhooks_feminism-by-bell-hooks&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Feminism-Everybody-Passionate-bell-hooks-ebook/dp/B00OCKEF8W&#34;&gt;Feminism is for Everybody&lt;/a&gt; by Bell Hooks&lt;/h3&gt;&#xA;&lt;p&gt;I&#39;ve known about this book for a while now, but up until early 2015 it was only available in print. And since I don&#39;t really like owning physical books and read exclusively on my Kindle and iPhone I hadn&#39;t bought it yet. So when I found out there is a Kindle version now, I immediately bought it. As expected, the book is really good and gives a good primer on feminism and the historical context from the author&#39;s perspective. It reads less extreme to me as Greer which is very much in line with Hooks&#39; other writing. Definitely highly recommended for learning more about feminism.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Feminism is a movement to end sexism, sexist exploitation, and oppression.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;designing-for-performancedfp-by-lara-hogan&#34;&gt;&lt;a href=&#34;http://designingforperformance.com/&#34;&gt;Designing for Performance&lt;/a&gt; by Lara Hogan&lt;/h3&gt;&#xA;&lt;p&gt;My coworker &lt;a href=&#34;https://twitter.com/lara_hogan&#34;&gt;Lara&lt;/a&gt; wrote this book last year and it was a lot of fun watching her process and how she knocked out that book. Since then it was on my list of books to read. Especially since I tend to shy away from frontend things in my day job and want to get better at not doing that. The book is a wonderful introduction into web performance especially from a design view. It gives very solid technical details on a lot of things like browser rendering and image formats that I only had very superficial knowledge of before. I really enjoyed it and the book lead me to &lt;a href=&#34;https://unwiredcouch.com/2015/07/24/frontend-performance.html&#34;&gt;reduce the page weight of this blog by 92%&lt;/a&gt; which was tons of fun to do as well.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The largest hurdle to creating and maintaining stellar site performance is the culture of your organization.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;manage-your-day-to-dayday_to_day-by-jocelyn-glei&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Manage-Your-Day---Day-Creative-ebook/dp/B00B77UE4W&#34;&gt;Manage your Day-to-Day&lt;/a&gt; by Jocelyn Glei&lt;/h3&gt;&#xA;&lt;p&gt;This book sparked my interest while I was looking for improving my daily routines. I was often just starting the day as it happened often leaving me feel disorganized, unproductive, and imbalanced. Reading &#34;Manage your Day-to-Day&#34; gave me a lot of ideas of what things to try and add to my daily routine. And also to try and even have a daily routine. Something I picked up again through this book was journaling and while it has been on and off for the last couple of months I really enjoy it. The book was not mind blowing for me but I enjoyed reading it and definitely would recommend it if you are looking for inspiration for your daily routine.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;It takes willpower to switch off the world, even for an hour.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;leading-snowflakessnowflakes-by-oren-ellenbogen&#34;&gt;&lt;a href=&#34;http://leadingsnowflakes.com/&#34;&gt;Leading Snowflakes&lt;/a&gt; by Oren Ellenbogen&lt;/h3&gt;&#xA;&lt;p&gt;I&#39;ve heard about this book ever since it was released and a lot of people I know speak very highly of it. And they weren&#39;t wrong, I basically devoured the book in a weekend. It&#39;s very well written and has a ton of actionable advice for engineers becoming managers. But I would argue that this description really limits the value of the book. I have no intention to become a manager at the moment however the book was really interesting and helpful for me. I think it&#39;s a great read for anyone looking to grow more into a leadership position.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-highly-sensitive-personhighly_sensitive-by-elaine-n-aron&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Highly-Sensitive-Person-Elaine-Aron-ebook/dp/B00GT1YES8&#34;&gt;The Highly Sensitive Person&lt;/a&gt; by Elaine N. Aron&lt;/h3&gt;&#xA;&lt;p&gt;I had no idea about the concept of highly sensitive people until I read &lt;a href=&#34;http://m.huffpost.com/us/entry/4810794&#34;&gt;this article&lt;/a&gt;. It has a pretty click-baity headline but it really hit home for me. So I decided to learn more about it and this book was the most prominent resource to pop up in my search. It&#39;s a really good book with a lot of great psychological insights and explicit case studies. At times the way high sensitivity was described was a bit too feel-good for my taste. At other times I would almost throw my kindle across the room as the author managed to really sneak up on and hijack my sensitivity. The book focuses a lot on what usually goes wrong during childhood for highly sensitive people and makes it a point to relive memories and traumas through the lense of high sensitivity. This is a practice I really enjoyed although it felt a bit much to me at times as I consider my childhood to have been a happy one. On the other hand I started to do this practice with every day situations at work to help me understand why I feel what I feel in different situations. I identify myself as a highly sensitive person and the book was an extremely good read to help me understand better what this could mean for me and my days.&lt;/p&gt;&#xA;&lt;h3 id=&#34;recoding-genderrecoding_gender-by-janet-abbate&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Recoding-Gender-Changing-Participation-Computing-ebook/dp/B009Z3U46S&#34;&gt;Recoding Gender&lt;/a&gt; by Janet Abbate&lt;/h3&gt;&#xA;&lt;p&gt;I have a very complex relationship with the profession of &#34;software engineering&#34; and how it&#39;s often defined in a non-inclusive way and as the profession of the golden children of society. Part of that is that I had always known a bit about the origins of programming and that a majority of programmers used to be women. But I didn&#39;t know a lot about it which is why I was excited to read this book. And it was great! The book walks you through the beginnings before and during WWII and what programming meant back then. It discusses how the emerging industry in this field changed job prospects and economic chances for women. But it also discusses how the image of a programmer changed as more and more men participated. It&#39;s full of historical facts and documents and a more than wonderful read. It sparked a lot of thoughts for me and changed the way I think about my profession even more.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;the traits that managers found most problematic in programmers were those stereotypically associated with men&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;you-had-me-at-hello-worldhello_world-by-dona-sarkar&#34;&gt;&lt;a href=&#34;http://www.amazon.com/You-Had-Hello-World-Mentoring-ebook/dp/B0147SC2WO&#34;&gt;You had me at &#39;Hello World&#39;&lt;/a&gt; by Dona Sarkar&lt;/h3&gt;&#xA;&lt;p&gt;I found this book through &lt;a href=&#34;https://twitter.com/skamille&#34;&gt;Camille&lt;/a&gt; tweeting about the fact that she was also interviewed for it. &#34;You had me at &#39;Hellow World&#39;&#34; is a collection of interviews with industry leaders from successful companies about the many aspects of leadership and mentoring. It&#39;s a pretty lightweight read and a great resource to get some insight how successful people talk about those topics. It does a great job in conveying how important skills outside of writing code are. And it provides good examples of how to use those for your advantage.&lt;/p&gt;&#xA;&lt;h3 id=&#34;nonviolent-communicationnonviolent_comm-by-marshall-b-rosenberg&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Nonviolent-Communication-Language-Life-Changing-Relationships-ebook/dp/B014OISVU4&#34;&gt;Nonviolent Communication&lt;/a&gt; by Marshall B. Rosenberg&lt;/h3&gt;&#xA;&lt;p&gt;This has been recommended by many people I work with as a wonderful resource about positive human communication. And as - especially in a growing engineering org - communication is one of the most important skills to try to master, I decided to finally read this one. It&#39;s a very interesting book with an approach to communication that is rarely taught especially not to men. It focuses on a collaborative rather than a competitive style of communication and the goal to reach agreements over winning arguments. The examples in the book are often pretty extreme coming from the author&#39;s work as a diplomat. And even though those are great to demonstrate how this way of communicating can work in the most extreme cases, it also shifts its focus a lot on explicit diplomatic style discussions. There are more examples that are more directed towards every day situations and even though the author is very explicit about this being useful in regular work meetings as well, I had a very hard time understanding how to practically apply those lessons in a meeting for example. That being said however it made me think a lot more about the way I communicate and what I&#39;m saying versus what I want to say. I have also applied that way of communicating successfully at least once since reading the book. And I look forward to try it out more.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-retrospective-handbookretrospective-by-patrick-kua&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Retrospective-Handbook-guide-agile-teams-ebook/dp/B00916BRVU&#34;&gt;The Retrospective Handbook&lt;/a&gt; by Patrick Kua&lt;/h3&gt;&#xA;&lt;p&gt;At work we have a group of people which I&#39;m part of that work on making sure we have good frameworks in place for blameless postmortems and organizational learning as a whole. Part of that is moving past only investigating failure (via postmortems) and also look into investigating successes (via retrospectives). So in a similar way to how I&#39;ve spent time understanding the unhelpful concept of human error, I wanted to learn more about the theoretical concepts of successful retrospectives. Unfortunately this was completely the wrong book for this. It is a great and very practical read for retrospectives in the agile sense and how to run successful meetings in general. However I wasn&#39;t looking for that so I constantly kept thinking when we are going to dive into the meaty, theoretical stuff. This is in no way the authors fault and I would highly recommend the book as inspiration for improving your meetings. But for the theoretical underpinnings of retrospectives as an organizational learning tool I&#39;m still on the lookout. Let me know if you have recommendations :).&lt;/p&gt;&#xA;&lt;h3 id=&#34;cybersexism-sex-gender-and-power-on-the-internetcybersexism-by-laurie-penny&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Cybersexism-Sex-Gender-Power-Internet-ebook/dp/B00EO24J3O&#34;&gt;Cybersexism: Sex, Gender and Power on the Internet&lt;/a&gt; by Laurie Penny&lt;/h3&gt;&#xA;&lt;p&gt;This short book by Laurie Penny is a very good read about sexism in the age of social networks and the omnipresent Internet. It does a great job at talking about how a lot of familiar concepts of &#34;offline sexism&#34; are reinvented online and no news to women. It&#39;s short and insightful enough to recommend reading it without hesitation.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Perhaps one reason that women writers and technologists have, so far, the calmest and most comprehensive understanding of what surveillance technology really does to the human condition is that women grow up being watched.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;the-boy-kingsboy_kings-by-katherine-losse&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Boy-Kings-Journey-Social-Network-ebook/dp/B007MAXH38&#34;&gt;The Boy Kings&lt;/a&gt; by Katherine Losse&lt;/h3&gt;&#xA;&lt;p&gt;The biography of Kate Losse about her time at (earl stage) Facebook is in my mind a must read for any software engineer and especially if you&#39;re a man. It gives an extremely good insight view into what happens when young men are suddenly in charge of a ton of money. But more importantly it talks very bluntly about how engineers are treated differently from most other employees for our supposed gift to turn any idea into gold with code.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Technology carries with it all the biases of the people who make it, so simply making the world more technical was not going to save us.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;the-art-of-mindfulnessmindfulness-by-thích-nhất-hạnh&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Art-Mindfulness-HarperOne-Select-Selects-ebook/dp/B005HG4H24&#34;&gt;The Art of Mindfulness&lt;/a&gt; by Thích Nhất Hạnh&lt;/h3&gt;&#xA;&lt;p&gt;This is another super short read and the de-facto introductory book to mindfulness meditation. There&#39;s not a lot to say here. It&#39;s good, give it a read as it&#39;s short enough to not matter if you end up not liking it. I started meditating regularly after reading it and it has been a great experience.&lt;/p&gt;&#xA;&lt;h3 id=&#34;men-explain-things-to-memen_explain-by-rebecca-solnit&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Men-Explain-Things-Rebecca-Solnit-ebook/dp/B00IWGQ8PU&#34;&gt;Men Explain Things to Me&lt;/a&gt; by Rebecca Solnit&lt;/h3&gt;&#xA;&lt;p&gt;This collection of essays titled for the aggressive tendency of men to always have to explain things to women while assuming they have no idea what they are talking about. The first essay brings this to a point by telling a story of a party where a man mansplains to the author the book she herself wrote. Without having actually read it. The book than continues with more essays that talk about a lot more darker things like discussing domestic violence. The over arching theme is that the credibility of and respect towards women is continuously diminished to maintain the status quo and its power imbalance. Some of the essays towards the end of the book are not easy to read but it&#39;s more than worth it.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Credibility is a basic survival tool.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;dont-make-me-thinkdont_make_think-by-steve-krug&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Dont-Make-Think-Revisited-Usability-ebook/dp/B00HJUBRPG&#34;&gt;Don&#39;t Make Me Think&lt;/a&gt; by Steve Krug&lt;/h3&gt;&#xA;&lt;p&gt;I&#39;m one of those engineers who used to happily claim to not have any frontend skills and just not be good at design. I came to loathe this thinking over the years and decided that if I can&#39;t do something I want to learn at least the basics. This is one of the reasons why I read &#34;Designing for Performance&#34; as mentioned above. Thankfully I also work with a ton of talented designers and one of them is &lt;a href=&#34;https://twitter.com/harllee&#34;&gt;Jessica Harllee&lt;/a&gt;. I talked to her about suggestions to get started with learning about design. And she said I should read &#34;Don&#39;t make me think&#34;. And she wasn&#39;t wrong. The book is a wonderful introduction into usability and design. The beauty of it is that while reading it, all of the things mentioned are total no-brainers. But you have to remember it while designing things. The other interesting thing for me was that while all of the examples in the book are web based (with some brief stints into mobile) I could totally think of CLI apps I&#39;ve written in the past that totally do the wrong thing design-wise. Definitely a recommended read.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-internet-of-garbageinternet_garbage-by-sarah-jeong&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Internet-Garbage-Sarah-Jeong-ebook/dp/B011JAV030&#34;&gt;The Internet of Garbage&lt;/a&gt; by Sarah Jeong&lt;/h3&gt;&#xA;&lt;p&gt;In this book Sarah Jeong - a journalist trained as a lawyer at Harvard Law School - talks about the problem of online harassment. It&#39;s another short but really good one. I&#39;ve learned a ton about copyright law and the limitations of current legislation when it comes to online harassment. But also things that do work and what things could be attempted. It&#39;s a very sobering look at the current state of social networks, online harassment and tooling and legislation to help fight it. Definitely worth a read if you spend any time on the internet.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/12/31/reading-list.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This year has been really good for reading for me. Starting off from &lt;a href=&#34;https://unwiredcouc</summary>
  </entry>
  <entry>
    <title>Chef Driven Graphite Dashboards</title>
    <updated>2015-12-17T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-12-17:/12/17/chef-driven-dashboards.html</id>
    <content type="html">&lt;p&gt;Some years ago &lt;a href=&#34;https://unwiredcouch.com/2012/09/15/getting-started-with-monitoring.html&#34;&gt;I wrote about&lt;/a&gt; how to use Heroku and a set of hosted solutions for getting started with monitoring for your personal infrastructure. I used this set up for quite a while and I learned a ton setting it up. But after a while things were chugging along and I was paying for things I wasn&#39;t using. So I decided to self host my monitoring on the infrastructure I was already running anyways. The big switches were using Nagios instead of Sensu (as I was familiar with it and it has less moving parts), dropping chat integration and log aggregation as I was barely using it and switching to Graphite for graphs. Interestingly enough this switch made me improve my graphing setup a lot. I&#39;m still using collectd and I&#39;ve extended it a lot more with custom scripts to track various things.&lt;/p&gt;&#xA;&lt;h2 id=&#34;yet-another-graphite-dashboard&#34;&gt;Yet Another Graphite Dashboard&lt;/h2&gt;&#xA;&lt;p&gt;However since I wasn&#39;t using Librato anymore, I now had to find a way to get nice overview dashboards for all of my metrics. And I looked into the usual suspects. But all of them seemed to need a very elaborate setup and running an additional application server besides &lt;code&gt;mod_php&lt;/code&gt; which I was already running for Nagios just for some graphs embedded on an HTML page didn&#39;t seem like a thing I wanted to embark on. I always liked the way we approach &lt;a href=&#34;https://github.com/etsy/dashboard&#34;&gt;dashboards at Etsy&lt;/a&gt; a lot. It&#39;s basically a PHP framework that gives you a nice way to create graphs from Graphite or Ganglia and combine them into dashboards. However it was a bit overkill for my use case and I would have to write all the code for a typical collectd host anyways. So I wrote my own little PHP script to generate a list of graphs from a config file. And it was really nice, took me 20 minutes, was a lot of fun, and did everything I wanted it to do. I decided to just use Twitter Bootstrap for the UI, which means it also looks nice on my iPhone and it&#39;s aptly named &lt;a href=&#34;http://code.mrtazz.com/yagd/&#34;&gt;Yet Another Graphite Dashboard&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;chef-integration-and-additional-metrics&#34;&gt;Chef integration and additional metrics&lt;/h2&gt;&#xA;&lt;p&gt;Now that I had this nice way of viewing dashboards, I wanted to have more graphs. I have long made a choice to track as much as possible in Chef for my personal infrastructure. And graphing is no exception here. Setting up the initial collectd install is a bit manual as I depend on some options that are available in the ports but not the official package builds (my infrastructure is still all FreeBSD). But the configuration and graphing additions are all fully chef-ed. I took the way we have Ganglia set up at Etsy as the role model. We have a setup chef-ed to every box that runs all scripts prefixed with &lt;code&gt;gmetric-&lt;/code&gt; in a certain location on a minutely cron. This means in order to get a new set of metrics, you just have to write a shell script that ends up calling &lt;code&gt;gmetric&lt;/code&gt; and put it in Chef. And a couple of minutes later graphs for all boxes will magically appear in Ganglia. I did the same for my collectd setup via &lt;code&gt;collectdctl&lt;/code&gt; and it looks a little bit like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;*&lt;/span&gt; * * * * for SCRIPT in &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;ls&lt;/span&gt; /usr/local/collectd/collectd-*&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt; &lt;span class=&#34;bu&#34;&gt;command&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${SCRIPT}&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;done&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This means I can now easily add new metrics by dropping a script in there that utilizes the collectd CLI tooling. However since collectd has a very specific type setup, each script also needs a corresponding configuration in a custom types db. I also track this in Chef so it&#39;s not too big of a problem. An example script to track disk temperature looks like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#!/bin/sh&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;PLUGIN_NAME=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;disktemp&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;HOSTNAME=$(&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;hostname&lt;/span&gt; -f&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;SMARTCMD=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;/usr/local/sbin/smartctl&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-6&#34;&gt;&lt;a href=&#34;#cb2-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;COLLECTD=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;/usr/local/bin/collectdctl&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-7&#34;&gt;&lt;a href=&#34;#cb2-7&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-8&#34;&gt;&lt;a href=&#34;#cb2-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;disk&lt;/span&gt; in &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;ls&lt;/span&gt; /dev/ada* &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;grep&lt;/span&gt; -o &lt;span class=&#34;st&#34;&gt;&amp;quot;ada[0-9]$&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-9&#34;&gt;&lt;a href=&#34;#cb2-9&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;va&#34;&gt;TEMP=$(${SMARTCMD}&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;-a&lt;/span&gt; /dev/&lt;span class=&#34;va&#34;&gt;${disk}&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;awk&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;/194 Temperature_Celsius/ {print $10}&amp;#39;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-10&#34;&gt;&lt;a href=&#34;#cb2-10&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;va&#34;&gt;${COLLECTD}&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;putval&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${HOSTNAME}&lt;/span&gt;/&lt;span class=&#34;va&#34;&gt;${PLUGIN_NAME}&lt;/span&gt;-&lt;span class=&#34;va&#34;&gt;${disk}&lt;/span&gt;/celsius_current interval=60 N:&lt;span class=&#34;va&#34;&gt;${TEMP}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-11&#34;&gt;&lt;a href=&#34;#cb2-11&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-12&#34;&gt;&lt;a href=&#34;#cb2-12&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$?&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;!=&lt;/span&gt; 0&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-13&#34;&gt;&lt;a href=&#34;#cb2-13&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;ERROR &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${0}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;: &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${HOSTNAME}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${PLUGIN_NAME}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${disk}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/celsius_current interval=60 N:&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${TEMP}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-14&#34;&gt;&lt;a href=&#34;#cb2-14&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-15&#34;&gt;&lt;a href=&#34;#cb2-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;done&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Another thing that Ganglia gives you for free is a section for additional metrics that just appear as soon as you send them with an optional group name to group them by. In order to emulate that in my setup, the recipes for each collectd script are also defining node attributes with the Graphite graphs they are generating and how they are supposed to be displayed. This made a lot of sense to me as when I&#39;m writing the scripts I have the generated metrics in my head anyways. And it&#39;s easy to just drop them in a node attribute. So for tracking disk temperature for example, the recipe looks a bit like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode ruby&#34;&gt;&lt;code class=&#34;sourceCode ruby&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34;&gt;&lt;/a&gt;cookbook_file &lt;span class=&#34;st&#34;&gt;&amp;quot;/usr/local/collectd/collectd-disk-temp.sh&amp;quot;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34;&gt;&lt;/a&gt;  source &lt;span class=&#34;st&#34;&gt;&amp;quot;collectd-disk-temp.sh&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34;&gt;&lt;/a&gt;  owner &lt;span class=&#34;st&#34;&gt;&amp;quot;root&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34;&gt;&lt;/a&gt;  group &lt;span class=&#34;st&#34;&gt;&amp;quot;wheel&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34;&gt;&lt;/a&gt;  mode &lt;span class=&#34;bn&#34;&gt;0755&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-6&#34;&gt;&lt;a href=&#34;#cb3-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;end&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-7&#34;&gt;&lt;a href=&#34;#cb3-7&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-8&#34;&gt;&lt;a href=&#34;#cb3-8&#34;&gt;&lt;/a&gt;node.default[&lt;span class=&#34;st&#34;&gt;:yagd&lt;/span&gt;][&lt;span class=&#34;st&#34;&gt;:additional_metrics&lt;/span&gt;][&lt;span class=&#34;st&#34;&gt;:disk_temperature&lt;/span&gt;] = {&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-9&#34;&gt;&lt;a href=&#34;#cb3-9&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&amp;quot;Disk Temperature&amp;quot;&lt;/span&gt; =&amp;gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;collectd.&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;node[&lt;span class=&#34;st&#34;&gt;:fqdn&lt;/span&gt;].gsub(&lt;span class=&#34;st&#34;&gt;&amp;quot;.&amp;quot;&lt;/span&gt;,&lt;span class=&#34;st&#34;&gt;&amp;quot;_&amp;quot;&lt;/span&gt;)&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;.disktemp-ada*.celsius_current&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-10&#34;&gt;&lt;a href=&#34;#cb3-10&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;The next step was now to not have to manually edit the config file for my dashboards anymore. I now had all the data I needed in Chef, so all it took was generating the config file there from a Chef search and all graphs were magically appearing as soon as both the node to monitor and the dashboard host had run Chef. This can take up to 20 minutes worst case (I run Chef every 10 minutes) which is really not a big deal for me. The Chef search code that does this for me looks like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode ruby&#34;&gt;&lt;code class=&#34;sourceCode ruby&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34;&gt;&lt;/a&gt;hosts = []&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34;&gt;&lt;/a&gt;nodes = search(&lt;span class=&#34;st&#34;&gt;:node&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&amp;quot;domain:*unwiredcouch.com&amp;quot;&lt;/span&gt;)&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34;&gt;&lt;/a&gt;nodes.each &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt; |computer|&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-5&#34;&gt;&lt;a href=&#34;#cb4-5&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-6&#34;&gt;&lt;a href=&#34;#cb4-6&#34;&gt;&lt;/a&gt;  this_computer = {}&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-7&#34;&gt;&lt;a href=&#34;#cb4-7&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-8&#34;&gt;&lt;a href=&#34;#cb4-8&#34;&gt;&lt;/a&gt;  this_computer[&lt;span class=&#34;st&#34;&gt;:name&lt;/span&gt;] = computer[&lt;span class=&#34;st&#34;&gt;:fqdn&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-9&#34;&gt;&lt;a href=&#34;#cb4-9&#34;&gt;&lt;/a&gt;  this_computer[&lt;span class=&#34;st&#34;&gt;:cpus&lt;/span&gt;] = computer[&lt;span class=&#34;st&#34;&gt;:cpu&lt;/span&gt;].nil? ? &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt; : computer[&lt;span class=&#34;st&#34;&gt;:cpu&lt;/span&gt;][&lt;span class=&#34;st&#34;&gt;:total&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-10&#34;&gt;&lt;a href=&#34;#cb4-10&#34;&gt;&lt;/a&gt;  this_computer[&lt;span class=&#34;st&#34;&gt;:apache&lt;/span&gt;] = computer.recipes.include?(&lt;span class=&#34;st&#34;&gt;&amp;quot;apache&amp;quot;&lt;/span&gt;)&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-11&#34;&gt;&lt;a href=&#34;#cb4-11&#34;&gt;&lt;/a&gt;  this_computer[&lt;span class=&#34;st&#34;&gt;:interfaces&lt;/span&gt;] = computer.network.interfaces.keys.select {|k| !k.to_s.start_with?&lt;span class=&#34;st&#34;&gt;&amp;quot;lo&amp;quot;&lt;/span&gt; }&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-12&#34;&gt;&lt;a href=&#34;#cb4-12&#34;&gt;&lt;/a&gt;  this_computer[&lt;span class=&#34;st&#34;&gt;:filesystems&lt;/span&gt;] = []&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-13&#34;&gt;&lt;a href=&#34;#cb4-13&#34;&gt;&lt;/a&gt;  computer.filesystem.each &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt; |k,v|&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-14&#34;&gt;&lt;a href=&#34;#cb4-14&#34;&gt;&lt;/a&gt;    name = v[&lt;span class=&#34;st&#34;&gt;:mount&lt;/span&gt;] == &lt;span class=&#34;st&#34;&gt;&amp;quot;/&amp;quot;&lt;/span&gt; ? &lt;span class=&#34;st&#34;&gt;&amp;quot;/root&amp;quot;&lt;/span&gt; : v[&lt;span class=&#34;st&#34;&gt;:mount&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-15&#34;&gt;&lt;a href=&#34;#cb4-15&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;co&#34;&gt;# cut out leading &amp;#39;/&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-16&#34;&gt;&lt;a href=&#34;#cb4-16&#34;&gt;&lt;/a&gt;    name[&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;] = &lt;span class=&#34;st&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-17&#34;&gt;&lt;a href=&#34;#cb4-17&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;co&#34;&gt;# substitute &amp;#39;/&amp;#39; with &amp;#39;-&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-18&#34;&gt;&lt;a href=&#34;#cb4-18&#34;&gt;&lt;/a&gt;    name.gsub!(&lt;span class=&#34;st&#34;&gt;&amp;quot;/&amp;quot;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&amp;quot;-&amp;quot;&lt;/span&gt;)&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-19&#34;&gt;&lt;a href=&#34;#cb4-19&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;co&#34;&gt;# substitute &amp;#39;.&amp;#39; with &amp;#39;_&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-20&#34;&gt;&lt;a href=&#34;#cb4-20&#34;&gt;&lt;/a&gt;    name.gsub!(&lt;span class=&#34;st&#34;&gt;&amp;quot;.&amp;quot;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&amp;quot;_&amp;quot;&lt;/span&gt;)&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-21&#34;&gt;&lt;a href=&#34;#cb4-21&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;co&#34;&gt;# and add to array&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-22&#34;&gt;&lt;a href=&#34;#cb4-22&#34;&gt;&lt;/a&gt;    this_computer[&lt;span class=&#34;st&#34;&gt;:filesystems&lt;/span&gt;] &amp;lt;&amp;lt; name&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-23&#34;&gt;&lt;a href=&#34;#cb4-23&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;end&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-24&#34;&gt;&lt;a href=&#34;#cb4-24&#34;&gt;&lt;/a&gt;  this_computer[&lt;span class=&#34;st&#34;&gt;:additional_metrics&lt;/span&gt;] = computer[&lt;span class=&#34;st&#34;&gt;:yagd&lt;/span&gt;][&lt;span class=&#34;st&#34;&gt;:additional_metrics&lt;/span&gt;] &lt;span class=&#34;kw&#34;&gt;unless&lt;/span&gt; computer[&lt;span class=&#34;st&#34;&gt;:yagd&lt;/span&gt;].nil?&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-25&#34;&gt;&lt;a href=&#34;#cb4-25&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-26&#34;&gt;&lt;a href=&#34;#cb4-26&#34;&gt;&lt;/a&gt;  hosts &amp;lt;&amp;lt; this_computer&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-27&#34;&gt;&lt;a href=&#34;#cb4-27&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-28&#34;&gt;&lt;a href=&#34;#cb4-28&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;end&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-29&#34;&gt;&lt;a href=&#34;#cb4-29&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-30&#34;&gt;&lt;a href=&#34;#cb4-30&#34;&gt;&lt;/a&gt;template &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;dashboards_dir&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/config.php&amp;quot;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-31&#34;&gt;&lt;a href=&#34;#cb4-31&#34;&gt;&lt;/a&gt;  source &lt;span class=&#34;st&#34;&gt;&amp;quot;yagd.config.php.erb&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-32&#34;&gt;&lt;a href=&#34;#cb4-32&#34;&gt;&lt;/a&gt;  owner &lt;span class=&#34;st&#34;&gt;&amp;quot;www&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-33&#34;&gt;&lt;a href=&#34;#cb4-33&#34;&gt;&lt;/a&gt;  group &lt;span class=&#34;st&#34;&gt;&amp;quot;wheel&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-34&#34;&gt;&lt;a href=&#34;#cb4-34&#34;&gt;&lt;/a&gt;  mode &lt;span class=&#34;bn&#34;&gt;0775&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-35&#34;&gt;&lt;a href=&#34;#cb4-35&#34;&gt;&lt;/a&gt;  variables( &lt;span class=&#34;st&#34;&gt;:hosts&lt;/span&gt; =&amp;gt; hosts )&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-36&#34;&gt;&lt;a href=&#34;#cb4-36&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;end&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;And this is the accompanying erb template that gets rendered into a PHP file to serve as the configuration for my dashboards instance.&lt;/p&gt;&#xA;&lt;pre class=&#34;erb&#34;&gt;&lt;code&gt;&amp;lt;?php&#xA;&#xA;$CONFIG = array(&#xA;    &amp;#39;title&amp;#39; =&amp;gt; &amp;quot;dashboards&amp;quot;,&#xA;    &amp;#39;navitems&amp;#39; =&amp;gt; [&#xA;        &amp;#39;Hosts&amp;#39; =&amp;gt; &amp;#39;/hosts.php&amp;#39;,&#xA;        &amp;#39;Graphite&amp;#39; =&amp;gt; &amp;#39;/graphite.php&amp;#39;,&#xA;        &amp;#39;Twitter&amp;#39; =&amp;gt; &amp;#39;/tweets.php&amp;#39;&#xA;    ],&#xA;    &amp;#39;graphite&amp;#39; =&amp;gt; [&#xA;      &amp;#39;host&amp;#39; =&amp;gt; &amp;quot;https://graphite.example.com&amp;quot;,&#xA;      &amp;#39;hidelegend&amp;#39; =&amp;gt; false&#xA;    ],&#xA;    &amp;#39;hosts&amp;#39; =&amp;gt; array(&#xA;      &amp;lt;% @hosts.each do |host| %&amp;gt;&#xA;       &amp;quot;&amp;lt;%= host[:name] %&amp;gt;&amp;quot; =&amp;gt; array(&#xA;         &amp;quot;cpus&amp;quot; =&amp;gt; &amp;lt;%= host[:cpus] %&amp;gt;,&#xA;         &amp;quot;apache&amp;quot; =&amp;gt; &amp;lt;%= host[:apache] %&amp;gt;,&#xA;         &amp;quot;interfaces&amp;quot; =&amp;gt; &amp;lt;%= host[:interfaces].to_json %&amp;gt;,&#xA;         &amp;quot;filesystems&amp;quot; =&amp;gt; &amp;lt;%= host[:filesystems].to_json %&amp;gt;,&#xA;         &amp;quot;additional_metrics&amp;quot; =&amp;gt; [&#xA;           &amp;lt;% host[:additional_metrics].each do |name,values| %&amp;gt;&#xA;           &amp;quot;&amp;lt;%= name %&amp;gt;&amp;quot; =&amp;gt; [&#xA;             &amp;lt;% values.each do |title,metric| %&amp;gt;&#xA;               &amp;quot;&amp;lt;%= title %&amp;gt;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;%= metric %&amp;gt;&amp;quot;,&#xA;             &amp;lt;% end %&amp;gt;&#xA;           ],&#xA;           &amp;lt;% end %&amp;gt;&#xA;         ]&#xA;       ),&#xA;    &amp;lt;% end %&amp;gt;&#xA;    )&#xA;);&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2 id=&#34;the-cleanup&#34;&gt;The Cleanup&lt;/h2&gt;&#xA;&lt;p&gt;After all of this configuration, my dashboard setup was working beautifully and I added more and more graphs I was interested in. But it was still more or less the 20 minute PHP code I had initially thrown together. This was technically fine and I didn&#39;t mind it too much. But at the same time I thought it might be nice to bring it in a state where it&#39;s usable for others. So I decided to take some time to clean it up and make it more generically usable. So I refactored the code, added unit tests to run on &lt;a href=&#34;https://travis-ci.org/mrtazz/yagd&#34;&gt;Travis CI&lt;/a&gt; and hooked it up to &lt;a href=&#34;https://codeclimate.com/github/mrtazz/yagd/&#34;&gt;Code Climate&lt;/a&gt; so I could have a computer tell me how I can improve the code quality.&lt;/p&gt;&#xA;&lt;p&gt;With this refactor in place it&#39;s now fairly easy to get a dashboard page that shows the status of all hosts:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode php&#34;&gt;&lt;code class=&#34;sourceCode php&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;&amp;lt;?php&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-2&#34;&gt;&lt;a href=&#34;#cb6-2&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-3&#34;&gt;&lt;a href=&#34;#cb6-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;require&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;__DIR__&lt;/span&gt; . &lt;span class=&#34;st&#34;&gt;&amp;#39;/../vendor/autoload.php&amp;#39;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-4&#34;&gt;&lt;a href=&#34;#cb6-4&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-5&#34;&gt;&lt;a href=&#34;#cb6-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;include_once&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;../config.php&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;);&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-6&#34;&gt;&lt;a href=&#34;#cb6-6&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-7&#34;&gt;&lt;a href=&#34;#cb6-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;use&lt;/span&gt; Yagd\CollectdHost&lt;span class=&#34;ot&#34;&gt;;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-8&#34;&gt;&lt;a href=&#34;#cb6-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;use&lt;/span&gt; Yagd\Page&lt;span class=&#34;ot&#34;&gt;;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-9&#34;&gt;&lt;a href=&#34;#cb6-9&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-10&#34;&gt;&lt;a href=&#34;#cb6-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;$page&lt;/span&gt; = &lt;span class=&#34;kw&#34;&gt;new&lt;/span&gt; Page&lt;span class=&#34;ot&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;$CONFIG&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;);&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-11&#34;&gt;&lt;a href=&#34;#cb6-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;$page&lt;/span&gt;-&amp;gt;getHeader&lt;span class=&#34;ot&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;$CONFIG&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;title&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;],&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-12&#34;&gt;&lt;a href=&#34;#cb6-12&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;kw&#34;&gt;$CONFIG&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;navitems&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;]);&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-13&#34;&gt;&lt;a href=&#34;#cb6-13&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-14&#34;&gt;&lt;a href=&#34;#cb6-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;$CONFIG&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;hosts&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;$host&lt;/span&gt; =&amp;gt; &lt;span class=&#34;kw&#34;&gt;$data&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;)&lt;/span&gt; {&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-15&#34;&gt;&lt;a href=&#34;#cb6-15&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-16&#34;&gt;&lt;a href=&#34;#cb6-16&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;kw&#34;&gt;$fss&lt;/span&gt; = &lt;span class=&#34;kw&#34;&gt;empty&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;$data&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;filesystems&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;?&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;$data&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;filesystems&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;];&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-17&#34;&gt;&lt;a href=&#34;#cb6-17&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-18&#34;&gt;&lt;a href=&#34;#cb6-18&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;kw&#34;&gt;$server&lt;/span&gt; = &lt;span class=&#34;kw&#34;&gt;new&lt;/span&gt; CollectdHost&lt;span class=&#34;ot&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;$host&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;$data&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;cpus&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;$fss&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-19&#34;&gt;&lt;a href=&#34;#cb6-19&#34;&gt;&lt;/a&gt;                               &lt;span class=&#34;kw&#34;&gt;$data&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;interfaces&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;]);&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-20&#34;&gt;&lt;a href=&#34;#cb6-20&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;kw&#34;&gt;$server&lt;/span&gt;-&amp;gt;setGraphiteConfiguration&lt;span class=&#34;ot&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;$CONFIG&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;graphite&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;host&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;]);&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-21&#34;&gt;&lt;a href=&#34;#cb6-21&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;kw&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&amp;lt;h2&amp;gt; &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;{$host}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; &amp;lt;/h2&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-22&#34;&gt;&lt;a href=&#34;#cb6-22&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;kw&#34;&gt;$server&lt;/span&gt;-&amp;gt;render&lt;span class=&#34;ot&#34;&gt;();&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-23&#34;&gt;&lt;a href=&#34;#cb6-23&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-24&#34;&gt;&lt;a href=&#34;#cb6-24&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-25&#34;&gt;&lt;a href=&#34;#cb6-25&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;$page&lt;/span&gt;-&amp;gt;getFooter&lt;span class=&#34;ot&#34;&gt;();&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;You can also &lt;a href=&#34;https://github.com/mrtazz/yagd#inject-a-select-box-into-the-navbar&#34;&gt;inject a selectbox&lt;/a&gt; into the header to have it be possible to just select a single server instead of always displaying all of them. This makes it really nice to be able to just browse to something like &lt;code&gt;https://yagd.example.com/hosts.php?hostname=foo.example.com&lt;/code&gt; and get a quick overview of how that that host is doing. Plus it gives you a URL you can link to from anywhere else.&lt;/p&gt;&#xA;&lt;p&gt;Also since this is just plain PHP, entirely driven by the config file, it&#39;s possible to have a per cluster view by passing a URL parameter like &lt;code&gt;?cluster=name&lt;/code&gt; and then changing the &lt;code&gt;include_once()&lt;/code&gt; code in that example to include a different config file based on that. And since Chef already knows or can know all that data (maybe each cluster is its own role? ), it&#39;s just a matter of writing some ruby to generate different sets of config files for the dashboards.&lt;/p&gt;&#xA;&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;Writing yagd has been a lot of fun. The initial version took - as I already said - about 20 minutes to write and I learned a ton of things while refactoring it into a usable PHP module. You can install it via composer &lt;a href=&#34;https://packagist.org/packages/mrtazz/yagd&#34;&gt;from packagist&lt;/a&gt; if you want to try it out and use it for your own dasboards.&lt;/p&gt;&#xA;&lt;p&gt;However the point of this is not so much that I wrote yet another dashboard framework, but rather how easy it was to get this going. Sure it&#39;s not super trivial to get your infrastructure into Chef if it&#39;s not. And it also takes some time to install Graphite if you aren&#39;t familiar with it. But with those things in place, you have all the building blocks to quickly whip up a nice dashboarding solution with some simple PHP.&lt;/p&gt;&#xA;&lt;p&gt;As much as I love how many frameworks and libraries there are to already solve those problems for us, I think it&#39;s a good practice to occasionally go back to the basics and think about what the simplest solution is I actually need. In my case this was showing graphs on an HTML page in a somewhat structured way. I didn&#39;t need anything more fancy. And there was no reason to try and find the dashboard solution that would do that, preferably in PHP so I don&#39;t have to set up yet another application server, which most likely solved way more problems that I actually had.&lt;/p&gt;&#xA;&lt;p&gt;If you want to give &lt;a href=&#34;http://code.mrtazz.com/yagd/&#34;&gt;yagd&lt;/a&gt; a try, I would love to hear what you think. I currently track 4 servers and 2 jails with it, but for this and other reasons it won&#39;t be the solution to all dashboarding problems. Nor should it. The way more important thing in my mind is that it&#39;s solving a very specific problem I had, in a pretty simple way. And in addition served as a side project for me to learn a lot of things about writing PHP, setting up phpunit, using codeclimate, and creating a reusable package on Packagist I didn&#39;t know before.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/12/17/chef-driven-dashboards.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Some years ago &lt;a href=&#34;https://unwiredcouch.com/2012/09/15/getting-started-with-monitoring.html&#34;</summary>
  </entry>
  <entry>
    <title>Timeouts And Reflections</title>
    <updated>2015-11-20T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-11-20:/11/20/timeouts-reflections.html</id>
    <content type="html">&lt;p&gt;I love &lt;a href=&#34;https://unwiredcouch.com/setup/coffee/&#34;&gt;coffee&lt;/a&gt;. I really do. And yet I haven&#39;t had any for 4 days now. The first day was rough, I got the headaches that everybody will tell you about when it comes to the topic of caffeine withdrawal symptoms. The second day was better and by the third, the headaches were gone. And I&#39;m just halfway done. I&#39;m not gonna drink coffee for a couple more days. It&#39;s part of a yearly ritual I have of not drinking any coffee for at least a week or so. Last year the headaches didn&#39;t disappear until day 5 so I decided to go for 10 days without coffee instead of 7. And after the headaches disappear, the fun part starts: trying to figure out how to replace something so integral of my life. What to drink for breakfast now? What to do instead of going to the coffee shop?&lt;/p&gt;&#xA;&lt;p&gt;So why is this important? Everybody does not drink coffee at some point, right? It&#39;s important because it&#39;s part of something I&#39;ve tried to continuously include more and more in my life over the years. Taking timeouts and making time for reflections. Humans tend to be creatures of habit. If you want to achieve something that needs constant work, build a habit out of it. You want to read more books? Spend 30 minutes every morning with just reading. You want to lose weight? Have a strict habit of going to the gym every Monday, Wednesday, and Friday. Want to learn a language? Start memorizing words every day on your commute. If you search Google for &#34;building habits&#34; you will find a myriad of websites, articles, and tutorials of how to hack your life and yourself into a more productive version by making things a routine. And it&#39;s true, building habits is a very effective way of incorporating new things into your daily life.&lt;/p&gt;&#xA;&lt;p&gt;However the same also goes for negative habits. Smoking, drinking a beer every day after work, eating too much unhealthy food, constantly immersing oneself in the stressful routines at work, not going to the gym because the day already feels too planned out every day. Once something has become an ingrained part of your day, it&#39;s really hard to notice whether it&#39;s there for fun and enjoyment or actually harmful, and it&#39;s even harder to get rid off.&lt;/p&gt;&#xA;&lt;p&gt;The way I&#39;m trying to battle those things becoming too much of a routine is by taking timeouts and reflect on my choices. Because that&#39;s what they all are. Choices. I do reflect a lot without necessarily taking a timeout, however when I do take a timeout from something, I automatically also reflect on what impact that thing has on my life and whether I like it or not. Over 9 years ago I thought deep and hard about why I was smoking and decided that it wasn&#39;t worth it and stopped. I had multiple times in my life where I completely stopped drinking alcohol for months or even years because I had stopped and reflected on whether I really want to drink this beer because of its taste or because of habit. I generally try to eat vegetarian by default and then have meat twice a week and fish/seafood two to three times a week. I periodically stop and think about whether this is still the case and whether it has been for the last couple of weeks or months. If it doesn&#39;t then I think about why and if it&#39;s because I decided to or just because I got carried away in another routine.&lt;/p&gt;&#xA;&lt;p&gt;But this doesn&#39;t only go for negative things in my life. I have a very specific set of tools that I rely on heavily for my work. I write code and words only in vim, I have all my todos &lt;a href=&#34;https://unwiredcouch.com/2014/05/13/omnifocus.html&#34;&gt;in OmniFocus&lt;/a&gt;, I exclusively use iPhones, OSX on my laptops and FreeBSD on my personal servers. And I really like it. My setup is as close to ideal as I can imagine. However I still occasionally stop and revisit those choices. I have used Atom for a bit when it came out and have tried to use emacs as well. I&#39;ve switched my todos over to a different app or even plain text notes for a month, I every now and then wonder if I want to run FreeBSD on my laptop again, and I&#39;ve switched completely to an Android phone for a week last year.&lt;/p&gt;&#xA;&lt;p&gt;Of course this is partly because of the ever present nagging of optimizing things. But it&#39;s also because I want to make conscious choices about the things I use and be mindful about the way I consume. Just because I have used a tool for 5 years doesn&#39;t make it the perfect one. Just because I have been doing things in a certain way every day doesn&#39;t mean it&#39;s the best way to do it. The hard part is recognizing which things are even part of a routine. This is why it&#39;s important to me to have a lot of time for reflections. I try to have multiple times a day where I can just think. This is mostly right after I get up in the morning and prepare breakfast, on my commute, when I do the dishes, or in the shower. I don&#39;t reflect on my habits every single time but I do have the time to do so every day. It&#39;s also the reason why I really value vacation days and completely unplug from work when I go on vacation. This forces a timeout of all work related things on me. It&#39;s so easy to take things for granted and assume that&#39;s how it has to be instead of thinking about what you want it to be. I&#39;ve cut down on mailing list memberships, push notifications, and times I check and respond to email just because I was on vacation and had a timeout from it all and when I came back reflected on why I was getting all those notifications and if I really had to.&lt;/p&gt;&#xA;&lt;p&gt;Taking the time to stop one of your routines or habits for a week or a month and reflecting on whether it actually makes your life better has been a wonderful way of improving my quality of life. It made me cut out things completely that turned out to not bring me the joy I thought they would. It made me find new things that I thoroughly enjoy now. And it made me appreciate the things that continue to be part of my life even more. Because come Monday I will drink coffee again. And it&#39;s gonna be wonderful because I know why I do drink it.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/11/20/timeouts-reflections.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I love &lt;a href=&#34;https://unwiredcouch.com/setup/coffee/&#34;&gt;coffee&lt;/a&gt;. I really do. And yet I haven&#39;</summary>
  </entry>
  <entry>
    <title>How I prepare for and give conference talks</title>
    <updated>2015-09-25T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-09-25:/09/25/talk-prep.html</id>
    <content type="html">&lt;p&gt;I thoroughly enjoy reading about how other people do their work, tackle problems, find productivity, and prepare for talks. So this is my contribution to this. Before I start however I want to acknowledge that this post is completely inspired by blog posts from &lt;a href=&#34;http://www.catehuston.com/blog/2014/06/06/my-4-step-plan-for-giving-a-talk/&#34;&gt;Cate Huston&lt;/a&gt; and &lt;a href=&#34;http://lizabinante.com/blog/how-i-prepare-conference-talks/&#34;&gt;Liz Abinante&lt;/a&gt; who have written wonderful posts about their conference talk prep process. So before you go on reading here, I encourage you to read theirs first.&lt;/p&gt;&#xA;&lt;p&gt;I have given &lt;a href=&#34;https://unwiredcouch.com/talks&#34;&gt;a bunch of talks&lt;/a&gt; over the last 2 years. Most of them were last year where I felt like I was at a different conference every month. I have given regular conference talks, keynotes, and was on panels. Some of them were as short as 15 minutes with the longest one having been 90 minutes of me talking. The topics range from cultural talks about how we approach things like deployment or blameless postmortems at Etsy to somewhat technical talks about our stack and tools we use and have built. Before 2013 I had never given a public talk, save for some presentations at work and university with a somewhat mixed audience of coworkers or other academics. This means when I had my first talk over 2 years ago, everything was very new to me, I had no idea what I was doing and it took me a long time to get anything done. However I have learned a lot since then and have refined my skills to a level where I enjoy and feel comfortable preparing talks, creating slides, and speaking in front of an audience. And giving talks has been one of the most amazing experiences in my career so far. So I hope this post is useful in helping more people to also improve their presentation skills and encouraging more to also give talks. While you&#39;re reading through this I also want you to always keep in mind that all of those things are very much a function of my character. I identify as an introvert and a highly-sensitive person (I haven&#39;t been tested for it, so I don&#39;t have conclusive proof that I am either one). A lot of things in how I prepare and give talks are to make this experience as good as I can for me as well as my audience. So while some things might work for you as well, I encourage you to take this as inspiration to find your own way.&lt;/p&gt;&#xA;&lt;h3 id=&#34;finding-a-topic&#34;&gt;Finding A Topic&lt;/h3&gt;&#xA;&lt;p&gt;The most important part about finding a topic is to remember that talks are about sharing knowledge and whatever seems obvious to you, is very likely pretty interesting to a lot of people outside of your company.&lt;/p&gt;&#xA;&lt;p&gt;I used to have a pretty hard time with this as I did think all my work was obvious and nothing interesting. I was fortunate however that the way Etsy does deployment was something still very popular when I started giving talks and still is to this day. And since I also work on deployment tooling as my day job it was a very natural thing to talk about for me. So when I got asked to submit a talk proposal for my first conference, I could take the topic of Continuous Deployment and turn it into a talk that was appropriate for what the organizers were looking for. Since then I have given many variations of that talk. Depending on what a conference was looking for I could put more focus on the cultural aspects of it, the tooling, or how it fits into the bigger picture of software development and collaboration at Etsy.&lt;/p&gt;&#xA;&lt;p&gt;However coming up with different topics has been a challenge for me. I gave two differently themed talks last year. One was focused on the Etsy monitoring stack and the other one on how we tackle blameless postmortems. What makes them both a little bit special is that they are not really related to an actual project I had at work. They are about existing setups and ongoing work we are doing to improve things. While this is great for getting out of the mindset that all your current work is obvious and nobody would be interested in hearing about it (two things that are basically always false), it can be hard to find your story arc in such a talk. Since you don&#39;t really go from a problem to the analysis and research part, to the implementation and then the solution, you have to find another hook for your audience. In the case of the monitoring talk I chose Etsy&#39;s technical architecture. We are for the most part running a monolithic &lt;a href=&#34;https://en.wikipedia.org/wiki/LAMP_(software_bundle)&#34;&gt;LAMP&lt;/a&gt; application which seems surprising to a lot of people. So this was a good introduction in to the talk. For talking about blameless postmortems I just chose something everybody can relate to: failure. Most people in the audience have seen their stack break under surprising conditions and Etsy is no exception there. So I chose a familiar scenario to talk about how we deal with it.&lt;/p&gt;&#xA;&lt;p&gt;Something that has helped in the past with finding a topic for me was talking to coworkers that are working on slightly different things and asking them what they think would be interesting to hear a talk on. There is also often an opportunity to follow trends on Twitter to see what kind of problems people are interested in and give a talk on how you tackle that. And if there is something you think is interesting, there&#39;s a high chance others will to. And even if it seems obvious to you, people love to hear about how others tackle problems. So don&#39;t think just because you feel like your work isn&#39;t totally novel that others won&#39;t be interested in it.&lt;/p&gt;&#xA;&lt;h3 id=&#34;writing-the-abstract&#34;&gt;Writing The Abstract&lt;/h3&gt;&#xA;&lt;p&gt;When it comes to writing the abstract, there are two things I try to optimize for:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Organizers should quickly get an idea if the talk is a fit&lt;/li&gt;&#xA;&lt;li&gt;Attendees should quickly know if they want to see the talk over another one&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Writing the abstract for the talk proposal used to be a huge undertaking for me. I wanted to make sure all my ideas are captured and the conference organizers knew what they were getting when they accepted my talk. So I ended up with proposals that were sometimes 2 pages of a fully fleshed out talk (that would change until I give it anyways) and really elaborate. It took me a while to realize that conference organizers get a ton of proposals and they don&#39;t have the time to read a novel of a proposal just to decide whether or not the topic is interesting (if you are a conference organizer and have gotten such a proposal from me: I&#39;m sorry). So I eventually learned to concentrate on the main story arc and message the talk will have. So now when I write an abstract, it&#39;s about 6 sentences to at most 2 paragraphs of text. It contains the title, the super high level outline and what the audience will be able to take away from it. Because the other part of this is that conferences often put the abstract on their schedule page and attendees use it to decide which talk to go to if it&#39;s not a single track conference. So I want them to be able to decide within 30 seconds whether or not my talk sounds interesting. And not bore them with 2 pages of things they might not even be interested in.&lt;/p&gt;&#xA;&lt;p&gt;Plus focusing on the main idea has a big benefit when writing the outline and the slides for the talk. I can always go back to the abstract and check whether or not my talk actually conveys the message I wanted it to bring across. And if I notice I drift from my original idea, I can correct that easily. There have also been occasions where I changed the story arc and message of the talk slightly as I found one I liked better while preparing the slides. This is ok most of the time, however if it turns into a completely different talk I&#39;d check with the organizers if they are fine with this as well. If not, maybe I have a new proposal for a different conference :).&lt;/p&gt;&#xA;&lt;h3 id=&#34;prepping-the-talk&#34;&gt;Prepping The Talk&lt;/h3&gt;&#xA;&lt;p&gt;The time leading up to the conference and preparing the talk is kind of a tricky one for me. I have a process there that works great for me, but which I wouldn&#39;t necessarily recommend for anyone. The main reason for this is that I don&#39;t write anything down until a week or so before the conference and I also don&#39;t do any dry runs. However I want to emphasize that this is not because I think I don&#39;t need all of those things. I&#39;m very convinced my talks would be better if I did them. It&#39;s mostly because of how my brain works and some of my personal anxieties.&lt;/p&gt;&#xA;&lt;p&gt;Just because I don&#39;t write anything down doesn&#39;t mean I don&#39;t think about the talk. As a matter of fact in the weeks before the conference I&#39;m mostly forming ideas and shaping things in my head which then end up on the slides. I do think a long time about things before taking actions, this is just my nature so my talk prep follows this. Then about a week before I give the talk, I start to write my ideas down as slides. Refining them until (sometimes literally) I go on stage. I have used &lt;a href=&#34;https://www.apple.com/mac/keynote/&#34;&gt;Keynote&lt;/a&gt; for a long time to do this. I sometimes wrote down my ideas as a Markdown outline in vim and then create slides in Keynote from this. However as much as I preferred writing the outline in vim, it being twice the amount of work - as I had to basically do the same thing in Keynote then - lead to me more often than not just starting in Keynote. Then in fall of last year I found &lt;a href=&#34;http://www.decksetapp.com&#34;&gt;Deckset&lt;/a&gt;. A wonderful OSX application that lets me write my slides completely in Markdown and then creates a beautiful presentation from them. Since then I have gone back to writing the outline of my talks in vim and then slowly transforming it into slides.&lt;/p&gt;&#xA;&lt;p&gt;And as I said before, I never do dry runs. That&#39;s not because I don&#39;t think they are a good idea. They are and you should absolutely do them. However for me they never fit into my schedule. Because I work on the slides until right before I have to give the talk, there isn&#39;t a version I&#39;m confident in showing people early enough for dry runs. In addition to that if I prepared my talk sooner so I could do a dry run I would constantly think that I&#39;m not giving my best because I&#39;m not using all the time there is. Plus talking in front of people takes a lot of preparation for me (as you will discover later). So dry runs take a huge amount of energy. That being said it is something I&#39;m not really happy about and want to work on getting better at in the future. There are so many things that other people notice about your talks that I think it is one of the things I&#39;m doing that is keeping my talks from being better.&lt;/p&gt;&#xA;&lt;h3 id=&#34;slide-design&#34;&gt;Slide Design&lt;/h3&gt;&#xA;&lt;p&gt;For the slide design I have come to heavily rely on Deckset to do the right thing. I&#39;m a big fan of having only a simple statement or message on a slide to carry the story of the talk. Even when I was using Keynote I tried to have as few things as possible on each slide. Keynote makes it really easy to go overboard with effects, information, shapes, pictures, movies, bullet points, etc. I had a pretty good slides template that I got from &lt;a href=&#34;https://twitter.com/lara_hogan&#34;&gt;a coworker&lt;/a&gt; and that has basically been adapted for almost all Etsy engineering talks by now. This made it pretty fast for me to iterate on slides. I would put the outline headings on a single slide in bold font and then fill in slides in between with content aiming for 1.5 slides per minute. When it comes to slide design I usually choose between either&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;a short statement or quote&lt;/li&gt;&#xA;&lt;li&gt;a picture (optionally with a statement or title)&lt;/li&gt;&#xA;&lt;li&gt;an animated gif&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;That&#39;s it. Nothing more complicated than that. I sometimes have a short bullet point list but I try to keep that rare. If I can&#39;t say something on a slide within those constraints, I very likely should rethink it or split it across multiple slides. I do use some font styles to emphasize words in a statement that I think should have more focus. But all in all I try to keep it simple. And Deckset makes that a lot easier with its constraints (generated from Markdown, no custom themes, etc) than Keynote. So I actually end up being able to iterate on slides much faster. I spent a lot of time trying to find the right pictures and animated gifs for my talks, often I even switch them out right before I give the talk (more on that later). Usually I look for things that are somewhat humorous and make the talk less dry and more enjoyable. I have a big weakness for pop culture references and so it&#39;s not unlikely that my talk includes references to Gossip Girl, Vampire Diaries, Black Sabbath, Iron Man, MacGyver, or various internet memes. This is also how I ended up giving a &lt;a href=&#34;https://speakerdeck.com/mrtazz/the-road-to-success-is-paved-with-small-improvements&#34;&gt;talk at the USPTO&lt;/a&gt; with the Backstreet Boys and Avril Lavigne being part of my slides. I usually end up having enough slides for my talk (to satisfy the 1.5 slides/minute ratio) by the day before the conference or the day before I leave for the conference.&lt;/p&gt;&#xA;&lt;h3 id=&#34;travel-optional&#34;&gt;Travel (optional)&lt;/h3&gt;&#xA;&lt;p&gt;This should probably be its own blog post as there is so much I&#39;ve learned about traveling in the last year. However this only has its own section here as I want to emphasize that I optimize for minimalism and worry free travel when I go to conferences. This means I only have my backpack, which can hold my clothes for at least a week, my laptop with all the cabling, and my &lt;a href=&#34;https://instagram.com/p/lIK8wstp-_/&#34;&gt;Aeropress, grinder, and beans&lt;/a&gt; because I love good coffee and don&#39;t want to think about where to get coffee when I&#39;m in a hotel. I plan my travel so I&#39;ll be at the conference on the day before I give my talk. Usually I end up working on the slides more on the plane and thinking about what message I want to bring across with each slide.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-day-before&#34;&gt;The Day Before&lt;/h3&gt;&#xA;&lt;p&gt;When I arrive at the conference, I check into the hotel, make sure to ask where breakfast is served the next day and when and then meet up with the organizers and try to get a feel for the atmosphere of the conference. This is all for me to get acclimated with the new environment and to minimize surprises and things to worry about. I try to find the room I&#39;m going to give the talk in and if there is a talk I really want to see I attend it. But I don&#39;t sweat that too much, if I have the feeling that I don&#39;t yet feel good about my slides or that I will be more calm by hanging out in the hotel room, I will do that instead. After all I&#39;m here for giving a kick-ass talk and I will do everything to make sure this is what&#39;s gonna happen. Either way I try to be in my hotel room at 10pm at the latest. If I&#39;m there sooner, I&#39;ll go over my slides again and make some adaptations based on what atmosphere I picked up from the conference. By 10pm I&#39;m usually exhausted from travel and/or jet lag and will fall asleep.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-day-of&#34;&gt;The Day Of&lt;/h3&gt;&#xA;&lt;p&gt;I get up between 6 and 6.30am, read a book or browse twitter or my RSS feeds to not yet think about the talk. As soon as the hotel breakfast restaurant opens, I&#39;m heading down there to have an extensive and relaxed breakfast. I go that early for two reasons:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;I want to have as much time as possible to enjoy breakfast.&lt;/li&gt;&#xA;&lt;li&gt;Most likely there aren&#39;t a lot of people around yet, so it&#39;s quiet&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;After breakfast I go back to my room and go over my slides again. At this point I usually just do some minor changes. But I have also reworked a good chunk of the talk during this before. So there are no rules except that I have to feel good about the talk. I might look for a better picture or gif to support the message of some slides or reorder them a bit to make the flow of the overall talk better. I also make coffee as it&#39;s another thing that makes me calm (oddly enough) and feel good. I keep working on my slides until 90 minutes or so before my talk. Then I try to take my mind of the talk for a bit, shower, listen to some music, get dressed (I always wear my Etsy Engineering t-shirt so I don&#39;t have to think about what to wear) and head to the conference. I always try to be at the conference 30-45 minutes before my talk to acclimate myself with the atmosphere. This is a lot easier if the conference is at the same hotel obviously but the same goes regardless of where it&#39;s at. I then find the room I&#39;m giving the talk in, if nobody is speaking there before I find an organizer or other staff member and get set up. My favourite speaking slots are the first ones in the morning. The conference is still a bit empty, the rooms usually are. I just take 15 minutes or so to get a feeling for the room and watch the people coming in. While attendees are sitting down I try to spot 3-5 people in various locations that are evenly spread out and remember them. Those are going to be the people that I try to make eye contact with during the talk. Then 10 minutes or so before I actually am supposed to go on, I go to the restroom, even if it&#39;s just to wash my hands, to have another couple of minutes of quietness before I&#39;m supposed to talk to a room full of people.&lt;/p&gt;&#xA;&lt;h3 id=&#34;actually-giving-the-talk&#34;&gt;Actually Giving The Talk&lt;/h3&gt;&#xA;&lt;p&gt;Once I&#39;m on stage and have my slides up there and am ready to give the talk. Nothing matters except for the talk. I try to be my most energetic, friendly and enthusiastic self. I emphasize when I think how good or bad something is that we are doing or trying to solve. I might try to make some jokes about certain things that people can likely relate to, like how naming this is hard or how computers sometimes don&#39;t do what you think you told them to do. I remember the 3-5 people from before and while I&#39;m talking I switch between them, trying to make eye contact. Generally I&#39;m really bad about making eye contact even in conversations within small groups. So by adhering to this pattern of looking up people beforehand I can just follow it without worrying whether or not I&#39;m actually capturing the audience enough or staring holes into the air. I have my speaker notes on my laptop (I try to present with my laptop if at all possible) but I only usually have notes for the most crucial things or if I&#39;m not confident I get some things right. English isn&#39;t my first language so if things might get tricky with remembering an important word I write it down. Otherwise I tend to improvise on slides a bit. I generally know what I want to say and not having a strict set of notes tends to make it less dry and more lively for me. I tend to always have the last 10% of talk time open for questions. So once I&#39;m done with my slides I let everyone know that I have time for questions. But also make sure it&#39;s clear that I will be around after the talk and also have my (work) email address on the slides. So if someone in the audience has a question but doesn&#39;t want to ask it in front of a lot of people, there is more than that one setting to ask about my talk.&lt;/p&gt;&#xA;&lt;h3 id=&#34;after-the-talk&#34;&gt;After The Talk&lt;/h3&gt;&#xA;&lt;p&gt;If possible I try to stay in the room for a couple of minutes so people can come up to me for questions. If not I&#39;ll try to be around the conference somewhere and - although I have the urge to - try not to disappear immediately. I won&#39;t however attend a talk right after as I&#39;m too hyped up and overstimulated from just having spoken to a room full of people. Once people are not coming up to me for questions anymore or it otherwise doesn&#39;t seem like I&#39;m running away from anyone I try to find a quiet corner and check Twitter to see how people reacted to my talk and what things they tweeted from it. This is a good indicator for me which parts resonated with people and which didn&#39;t. I don&#39;t over obsess on this but it&#39;s nice to read about how people liked your talk and gives me a better feeling about all this preparation and over stimulation having been worth it. I then upload my slides, usually have a page written for it on my &lt;a href=&#34;https://unwiredcouch.com/talks&#34;&gt;site&lt;/a&gt; which I publish and then try to enjoy the rest of the conference. I tend to only go into hiding for a bit and not go to my hotel room as there is a big chance I won&#39;t come back to the conference. So I only take as much time as I need to be able to recharge and enjoy the conference again.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-takeaway&#34;&gt;The Takeaway&lt;/h3&gt;&#xA;&lt;p&gt;Preparing and giving a talk is something I do very thoroughly. I do all those things mentioned here (which may seem like a huge set of preparations) because it helps me be and feel prepared. A lot of the preparation for a talk is psychological for me. As I said in the introduction, I&#39;m very introverted and often have somewhat strong reactions to new and unknown environments and people. So having this framework helps me immensely feeling less overwhelmed.&lt;/p&gt;&#xA;&lt;p&gt;However it&#39;s worth noting that this is the absolute ideal plan. I try to make it work like that but if any of the things don&#39;t work according to plan it&#39;s not a catastrophe. I&#39;m able to give the talk regardless, this is just the dream set up. It also varies a lot depending on how big the conference is and what kind of talk I&#39;m giving. If it&#39;s an internal lunch talk at work, it&#39;s fairly low stress for me now and I don&#39;t have that much prep time that I need. But mostly because I now have a ton of experience giving talks and it&#39;s less scary than it was 2 years ago.&lt;/p&gt;&#xA;&lt;p&gt;This year however I have decided to take a break from giving talks as it was just a bit too much last year. I&#39;m looking forward to giving more talks next year and have spent this year so far helping others to give talks by connecting them to conferences I have spoken at, acting as a sounding board for talk ideas, giving feedback on abstracts and proposals and answer as many questions as I can about the process and nature of giving a conference talk. Learning how to give talks and giving them until I felt pretty comfortable doing it has been a great experience and definitely one of the most amazing things I get to do as part of my job.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Thanks to &lt;a href=&#34;https://twitter.com/bethanymacri&#34;&gt;Bethany Macri&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/lara_hogan&#34;&gt;Lara Hogan&lt;/a&gt; for reading drafts of this and giving feedback&lt;/em&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/09/25/talk-prep.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I thoroughly enjoy reading about how other people do their work, tackle problems, find productivi</summary>
  </entry>
  <entry>
    <title>My Writing Workflow</title>
    <updated>2015-08-31T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-08-31:/08/31/writing-workflow.html</id>
    <content type="html">&lt;p&gt;I love writing. A lot. It&#39;s one of the things that helps me the most with structuring thoughts and opinions I have. It&#39;s also invaluable for me to just brain dump things and see how I feel about them later. I&#39;ve come to really appreciate taking the time to properly formulate things and incorporating time to write (almost) every day. In order to make this as easy to get started with as possible I have developed a setup that works really well for me and thus I wanted to share it.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-basics&#34;&gt;The Basics&lt;/h3&gt;&#xA;&lt;p&gt;In order to make writing for me as low barrier as possible it has to work with the tools I use every day. For me this mostly means vim and git. I try to really embrace plain text for everything and store those files in git - even for my &lt;a href=&#34;https://unwiredcouch.com/2015/06/08/accounting-the-unix-way.html&#34;&gt;accounting data&lt;/a&gt;. For quite a long time I just used my regular (terminal) vim setup that I had configured for writing code to also write prose. And it worked remarkably well. However it also always had this programming feel to me with all the important status bar information that was actually way more distracting than useful when not in a coding mode. It&#39;s also a lot harder and uncomfortable to focus on only writing with default left aligned layout in vim. I would open vim in full screen to not have any distractions and my text would always hang on the left third of the terminal.&lt;/p&gt;&#xA;&lt;p&gt;I was looking for something like a &lt;a href=&#34;http://www.hogbaysoftware.com/products/writeroom&#34;&gt;write room&lt;/a&gt; style setup. Fortunately a lot of other people have also had that problem and there&#39;s a huge variety of distraction-less writing plugins for vim now. After some searching I&#39;ve settled on &lt;a href=&#34;https://github.com/amix/vim-zenroom2&#34;&gt;vim-zenroom2&lt;/a&gt;. It&#39;s based on &lt;a href=&#34;https://github.com/junegunn/goyo.vim&#34;&gt;Goyo&lt;/a&gt; and gives me a beautifully decluttered vim session where I can focus on only the text I want to write and nothing else. I spent some time trying to get the vim status bar to display the word count of the current buffer. But it was always kind of janky. So I decided to not care that much and just run &lt;code&gt;:!wc - w %&lt;/code&gt; when I really want to know how much I&#39;ve written. And as I also exist inside of &lt;a href=&#34;https://unwiredcouch.com/2013/11/15/my-tmux-setup.html&#34;&gt;a tmux session&lt;/a&gt; most of the time, I also disable the status bar there when in writing mode. I rely heavily on the terminal bell changing the status bar for notifications and I don&#39;t want to be interrupted by that when I&#39;m writing.&lt;/p&gt;&#xA;&lt;p&gt;I do all my writing in Markdown. I really like that it&#39;s basically plain text with a little bit of markup and super close to HTML. That makes it easy to just write and more importantly read without having to constantly render and preview it. I actually write out all of my drafts before looking at the rendered version most of the time. A helpful setting in vim there is to enable spell checking for Markdown files. In my &lt;code&gt;vimrc&lt;/code&gt; I have &lt;code&gt;autocmd FileType markdown setlocal spell&lt;/code&gt; set, so that every time I open a Markdown file I get spell correction automatically. This is especially helpful as I do most of my writing not in my first language. So vim tells me immediately when I&#39;ve written the German spelling for an English word and lets me correct it.&lt;/p&gt;&#xA;&lt;p&gt;When I want to focus on writing I also tend to only work on my 11&#34; MacBook Air and not connect it to the Thunderbolt Display. The bigger screen tends to distract me more than it helps. However I do have an iTerm profile with a bigger font for writing. The default for coding, IRC, email, etc for me is 11pt. And I switch to 18pt for writing.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/goyo.png&#34; alt=&#34;vim distraction free writing&#34; /&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;blogging&#34;&gt;Blogging&lt;/h3&gt;&#xA;&lt;p&gt;For blogging I use &lt;a href=&#34;http://jekyllrb.com&#34;&gt;jekyll&lt;/a&gt;. I switched to it 6 years ago when I wanted to have a blog again and it works pretty well most of the time. Rumour has it that I&#39;m constantly trying to replace it with a simple Makefile but that may or may not be true. The repo is &lt;a href=&#34;https://github.com/mrtazz/unwiredcouch.com&#34;&gt;open source on GitHub&lt;/a&gt; but I host the actual site on my own server.&lt;/p&gt;&#xA;&lt;p&gt;I used to have all my drafts in the jekyll &lt;code&gt;_drafts&lt;/code&gt; folder, as it made the most sense to have it all in one place. Whenever I had an idea for a new blog post I would create a file in there with the yaml frontmatter, set the title and &lt;code&gt;published&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt; and jot down some bullet points. However since I didn&#39;t want the blog posts I may or may not write be in the git repo on GitHub, I never committed them to git. Which started to annoy me as I didn&#39;t really have a commit log, backup, etc for my drafts. I also had the whole blog cloned into my owncloud folder, which meant that it would always try to sync all the jekyll files and git objects although it wasn&#39;t really necessary as I only really cared about having my drafts everywhere for easy access. So I decided to move my drafts into a separate repo, that is just pushed to one of my servers. From there I can just clone it wherever I want, edit, and push it back up.&lt;/p&gt;&#xA;&lt;p&gt;The way I create drafts in there is still the same. I add a file with the yaml frontmatter (I actually have a &lt;a href=&#34;https://github.com/mrtazz/vim-stencil&#34;&gt;vim-stencil&lt;/a&gt; template for it). And then add some bullet points, headlines and ideas I have about that blog post in there. Basically a small outline which I will use to evolve the post. I will then most likely not touch it for quite a while. The way I write most blog posts is that I have the draft with some notes in the repo for weeks or months and every now and then think about it and come up with some new things to add and new ways to phrase ideas. Then at some point I just sit down and write it all down. So my writing flow really happens in spurts.&lt;/p&gt;&#xA;&lt;p&gt;Once I&#39;m happy with the draft, I move it over to the jekyll blog, make some minor adjustments so it looks good in HTML and publish it by rsyncing the generated &lt;code&gt;_site&lt;/code&gt; folder to my server. I then &lt;code&gt;git rm&lt;/code&gt; the file from the drafts repo and add the URL where it&#39;s published in the commit message.&lt;/p&gt;&#xA;&lt;h3 id=&#34;journaling&#34;&gt;Journaling&lt;/h3&gt;&#xA;&lt;p&gt;Another outlet for my writing is journaling. However it&#39;s a lot more infrequent and random for me. The setup is kinda similar, although I don&#39;t use jekyll for it. I basically have a &lt;code&gt;journal&lt;/code&gt; git repo that holds a file &lt;code&gt;current.md&lt;/code&gt; where I write down my thoughts for the day. At the end of the month I move the file to an archive format in the form of &lt;code&gt;YYYY/MM.md&lt;/code&gt; and touch the file again to now hold the entries for the current month. This means I have a setup in the repo that holds a folder per year and a markdown file per month in each folder. There is also a Makefile to generate a single HTML file from all entries to make it nicer to browse.&lt;/p&gt;&#xA;&lt;p&gt;I try to write something into my journal every day but it&#39;s been one of the harder habits to keep up. Similarly to how I have a hard time taking notes in meetings, I&#39;m a person who thinks a lot about things. But since it all takes place in my brain I never remember to actually write it down. In order to make it more low barrier to write journal entries I have created a specific iTerm profile just for that. It opens a terminal in a new window, and immediately runs &lt;code&gt;/usr/local/bin/vim -c Goyo /path/to/current.md&lt;/code&gt; instead of a shell. Thus I get a vim session with my journal immediately. I also have an &lt;a href=&#34;https://www.alfredapp.com&#34;&gt;Alfred&lt;/a&gt; workflow to open iTerm profiles directly. So I can open Alfred, type &lt;code&gt;itp journal&lt;/code&gt; and get the iTerm session for writing. This makes it a lot easier and low barrier to journaling.&lt;/p&gt;&#xA;&lt;p&gt;When I&#39;m done with the entry, I commit it to git and immediately push. This way I have my journal available wherever I want it but especially on my phone to jot things down on the go.&lt;/p&gt;&#xA;&lt;h3 id=&#34;mobile&#34;&gt;Mobile&lt;/h3&gt;&#xA;&lt;p&gt;I don&#39;t write a ton on my phone but it&#39;s nonetheless a crucial part of my writing flow. I used to have all my writing things in my ownCloud folder together with my notes and synced to my iPhone via &lt;a href=&#34;http://www.notebooksapp.com&#34;&gt;Notebooks&lt;/a&gt; and webdav. However this has gotten a bit more tedious than I want it to be. Webdav is not super fast and if there is a merge conflict, I don&#39;t get all the niceties of git to resolve it. Plus I don&#39;t need it to check all the files when I really just want to open my journal and add an entry.&lt;/p&gt;&#xA;&lt;p&gt;So with the move to separate git repos for my drafts and journal I also started to base my mobile flow more on git. I use &lt;a href=&#34;http://workingcopyapp.com&#34;&gt;Working Copy&lt;/a&gt; on the iPhone to get access to all my git repos. It&#39;s a really great mobile git client and for journaling I just open the &lt;code&gt;current.md&lt;/code&gt; file in the app directly and commit and push it back up. The editor is pretty decent and more than apt for quickly jotting things down.&lt;/p&gt;&#xA;&lt;p&gt;For writing longer, actual blog posts I&#39;ve come to really like &lt;a href=&#34;http://omz-software.com/editorial/&#34;&gt;Editorial&lt;/a&gt; for iOS. It&#39;s an extremely nice plain text editor with a great Markdown mode. And since both Working Copy and Editorial support the iOS share extensions, I can open a file from Working Copy in Editorial and then save it back to Working Copy for committing the changes to git when I&#39;m done. I&#39;m not gonna ditch the laptop for it anytime soon, but it&#39;s a great way to write when I suddenly am in the mood but don&#39;t want to get up and get my laptop. And I even wrote the first third of this blog post completely on the iPhone.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/editorial.jpg&#34; alt=&#34;writing on iOS with Editorial&#34; /&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;future-improvements&#34;&gt;Future Improvements&lt;/h3&gt;&#xA;&lt;p&gt;I&#39;m really happy with my setup, it works great for me and is based on the tools I know and trust. It&#39;s a very frictionless setup that makes it easy for me to write down my thoughts and have them available for look up and further editing.&lt;/p&gt;&#xA;&lt;p&gt;The things I definitely want to improve on is to write more. I have a lot of things on my mind and whenever I write things down, it makes things a lot clearer for me. But I have to remind myself to actually do it. One thing I want to establish is more of a writing routine. And even if it&#39;s just a couple of hundred words every day in the journal. Because writing is a ton of fun and it&#39;s one of the things I really really enjoy.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/08/31/writing-workflow.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I love writing. A lot. It&#39;s one of the things that helps me the most with structuring thoughts an</summary>
  </entry>
  <entry>
    <title>Practical Postmortems at Etsy</title>
    <updated>2015-08-22T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-08-22:/08/22/practical-postmortems-at-etsy.html</id>
    <content type="html">&lt;p&gt;I wrote an article on InfoQ about the way we conduct &lt;a href=&#34;https://codeascraft.com/2012/05/22/blameless-postmortems/&#34;&gt;Blameless Postmortems&lt;/a&gt; at Etsy. You can check it out &lt;a href=&#34;http://www.infoq.com/articles/postmortems-etsy&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/08/22/practical-postmortems-at-etsy.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I wrote an article on InfoQ about the way we conduct &lt;a href=&#34;https://codeascraft.com/2012/05/22/</summary>
  </entry>
  <entry>
    <title>Adventures in Frontend Performance</title>
    <updated>2015-07-24T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-07-24:/07/24/frontend-performance.html</id>
    <content type="html">&lt;p&gt;In my daily job I am far removed from being a frontend engineer. In a previous job I had spent months to optimize JavaScript to be small enough to be served by an &lt;a href=&#34;http://dl.acm.org/citation.cfm?id=1582405&#34;&gt;embedded microcontroller&lt;/a&gt; (there&#39;s a certain irony in the fact that I don&#39;t have the original paper anymore and thus can&#39;t read my own paper without paying now, but that&#39;s a different topic). But those days are long gone. My main tools today are Chef, PHP and shell script most of the time. This means that I unfortunately don&#39;t have a great amount of experience on how to structure web frontends to be fast. But it&#39;s one of the things I&#39;m working on getting better at. Fortunately I work with a lot of talented people. And one of them, my coworker and friend &lt;a href=&#34;http://twitter.com/lara_hogan&#34;&gt;Lara Hogan&lt;/a&gt;, literally wrote the book on &lt;a href=&#34;http://larahogan.me/design/&#34;&gt;&#34;Designing for Performance&#34;&lt;/a&gt;. So I decided to start there and bought it and read it last week. It&#39;s a great and fast read and gives you a really great introduction into how to structure web content to be fast.&lt;/p&gt;&#xA;&lt;p&gt;After I was done reading it, I decided to try out what I&#39;ve learned and see if I can make my blog faster. So I installed &lt;a href=&#34;http://yslow.org&#34;&gt;YSlow&lt;/a&gt; and ran it on an &lt;a href=&#34;https://www.unwiredcouch.com/2015/06/08/accounting-the-unix-way.html&#34;&gt;example blog post&lt;/a&gt;. I don&#39;t often have a lot of images in my posts. It&#39;s mostly text and maybe some inline code snippets. So I decided that this was a good representative post for testing my improvements. And the YSlow results weren&#39;t great. In my current setup loading this simple page resulted in the following YSlow result:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;12 HTTP requests and a total weight of 157.2K bytes with empty cache&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;At least I now had a baseline to compare my changes to. The book has a very good chapter on how to cleanup CSS and how it can affect page weight and page load times. So I started there. I didn&#39;t really have good structure in my CSS as it has basically organically grown since 2009. And whenever I wanted to change something or try out something new, I just added the CSS for it on top of the existing one. I&#39;ve rarely gone back and cleaned things up. This lead to me having 3 CSS files being loaded for every page. The main style declarations aptly named &lt;code&gt;style.css&lt;/code&gt;, a CSS file which contained definitions for all the code highlighting I&#39;m using on my site &lt;code&gt;pygments.css&lt;/code&gt; and a third file from when I started playing with fonts that would declare font-faces and such and was named - you guessed it - &lt;code&gt;fonts.css&lt;/code&gt;. When I added those files it made sense to me to have them separate. They were taking care of different things, contained no duplicate code, I was basically treating them like includes in a programming language. So I took a look at the files and found a lot of old clutter. I was still loading two fonts which I hadn&#39;t used in forever. And I also had recently reworked my header but was still loading the font that gave me icons for popular social media sites which I had previously used for linking. Those together were already around 75kB and 3 HTTP requests for nothing. So I removed the fonts I wasn&#39;t using, cleaned up some other CSS that I had found that was unused and combined the 3 style files I had into 1. And that already gave me a huge jump in optimization. Just by removing things that I didn&#39;t need and combining CSS files I went to:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;7 HTTP requests and a total weight of 65.4K bytes with empty cache&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;I was already amazed and excited and of course now I wanted to do more. So I installed a CSS minifier and decided to load only minified CSS. This gave me another 15 kB in improvements:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;7 HTTP requests and a total weight of 50.0K bytes with empty cache&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Another thing that is mentioned in the book as a common way to improve performance is to load images for the size you actually want to display them at and not bigger. I didn&#39;t want to go through all the images I had in some random blog posts but still do something for my baseline performance. And since I load my avatar from Gravatar into the header on every load, I looked at that and saw that I was requesting the image in size 142x142 (Gravatar gives you the handy URL parameter &lt;code&gt;?s=142&lt;/code&gt; for that) but was only displaying it in 100x100. So I changed the parameter to 100 and squeezed a couple more kilobytes out of my site:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;7 HTTP requests and a total weight of 47.7K bytes with empty cache&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Now I was kind of at a stopping point. I had collected all the low hanging fruit. My page was only a third as big as it was before and I was down 5 HTTP requests that didn&#39;t have to be done anymore. This was already huge for me. Looking at YSlow now told me that I was spending another HTTP request for loading JavaScript from Twitter to embed their social media buttons. And that this also added about 35 kB to my page weight. At this point about 75% of my total page weight. Of course as a first course of action, &lt;a href=&#34;https://twitter.com/mrtazz/status/622603993215303681&#34;&gt;I tweeted about it&lt;/a&gt; and thought about whether or not I really need or want the share buttons on there. Fortunately &lt;a href=&#34;https://twitter.com/atmos&#34;&gt;Corey&lt;/a&gt; responded to my tweet with essentially what I was thinking. That I don&#39;t really need those buttons for anything. So I removed the buttons, bringing my total YSlow results to:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;6 HTTP requests and a total weight of 12.4K bytes with empty cache&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;And I was blown away when I actually saw the number. Just by following some simple advice from the book, I was able to cut the number of HTTP requests in half. And slim down my page weight to ~8% of what it was before.&lt;/p&gt;&#xA;&lt;h3 id=&#34;learning-new-things-is-fun&#34;&gt;Learning new things is fun&lt;/h3&gt;&#xA;&lt;p&gt;Optimizing my site has been a lot of fun. Of course if you are an experienced frontend engineer, all of those things are not surprising and probably the first thing you would try. But not working in that field every day, I was surprised by the impact such a cleanup and restructuring can make on even a small site like mine. I had tried to dabble a little bit in getting better at frontend engineering and performance before. However I had never had a good introduction to give me a place to start. Learning new things can be overwhelming and especially if you don&#39;t know where to start, everything can feel like it&#39;s probably wrong. Lara&#39;s book gave me a great introduction into all the different topics of frontend performance and if you are interested in this as well, I can highly recommend it.&lt;/p&gt;&#xA;&lt;p&gt;For now I might not be able to squeeze out more performance just from reducing the page weight. I&#39;ve since installed &lt;code&gt;mod_deflate&lt;/code&gt; and &lt;code&gt;mod_expire&lt;/code&gt; on my web server to improve transfer size and caching for my site. However I still feel like structuring HTML and CSS in a good and fast performing way is something I don&#39;t have a good grasp on. And it&#39;s definitely something my site can benefit from, if even for more clarity next time I want to change anything. So this might be the next thing I&#39;ll tackle in learning more about frontend engineering.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/07/24/frontend-performance.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;In my daily job I am far removed from being a frontend engineer. In a previous job I had spent mo</summary>
  </entry>
  <entry>
    <title>Open Source Spring Cleaning</title>
    <updated>2015-07-09T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-07-09:/07/09/oss-spring-cleaning.html</id>
    <content type="html">&lt;p&gt;I wrote about our plans to clean up our open source repositories and be good maintainers on Etsy&#39;s &lt;a href=&#34;https://codeascraft.com&#34;&gt;engineering blog&lt;/a&gt;. You can find the post &lt;a href=&#34;https://codeascraft.com/2015/07/09/open-source-spring-cleaning/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/07/09/oss-spring-cleaning.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I wrote about our plans to clean up our open source repositories and be good maintainers on Etsy&#39;</summary>
  </entry>
  <entry>
    <title>Accounting: The Unix Way</title>
    <updated>2015-06-08T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-06-08:/06/08/accounting-the-unix-way.html</id>
    <content type="html">&lt;p&gt;I&#39;m a big fan of simple tools and building blocks. A function of writing code every day for the last 10 years has been that I feel really comfortable with plain text files, vim and git. So whenever I can, I try to see if I can base the solution to a problem on plain text. It&#39;s just in most cases so much more portable than any other way and I am already very comfortable with the command line. That way I can use my every day tools to add, modify and delete data.&lt;/p&gt;&#xA;&lt;p&gt;A while ago I wanted to find a better way to keep on top of my finances. They aren&#39;t crazy in any way and I have a very normal, regular, non-exceptional financial situation as an employed engineer. However I felt like I could get more data and better insights into everything. This wasn&#39;t really on my mind for a while though. I kept the idea in the back of my head but wasn&#39;t actively looking into any way to make it happen. Then one day I was reading my RSS feeds where I amongst others subscribe to the wonderful &lt;a href=&#34;http://usesthis.com/&#34;&gt;&#34;The Setup&#34;&lt;/a&gt; blog. If you don&#39;t know about it, it&#39;s basically an interview series where people talk about the tools (hardware and software) they use to get their job done. I like reading about the tools others use and get inspired to try out different things. And in there I was reading &lt;a href=&#34;http://stefano.zacchiroli.usesthis.com/&#34;&gt;an interview&lt;/a&gt; with a Debian developer who mentioned working a lot with text files and git. And he also said he was doing his accounting with git and &lt;a href=&#34;http://www.ledger-cli.org/&#34;&gt;ledger&lt;/a&gt; and I was immediately intrigued.&lt;/p&gt;&#xA;&lt;p&gt;I started to investigate the tool and read blog posts about how others were using it. Ledger actually has a very &lt;a href=&#34;http://www.ledger-cli.org/3.0/doc/ledger3.html&#34;&gt;comprehensive documentation&lt;/a&gt;, so I started there. Read about how to use it, the basics of &lt;a href=&#34;http://en.wikipedia.org/wiki/Double-entry_bookkeeping_system&#34;&gt;double-entry bookkeeping&lt;/a&gt;, and what kind of information I could get out of it. I then also found an &lt;a href=&#34;http://blog.andrewcantino.com/blog/2013/02/16/command-line-accounting-with-ledger-and-reckon/&#34;&gt;interesting post&lt;/a&gt; where someone wrote a tool - &lt;a href=&#34;https://github.com/cantino/reckon&#34;&gt;reckon&lt;/a&gt; - which parses CSV and formats it into ledger format. It even uses Bayesian machine learning to suggest accounts to use for each entry, minimizing the work that needs to be done manually even further.&lt;/p&gt;&#xA;&lt;h3 id=&#34;diving-into-the-deep-end&#34;&gt;Diving into the deep end&lt;/h3&gt;&#xA;&lt;p&gt;So I decided to give it a try and take the upcoming tax return I had to file as the motivation to get it done before that. I downloaded CSV data from my bank accounts (and learned that the allowed time to back is 2 years, no data before that), installed ledger via homebrew and the reckon rubygem and started to import data. This was a bit tedious at first, as reckon didn&#39;t support backspacing and thus editing mistyped accounts. I fixed that in the gem and sent a &lt;a href=&#34;https://github.com/cantino/reckon/pull/44&#34;&gt;pull request&lt;/a&gt; like a good open source citizen and &lt;a href=&#34;https://twitter.com/mrtazz/statuses/573671503029497856&#34;&gt;procrastinating software engineer&lt;/a&gt;. And after a couple of hours I had all my data from 2014 and (most of) 2013 in the ledger data format. I played around with the reporting options and really liked it. It was super flexible I could quickly fix and change things by opening the file in vim. So I decided to properly structure it and go full in with ledger.&lt;/p&gt;&#xA;&lt;h3 id=&#34;all-in&#34;&gt;All in&lt;/h3&gt;&#xA;&lt;p&gt;I created a git repo with directories for the raw csv files (in case I needed to regenerate any data at some point or look up something else) and for each year since 2013. In those per-year directories I have a file for checking, credit card, cash and opening balances. And a top level ledger dat file per year that includes the appropriate files.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;cassie&lt;/span&gt;:accounting[master]% cat 2015.dat&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;include&lt;/span&gt; 2015/opening_balances.dat&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;include&lt;/span&gt; 2015/checking.dat&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-4&#34;&gt;&lt;a href=&#34;#cb1-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;include&lt;/span&gt; 2015/credit_card.dat&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-5&#34;&gt;&lt;a href=&#34;#cb1-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;include&lt;/span&gt; 2015/cash.dat&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-6&#34;&gt;&lt;a href=&#34;#cb1-6&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-7&#34;&gt;&lt;a href=&#34;#cb1-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;cassie&lt;/span&gt;:accounting[master]% ls -1 2015&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-8&#34;&gt;&lt;a href=&#34;#cb1-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;cash.dat&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-9&#34;&gt;&lt;a href=&#34;#cb1-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;checking.dat&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-10&#34;&gt;&lt;a href=&#34;#cb1-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;credit_card.dat&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-11&#34;&gt;&lt;a href=&#34;#cb1-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;opening_balances.dat&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Checking and credit card should be self explanatory as they just hold the entries for those accounts. Whenever I withdraw money at an ATM, I book it to an &lt;code&gt;Expenses:Cash&lt;/code&gt; account as I expect to spend that money. Otherwise I wouldn&#39;t have withdrawn it. But this also means that I don&#39;t have a ton of visibilty into what I spend cash on. That is why I have a file called &lt;code&gt;cash.dat&lt;/code&gt;. When I spend cash on something and remember, I note it down on my phone in a text file which syncs to my computer. And when I&#39;m doing my monthly accounting I can pull up this file and just write proper ledger data entries for the contents of this file. I then note that those expenses come from the account &lt;code&gt;Expenses:Cash&lt;/code&gt; to keep everything correct. The next file special file is &lt;code&gt;opening_balances.dat&lt;/code&gt;. Because I have a file per year, the data only reflects postings for that year. In order to still get accurate balances, I run the equity command (&lt;code&gt;ledger -f ledger-old.dat equity&lt;/code&gt;) on the old year&#39;s data and write that into the opening balances file as coming from the account &lt;code&gt;Equity:OpeningBalances&lt;/code&gt;. This is a bit of hack, but it illustrates a major advantage of ledger. It doesn&#39;t care about what the accounts are named. This means you can give them names that mean something to you and ledger won&#39;t have a problem with that. The documentation even gives an example for tracking inventory in the &lt;a href=&#34;http://www.ledger-cli.org/3.0/doc/ledger3.html#Accounts-and-Inventories&#34;&gt;video game EverQuest&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;monthly-routine&#34;&gt;Monthly Routine&lt;/h3&gt;&#xA;&lt;p&gt;Now with this setup in place, I have a monthly recurring project in &lt;a href=&#34;https://unwiredcouch.com/2014/05/13/omnifocus.html&#34;&gt;my OmniFocus&lt;/a&gt; to download the CSV for my account and add them to my ledger data. Once I&#39;ve downloaded the file, I run reckon over it to have it properly format the data and suggest accounts to add them to. Since reckon - as I mentioned before - uses Bayesian learning to find out what accounts a posting likely belongs to, it makes sense to have a corpus for it to learn from which includes all possible accounts. And because I really like Makefiles, I have one with a simple task in there to generate a big file which contains all of my postings:&lt;/p&gt;&#xA;&lt;pre class=&#34;make&#34;&gt;&lt;code&gt;SOURCES := $(shell find . -iname &amp;quot;*.dat*&amp;quot; -mindepth 2)&#xA;&#xA;corpus.dat: $(SOURCES)&#xA;    cat $(SOURCES) &amp;gt; $@&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Now I run reckon with something like&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;reckon&lt;/span&gt; -f raw_data/2015/checking05.csv --contains-header -o 201505_checking.dat -l corpus.dat&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;in order to parse the CSV file. Usually when I run this, reckon detects almost all of my recurrent transactions like rent, gas, electricity, internet, subway and ferry fare. I just have to confirm the account by hitting enter. With this it takes me about 5-10 minutes to get through a CSV file. After I&#39;m done I might go through the file in vim to make some adaptions. For example I have a very generic account named &#34;Expenses:Amazon&#34; which reckon detects to use for everything coming from Amazon. However since I buy a variety of things (household items, clothes, etc) on Amazon I open my &#34;past orders&#34; page on amazon.com and check my transactions in ledger against it and file them into more specific accounts. When I&#39;m happy with it, I commit my changes to git and have an up to date version of my accounting data. I then can run all the queries on it to give me some overview of what I was spending money on in the last month. Ledger is versatile enough that I could spend a lot of time on explaining all the possibilities. But the simplest way to get started is just showing the top level balances which will give you an overview about Income, Expenses and Assets (if you have named your accounts like that):&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;ledger&lt;/span&gt; -f 2015.dat --period-sort &lt;span class=&#34;st&#34;&gt;&amp;quot;(amount)&amp;quot;&lt;/span&gt; balance -M --begin 2015/04/01 --end 2015/05/01 --depth=1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;h3 id=&#34;verdict&#34;&gt;Verdict&lt;/h3&gt;&#xA;&lt;p&gt;I&#39;m really happy with this setup so far. It&#39;s comparably low tech and low investment and I can (for the most part) use the tools I know and I don&#39;t have to store my financial data on someone elses server. Still if I want to do accounting on a different machine, it&#39;s just a matter of cloning the git repo to it and installing ledger. The import process is not too cumbersome, although I have to remember when I pay off my credit card from my checking account for example that I only enter the transaction once as it will show up in both CSV downloads (once as debit and once as credit). This has caused some confusion for me in the past when I forgot but generally isn&#39;t too bad.&lt;/p&gt;&#xA;&lt;p&gt;I&#39;m also not doing any super advanced things with it so far. I&#39;ve played with it&#39;s &lt;a href=&#34;http://www.ledger-cli.org/3.0/doc/ledger3.html#Visualizing-with-Gnuplot&#34;&gt;Gnuplot suppport&lt;/a&gt; and ran different queries in different situations to track down where I actually spent more money than the month before. I&#39;m sure there are more use cases that will arise over time and while I&#39;m no accountant (and probably used some words wrong on this post) it has been super interesting to get some more structure and insight into my personal finances.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/06/08/accounting-the-unix-way.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I&#39;m a big fan of simple tools and building blocks. A function of writing code every day for the l</summary>
  </entry>
  <entry>
    <title>There&#39;s No Such Thing as No Project Management</title>
    <updated>2015-05-04T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-05-04:/05/04/project-management.html</id>
    <content type="html">&lt;p&gt;Project management. Every engineer seems to loathe the term and also what it describes. It has that word &lt;em&gt;management&lt;/em&gt; in there. It&#39;s different than code. It&#39;s not code. So naturally whenever this comes up, all the engineers make a joke, shrug and go hide behind their editors. I&#39;ve been there, I&#39;ve done that. However over the years I have realized that this is not just stupid but actively working against making software projects successful. I mostly had an aversion against the overloaded, overused and useless definition of project management glorifying charts and plans and deadlines over actually organizing and making sense of the work and the processes to get it done. Because the truth is you are already doing project management. Yes you! The software engineer!&lt;/p&gt;&#xA;&lt;h3 id=&#34;you-had-the-project-management-all-along&#34;&gt;You had the project management all along&lt;/h3&gt;&#xA;&lt;p&gt;Every time you start to write code, even for some fun side project, you start to think about the different components that will make up the whole thing. You start to form a mental model of all the high level parts that comprise the finished application. You plan out some rough course of action for yourself. Which parts you want to tackle first. Which things to stub out and which things to punt on for later. You just (most of the time) don&#39;t write them down. But as you go on, you think about what the first workable version will be able to do. Then you think about the next one, maybe refactor some things to accomodate new features. Maybe you write down some notes for you or add some &lt;code&gt;//TODO:&lt;/code&gt; lines in the code so you know what to do when you come back to it. But the important part here is, that you&#39;re planning the application. You&#39;re basically already doing 85% of what project management for a small to medium software project is all about.&lt;/p&gt;&#xA;&lt;p&gt;So what&#39;s the difference? Well really mostly thinking about the structure of your project on a higher level and writing things down. To be clear: It&#39;s ok if you only want to write code. And you can be or get really good at it. However only wanting to write code is like saying you only want to hammer wood together. Sure there is beauty in how you do it. There are good carpenters out there who are able to do woodwork like nobody else. And everybody wants to have such a craftsperson on their team when it comes down to doing the work. However this will only be useful up to a certain level. And that&#39;s absolutely ok. But if you want to level up as a carpenter you will need to understand what it is that you&#39;re actually building.&lt;/p&gt;&#xA;&lt;p&gt;And that is very much the same for a software engineer. In my mind &lt;a href=&#34;http://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/&#34;&gt;being a senior engineer&lt;/a&gt; also means that you understand the problems you are solving past the perfect implementation of a binary sort. That you understand that writing code is a means to an end and not the ultimate purpose. That you understand what problem you are solving and the environment it will exist in so you &lt;a href=&#34;https://www.unwiredcouch.com/2015/01/28/building-a-plant.html&#34;&gt;plan for it&lt;/a&gt; accordingly. This means a good chunk of &#34;non-coding time&#34;. It means that you understand how to break the problem apart and how it would speed up the implementation if you suddenly got 2 or 3 more engineers on the project. Or if it wouldn&#39;t help at all. It means that you understand how the project could continue if you suddenly &lt;a href=&#34;https://twitter.com/mrtazz/status/593835726858518528&#34;&gt;decided to go on vacation&lt;/a&gt; because you know you don&#39;t want to &lt;a href=&#34;https://twitter.com/mrtazz/statuses/557697168010924033&#34;&gt;be a spof&lt;/a&gt;. It means that you have things planned out so someone else could &lt;a href=&#34;https://twitter.com/mrtazz/status/590506541436039169&#34;&gt;take it over&lt;/a&gt; or even make the whole project happen without you. It means understanding what existing or future work would be great for a more junior engineer on the team to level up on and plan work so it&#39;s possible for them to do it. And it means writing things down and communicating them.&lt;/p&gt;&#xA;&lt;p&gt;This can be as easy as creating a project in your JIRA instance and adding a bunch of subtasks. It can be Gantt charts if you are so inclined and want to show dependencies better. It can be a markdown document laying out all the bits and pieces you have thought about so far.&lt;/p&gt;&#xA;&lt;h3 id=&#34;you-are-not-your-project&#34;&gt;You are not your project&lt;/h3&gt;&#xA;&lt;p&gt;All of these things might feel weird at the beginning. All you want to do is write code, find the perfect abstraction, make it beautiful. You will suck at this at first because you are not used to it. But at the same time you will suddenly see others implementing things you want to exist, doing work for you and learning while they do it. And maybe even take a whole project over from you and finish it. And it will feel weird again. You will have this feeling of not having finished something. Of only going 80% there. Of only having done the &#34;soft&#34; parts. But in reality you just transferred a ton of knowledge. You made it possible for someone else to work on something that previously only existed in your head. &lt;a href=&#34;http://en.wikipedia.org/wiki/Egoless_programming&#34;&gt;You are not your projects&lt;/a&gt;. I&#39;ve &lt;a href=&#34;https://twitter.com/mrtazz/statuses/467769106780127232&#34;&gt;said before&lt;/a&gt; that you need to capture ideas for others to work on. It&#39;s the only way to scale yourself. And it frees up your time to work on other things. And even if you end up working on the project all by yourself (which is less and less likely as your organization grows), there will be a plan for others who are interested to follow along with what&#39;s going on. There is clear communication of what&#39;s in progress and what the current state of things is. And other engineers can learn from your example. Because suddenly you&#39;re doing project management. And it&#39;s not even that weird. You have been doing it on some level all along. And you should, it&#39;s part of your job. As an engineer you understand best how work gets done. So you are in the perfect position to plan out the structure of your projects. And there is no such thing as &#34;no project management&#34; anyways. You can only decide to do it badly or try to do it well. And seeing all the benefits of doing it well come to life is so much more fun.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/05/04/project-management.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Project management. Every engineer seems to loathe the term and also what it describes. It has th</summary>
  </entry>
  <entry>
    <title>First month with the Spark Notebook</title>
    <updated>2015-03-18T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-03-18:/03/18/spark-notebook-omnifocus.html</id>
    <content type="html">&lt;p&gt;When the &lt;a href=&#34;http://www.thesparknotebook.com/&#34;&gt;Spark Notebook&lt;/a&gt; got announced on Kickstarter I was first a bit hesitant as I have struggled before balancing digital and paper notes. But nonetheless I still always felt something was missing from the way I was currently going about planning my day and taking notes. My todos are all neatly organized &lt;a href=&#34;http://www.unwiredcouch.com/2014/05/13/omnifocus.html&#34;&gt;in OmniFocus&lt;/a&gt; and I did most of my note taking in VIM as text files in a folder structure. This works quite well and I even can sync them with my phone. However I always felt too restricted when taking notes without being able to scribble. There are things that just somehow feel better when written by hand. I have tried to bring a Moleskine notebook with me all the thing but somehow I rarely actually take notes. So when I saw the Spark Notebook I was somewhat sceptical but the whole structure and design seemed really thought through and as if it could actually fit into my setup and fill the gaps I was having. So I decided to &lt;a href=&#34;https://twitter.com/mrtazz/statuses/535621491392806912&#34;&gt;back the campaign&lt;/a&gt; and early February I got my 2 spark notebooks for 2015 and started using them.&lt;/p&gt;&#xA;&lt;h3 id=&#34;how-i-use-it&#34;&gt;How I use it&lt;/h3&gt;&#xA;&lt;p&gt;The arrival of the notebooks coincided with the first Monday of February for me. So that Monday morning I sat down to start to fill out my yearly, monthly and weekly goals. The notebooks had actually arrived on the weekend already. However other than looking at them quickly I didn&#39;t touch them but spent the weekend researching the intended use of the notebooks on the &lt;a href=&#34;https://popforms.com&#34;&gt;popforms&lt;/a&gt; site. I read about how to set the &lt;a href=&#34;https://popforms.com/how-to-create-a-yearly-theme/&#34;&gt;yearly theme&lt;/a&gt;, &lt;a href=&#34;https://popforms.com/getting-things-done-my-monday-morning-routine/&#34;&gt;create goals for the month&lt;/a&gt; and how to &lt;a href=&#34;https://www.kickstarter.com/projects/katemats/spark-notebook-a-place-for-your-life-plans-and-gre/posts/1121110&#34;&gt;plan your week&lt;/a&gt;. This first review probably took a whole hour or so for me because I had to do the whole thing. But it was actually a pretty good exercise and a great way to reflect a bit more about the things I have on my todo list. Since I&#39;ve written my original blog post about OmniFocus, I&#39;ve added a couple of useful perspectives and one of them is for planning my weeks and days. It&#39;s basically modeled after &lt;a href=&#34;http://simplicitybliss.com/blog/omnifocus-perspectives-redux-planning&#34;&gt;this blog post&lt;/a&gt; and shows all not on-hold or blocked projects from which I then pick things to work on every day. This perspective was the basis for my monthly and weekly planning with the spark notebooks. It reflects all my duties and obligations. For this first review after I set my yearly goals, planned my month to be in line with those goals (in an ideal world your work projects align with your yearly goals but in reality it&#39;s a healthy mix of things you have to do and things that bring you closer to your long term goals) and then planned my weekly tasks according to my montly plan I went on to &lt;a href=&#34;https://popforms.com/how-to-do-time-blocking/&#34;&gt;time blocking&lt;/a&gt;. I grabbed my calendar and put all the meetings in the time blocking view of the spark notebook. I then went ahead and filled all slots (or most of them) where I didn&#39;t have meetings with blocks for things I wanted to get done from my weekly goals. And after this hour or two of planning I went into my week. The following weekly and monthly reviews were much quicker as I didn&#39;t have to do everything from scratch again. To the point where my weekly reviews take me between 15 and 30 minutes right now.&lt;/p&gt;&#xA;&lt;p&gt;A somewhat big surprise was however that it turns out I can&#39;t plan my whole week with time blocks in advance. I did that for the first two and every time interruptions and unplanned work and meetings destroyed my carefully layed out plan. So now I timeblock the first 2 or 3 days of the week on Monday and then do it again on Wednesday for the rest of the week. And while doing that I literally put those blocks into my calendar as well so people see that I&#39;m working on something during that time and that no meetings should go there if possible. I also stopped putting meetings in the spark notebook outline as it was somewhat a double maintenance of the same thing. So the calendar for me holds the daily outline of meetings and blocks of time where I wanna do work. And the notebook tells me how I have planned to spend those time blocks. This has worked pretty well for me so far and I definitely have more structured time than I used to.&lt;/p&gt;&#xA;&lt;p&gt;Another great tool in the notebook are the meeting notes templates. They give you a structured form in which to write your notes down. Although I have some problems with this feature (see below) I&#39;ve really come to like them for facilitating PostMortems. They are great for taking notes during the reconstruction of the timeline and the &#34;Follow Up/Nest Steps&#34; box is perfect for jotting down remediation items before transferring them to Jira. I don&#39;t use the &#34;Main points&#34; box as it doesn&#39;t make a ton of sense for PostMortems and I still rarely take notes in other meetings (something I definitely want to get better at).&lt;/p&gt;&#xA;&lt;h3 id=&#34;balancing-it-with-omnifocus&#34;&gt;Balancing it with OmniFocus&lt;/h3&gt;&#xA;&lt;p&gt;A point I was curious about when I ordered the notebook was how this could be balanced with my OmniFocus setup. I rely heavily on OmniFocus and everything that needs to get done has a place in there. And I really didn&#39;t want to end doing duplicate work. So for the first week or two it felt kinda weird. I was a bit confused about where to look for what to work on next and which things to track where and in which granularity. I started out with a pretty detailed time blocking setup in the notebook and followed that one closely. But that turned out to be too much. I found my natural balance there to put the higher level tasks/projects in the time blocks and then have the break down of those in OmniFocus. This means I can have the overview of what I am supposed to work on in a given time slot in the notebook and then just open OmniFocus to see what the next important part is for that project. Thus I still do my weekly review in OmniFocus and then go on to plan the week in the spark notebook picking things from the OmniFocus &#34;Plan&#34; perspective.&lt;/p&gt;&#xA;&lt;p&gt;The natural balance there is that the spark notebook gives me the higher level overview of my plans that I was always missing in OmniFocus. It&#39;s a really great software for structuring lists, todos and break projects down into smaller things. But I have never figured out a great way to plan the higher level in there. And that&#39;s where the spark notebook fits in perfectly for me. So when I start to work in a time blocked slot, I check the notebook what I have noted down to work on during that time and then check OmniFocus for the next action on that project. This sounds a bit more tedious than it really is, often enough I remember what I allocated the time block for and don&#39;t need to open the notebook and even if I do, it&#39;s not a ton of overhead.&lt;/p&gt;&#xA;&lt;h3 id=&#34;short-comings-and-things-that-dont-work-for-me-so-far&#34;&gt;Short comings and things that don&#39;t work for me (so far)&lt;/h3&gt;&#xA;&lt;p&gt;After using the spark notebook for a couple of weeks now I have found a couple of things that unfortunately didn&#39;t work that well for me or that I was missing. None of them are a dealbreaker and I wasn&#39;t expecting everything to make perfect sense, since it&#39;s probably impossibly to make something work for so many people with different work and life styles.&lt;/p&gt;&#xA;&lt;p&gt;The first thing that I was missing was more bookmarks. The spark notebook comes with 2 bookmarks to quickly find pages. I&#39;m using one to mark my weekly time block table and the other one to mark the position of where I left off with meeting notes. However I would love to have at least two more to be able to quickly find the monthly overview and the project pages. Maybe even three to also quickly find the scribble pages at the end. And I would love it if the spark notebook also had a Moleskine style pocket in the back to put smaller cards and notes in.&lt;/p&gt;&#xA;&lt;p&gt;Speaking of the meeting notes, I&#39;m really enjoying the layout and it&#39;s extremely good for taking structured meeting notes. However the fact that there is only a limited number of them means that I&#39;m constantly trying to decide if a meeting is important enough to &#34;waste&#34; a meeting page if there is a chance that I&#39;m not taking notes at all (did I mention that I&#39;m a poor notetaker?). Especially with the anxiety to run out of meetings notes in my spark notebook and then having to bring a second notebook to meetings. I don&#39;t think this is something that can be fixed within the spark notebook but I have to be ok with.&lt;/p&gt;&#xA;&lt;p&gt;I have also yet to find a use case for the project planning pages and the scribble/free use pages at the end. My problem with the project planning notes is that it&#39;s easier for me to keep that part in OmniFocus (at least the task breakdown, I could definitely benefit from doing a more formal write up of the goals and notes write up) and easier to find as I don&#39;t have a bookmark left over to use for the project pages. Kind of the same goes for the free use pages at the end for me. I haven&#39;t really used them yet as I can&#39;t bookmark them and I&#39;m afraid of running out.&lt;/p&gt;&#xA;&lt;p&gt;The 30 day challenge is something I&#39;m really torn on. I love the idea but it&#39;s been really hard for me to follow. I&#39;m not sure if it&#39;s because it&#39;s a bit out of sight in the weekly plan (maybe I should account time for it in the time blocking more) or something else. But something I want to try there is to always mention the challenge as another weekly goal in the plan and see if that helps.&lt;/p&gt;&#xA;&lt;p&gt;As I mentioned above, I also had to adapt my time blocking routine to do it twice a week as planning all time blocks for the week in advance doesn&#39;t work for me. I have so far also written down 6-7 goals per week as this seems to be the number of things I can actually find the time to work on. I don&#39;t always finish all of them and I might try to break them down more in the future.&lt;/p&gt;&#xA;&lt;h3 id=&#34;verdict&#34;&gt;Verdict&lt;/h3&gt;&#xA;&lt;p&gt;While I haven&#39;t yet fully come to use all the features the spark notebook provides, it&#39;s really been a great addition to my planning tools. Especially since I&#39;ve always missed a higher level planning overview with OmniFocus, this is where the notebook fits in great for me. It gives me a good sense of the higher level things I need to do and whether or not I have allocated time for it appropriately on a weekly level. I use both tools to plan work and non-work related things and the combination of the spark notebook and OmniFocus has definitely become &lt;a href=&#34;https://twitter.com/mrtazz/status/577961903995113472&#34;&gt;crucial to my productivity&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/03/18/spark-notebook-omnifocus.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;When the &lt;a href=&#34;http://www.thesparknotebook.com/&#34;&gt;Spark Notebook&lt;/a&gt; got announced on Kickstart</summary>
  </entry>
  <entry>
    <title>Deployment is Unix</title>
    <updated>2015-02-23T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-02-23:/02/23/deployment-is-unix.html</id>
    <content type="html">&lt;p&gt;Over the last 3 years I&#39;ve worked a lot on &lt;a href=&#34;https://github.com/etsy/deployinator&#34;&gt;Etsy&#39;s deployment system&lt;/a&gt; (we&#39;ve recently &lt;a href=&#34;https://codeascraft.com/2015/02/20/re-introducing-deployinator-now-as-a-gem/&#34;&gt;brought the Open Source version back into sync with our internal changes&lt;/a&gt; and are running on the public version now as well). It&#39;s at the core of our development process as all development is framed in the context of continuously deploying small changes to the website. And the process of putting in feature flags and always comitting to master follows from that. Deployinator is a Sinatra/Ruby application that executes Bash scripts and commands in the background. It has two buttons - for staging and production - that run the (shell) commands to execute a list of deployment tasks. The usual tasks include refreshing the git checkout on the build box, building/minifying JavaScript and CSS, compiling templates, and rsyncing code to all the web servers (with our &lt;a href=&#34;https://codeascraft.com/2013/07/01/atomic-deploys-at-etsy/&#34;&gt;atomic deploys&lt;/a&gt; there is also some symlink flipping involved). But that&#39;s it, it&#39;s a very simple concept.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://speakerdeck.com/mrtazz/the-road-to-success-is-paved-with-small-improvements?slide=68&#34;&gt;&lt;img src=&#34;/images/deployinator-ruby-bash.png&#34; alt=&#34;deployinator - ruby in the front, bash in the back&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Of course the overall application has a lot of features. And they keep growing and changing as we figure out how a growing engineering team is using it. As we have remediation items coming from PostMortems. And as more teams need and add more deployment stacks for slightly different applications. The original version of deployinator had an execution model where all commands where executed in a streaming manner within an HTTP request. That meant we had to configure the correct output buffering, had a long running request doing the work and generally a somewhat confusing scenario where we often weren&#39;t sure what would happen when you close your laptop lid in the middle of a deploy. We also started to run into problems where the deploy would often break with SSH broken pipe errors (all commands are run over ssh) in the middle of a run. We tracked it down to an oddity in TCP behaviour between modern versions of OSX and Linux. And we decided that it was time to move the deploy run out of the HTTP request. We thought about different ways of doing that and prototyped a couple of things. And then one day while working on one of the prototypes of the new deployment model I took a step back and realized that I was basically trying to &lt;a href=&#34;https://twitter.com/mrtazz/statuses/380547968174415872&#34;&gt;reimplement OS process management in Ruby&lt;/a&gt;. And this was not what I wanted Deployinator to be. Deployinator is &lt;strong&gt;UNIX&lt;/strong&gt;. So a deployment is now done by &lt;a href=&#34;https://github.com/etsy/deployinator/blob/master/lib/deployinator/app.rb#L183&#34;&gt;forking into a separate process&lt;/a&gt;, setting the process title to the stack and stage name and letting it run. &lt;code&gt;ps&lt;/code&gt;, &lt;code&gt;kill&lt;/code&gt;, &lt;code&gt;nice&lt;/code&gt; all still work. If you need to log into the deployment server and figure things out, you can still use the tools you use every day. The rest of Deployinator also always has been very UNIX inspired. The deployment process runs commands over ssh and distributes commands to multiple machines via &lt;a href=&#34;https://www.netfort.gr.jp/~dancer/software/dsh.html.en&#34;&gt;dsh&lt;/a&gt;. All deployment output is written to a log file. The log file is tailed by a websocket server to present it back to the web application. The log in the web app shows all output of what the shell commands are doing. If the commands write to STDERR, Deployinator shows it in red and bubbles it up to a separate error log. This means you can write your deployment commands in the well known UNIX style. Infos go to STDOUT, errors go to STDERR. In addition Deployinator also comes with a command line tool to kick off any deploy without needing a working web server.&lt;/p&gt;&#xA;&lt;p&gt;And in my opinion this is how it should be. The actual steps of how your software gets deployed will always be a little different. You might run a Rails app instead of a PHP application. You might have a compiled binary that needs to be shipped or you will have to restart services. You might git pull on the servers directly instead of rsyncing files over. But there is always the operating system as the common denominator (or almost always). And by using that foundation in your tooling you already have a common ground when it comes to understanding and debugging what your deployment system does. And there are a lot of existing tools, like rsync, git or ssh which you can reuse and leverage. There is also a &lt;a href=&#34;https://gist.github.com/atmos/6631554&#34;&gt;great response&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/atmos&#34;&gt;Corey&lt;/a&gt; about how the GitHub deployment system works. And the final paragraph there is really what I love most about it:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;I think people would be underwhelmed by the technology and implementation though. It&#39;s just a bit of ruby, UNIX, and HTTP. It&#39;s not pushing the boundaries of computing, it just chugs along doing its job so we don&#39;t have to.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;And it really doesn&#39;t have to be complicated. Deployment can start with a simple shell script. And then you can wrap it in a web frontend. Or an IRC command. Or an iPhone app. But at its core it&#39;s still manipulating files and putting them on a computer. Deployment is still UNIX.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/02/23/deployment-is-unix.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Over the last 3 years I&#39;ve worked a lot on &lt;a href=&#34;https://github.com/etsy/deployinator&#34;&gt;Etsy&#39;s </summary>
  </entry>
  <entry>
    <title>You Shouldn&#39;t Have To Ask For Forgiveness</title>
    <updated>2015-02-04T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-02-04:/02/04/forgiveness.html</id>
    <content type="html">&lt;p&gt;A couple of days ago I was part of a private email thread about the popular Grace Hopper quote &lt;a href=&#34;http://en.wikiquote.org/wiki/Grace_Hopper&#34;&gt;&#34;It&#39;s easier to ask forgiveness than it is to get permission.&#34;&lt;/a&gt; and the somewhat related &lt;a href=&#34;https://medium.com/@katelosse/the-unbearable-whiteness-of-breaking-things-521cb394fda2&#34;&gt;blog post&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/katelosse&#34;&gt;Kate Losse&lt;/a&gt; (please go and read it first, it&#39;s really good). I got a helpful and friendly nudge to put the response I wrote on here, so here it is in a slightly edited version to fit the format:&lt;/p&gt;&#xA;&lt;p&gt;I have so many opinions on that and I hope the following brain dump makes sense/helps.&lt;/p&gt;&#xA;&lt;p&gt;I should start off with the disclaimer that I think there is something to that quote but it&#39;s been completely repurposed to serve as a backwards justification for a lot of things. I think the variant &lt;a href=&#34;http://en.wikiquote.org/wiki/Grace_Hopper&#34;&gt;&#34;If it&#39;s a good idea, go ahead and do it. It is much easier to apologize than it is to get permission.&#34;&lt;/a&gt; is a much better version (although still problematic) of this quote. But I highly dislike the often quoted form together with its corollary &#34;move fast and break things&#34; which basically has the vast majority of the same problems.&lt;/p&gt;&#xA;&lt;p&gt;So why do I dislike it? First and for all because it&#39;s arrogant and disrespectful. It has the implication that rules don&#39;t apply for some (for a certain value of some) people and that it is in their judgement to decide what applies to them. It also implicitly means, because (usually though not always) rules are made to protect/help people, that what you want to do is more important than protecting/helping. I&#39;m probably extremely biased because I work in infrastructure where a large part of work is maintenance. But in computering what following this rule most likely means is hack something together that works and then figure out how to maintain it and who. And in that regard it often comes down to upholding the romantic VC notion of a 10X engineer/lone wolf programmer who is so genius that you have to get everything out of their way because they can change the game in an instant. That they don&#39;t have to communicate, follow rules, or workflows, because their beautiful mind justifies everything. Another thing I highly dislike.&lt;/p&gt;&#xA;&lt;p&gt;The next problem I have with this statement is that it is so ambivalent that it doesn&#39;t really mean anything. And as so often, can only be verified in hindsight. The article you linked really pin pointed one of the major problems there. In order to be granted forgiveness, you are betting on &#34;the authority&#34; (this could be your manager, execs or tech leads, or even the police) to turn a blind eye on something you did or even praise you for breaking the &#34;law&#34; for making things better. This usually is only the case if you are a member of the same race, culture, class, group as those you will have to ask for forgiveness. Which doesn&#39;t work well for everybody. It&#39;s also important here, that - if I&#39;m not mistaken - the quote comes from a time where Grace Hopper was almost retired and already an accomplished Rear Admiral. The power and influence that comes with such a rank shouldn&#39;t be neglected. And I highly doubt that the same thing worked when she was a Sea(wo)man or Petty Officer.&lt;/p&gt;&#xA;&lt;p&gt;That being said there is something to that quote. But as I said in the beginning, I see it more in the context of the variant quote. And more importantly in the context of &lt;a href=&#34;http://en.wikipedia.org/wiki/Efficiency–thoroughness_trade-off_principle&#34;&gt;efficiency thoroughness trade-off&lt;/a&gt;. A lot of times you can&#39;t ask everyone for permission to do something because it takes too much time and doesn&#39;t make sense. Especially when it comes to computering there is often a lot of merit in trying to get a prototype in place so there is a concrete thing to talk about. It&#39;s also often worth it to only bounce ideas off of a handful of people before trying it out instead of getting a formal review and the exec&#39;s agreement to do it. But with all of this the impact if it&#39;s a bad idea has to be taken into account. If everybody runs off doing their weird ideas, we likely would have chaos. At the same time if everybody spends their day with getting permissions about work, there won&#39;t be any work getting done. Ideally we trust our colleagues that they know what is needed to bring things forward. That is why there are always tendencies to reduce bureaucracy and empower individuals. But I don&#39;t think this means you should do things where you have to ask for forgiveness. Because if you have to, you likely made someone else&#39;s day pretty miserable.&lt;/p&gt;&#xA;&lt;p&gt;I hope this was a somewhat coherent write up and answers at least some of the questions you had. Also I&#39;m super happy to be proven wrong here since this is very likely a pretty narrow view on things.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/02/04/forgiveness.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A couple of days ago I was part of a private email thread about the popular Grace Hopper quote &lt;a</summary>
  </entry>
  <entry>
    <title>You&#39;re building a Plant</title>
    <updated>2015-01-28T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-01-28:/01/28/building-a-plant.html</id>
    <content type="html">&lt;p&gt;As an infrastructure engineer you&#39;re building a plant. Not literally of course but it&#39;s also not too far off. There are actually a lot of parallels to building a chemical plant. I used to work for a chemical company a couple of years back and I have thought a lot about the similarities ever since I started working at Etsy and with that on infrastructure for a running website. This is why I decided to write down how I think about IT infrastructure projects. However as it&#39;s been years since I set foot in a chemical plant, most of the things I&#39;m gonna mention and explain are probably outdated and might be handled differently now. So take what I say with a grain of salt and don&#39;t run off trying to build a chemical plant with this, please.&lt;/p&gt;&#xA;&lt;h3 id=&#34;building-a-plant&#34;&gt;Building a plant&lt;/h3&gt;&#xA;&lt;p&gt;The general setup of a plant is most often pretty structured on a high level. You have a process that someone invented at some point. You burn sand or combine acid to create a new product that has properties which are desirable. Then you probably spent a lot of time improving and refining the process and making the actual plant work better (this is where the vast amount of IP and patents come from). And at some point you end up with a pretty good and structured plan how to repeat it all over the world. Of course the process refinements never stop but they get a little smaller over time.&lt;/p&gt;&#xA;&lt;p&gt;Then at some point the time comes to build a new one, maybe at a new location maybe at an old one. But you as the engineer (or project manager at that point) get told that a new plant is needed. You likely have done that many times before. So you&#39;re grabbing the documentation, maybe a project plan template for it and you start planning. This is really where the first important parts come together. A plant is build by tens or hundreds of people all in all. But at this stage you have to make sure you&#39;re getting the right people on the project for each component of the plant. Obviously there will have to be some buildings. So you go to Facility Management and ask for an engineer to work with you on the project. You don&#39;t have to know how to construct buildings yourself, but it&#39;s an important part of the plant so you get an engineer you can delegate the work to. Of course a dark, empty building isn&#39;t that helpful. We are gonna put a ton of machinery in there. And all of it needs power. So you&#39;re gonna get an electrical engineer on the project to plan out the electrical infrastructure and hook the plant up to power. Someone also has to actually install all that machinery, make sure you&#39;re choosing the right parts and devices, work on the actual construction. This means, you gotta get an engineer to supervise that. Once the plant is running there are a lot of things that constantly need regulation. Water flow, temperature, air flow, all those things need to be controlled and automated. You&#39;ll get an automation, measurement and control engineer to take care of this of course. And in the end this is also about a chemical process, so a chemical engineer will also be on the project. With all these engineers on board, it&#39;s your job to keep them all on the same page. You have to set up meetings, establish communication and make sure everyone is included on updates since changes might influence their area of work.&lt;/p&gt;&#xA;&lt;p&gt;This is only an exemplary run down of what goes into building a plant. Depending on what kind of engineer you are and the size and complexity of the plant you might be doing one those things yourself. But for a big project you might also just be the technical project lead and delegate all of those things to others.&lt;/p&gt;&#xA;&lt;h3 id=&#34;building-infrastructure&#34;&gt;Building infrastructure&lt;/h3&gt;&#xA;&lt;p&gt;So let&#39;s talk about the other kind of infrastructure projects. Where computers are involved. Because they aren&#39;t that different. Sure they are often much cheaper, you rarely get to work on a giant multi million dollar project. It is also much easier and cheaper to experiment if you&#39;re writing software. You can experiment with things before the whole project is done, change directions much more quickly and generally see intermittent results with less hassle. And you usually don&#39;t have to manage tens of people and contractor companies on the project. On the other side you are usually trying something new, so you don&#39;t have the security of having done this before multiple times. You have to come up with a lot of things for the first time as you are trying to solve problems with this new piece of infrastructure (this is why it might also be a good idea to write down a &lt;a href=&#34;http://www.d2fn.com/2013/01/28/functional-specifications-for-infrastructure-engineers.html&#34;&gt;spec for your project&lt;/a&gt;, to give you a better picture of what parts are actually involved).&lt;/p&gt;&#xA;&lt;p&gt;But the big thing both types of projects have in common is the collaboration and delegation part. You most likely won&#39;t have to deal with facility management, construction and maybe not even electrical power in your project. But there are still a lot of parts. The software you plan to write or the service you want to introduce is probably gonna run on some form of computer. And although it has become way easier to spin up a virtual machine or commission some hardware, you probably want to at least talk to an ops engineer about it. There could be different classes of machines to choose from that have proven to work better for different workloads. The requirements for hardware (virtualized or real) could change if the scope or implementation details of the project change. It could be that new machines are automatically added to the monitoring system unless you tell it not to. And speaking of monitoring: there should be some. And generally there is a lot of knowledge in Ops about monitoring things. You also want to automate the setup for your new service, write some Chef or Puppet to make it smooth to create new instances. Which is probably another thing your ops team can help with. So ask for an ops engineer to be on your project. Some infrastructure services also need to persist data. Maybe you need a cool new database, although likely there is already an existing place where you can put data. In any way this is something where an Ops engineer (or DBA) can help with as well. As soon as you access and write data, call to other services, maybe need some form of authentication or have a naive implementation where you shell out in your PHP code you should have a security engineer on board to make sure it doesn&#39;t end badly. Even if you don&#39;t think you are, having someone from security on board for the project or maybe even just review code changes a lot. Suddenly it&#39;s not that weird service anymore that someone put into production. You get code review from a very different angle and have the good feeling of everything being alright. Of course your new thing also has a ton of tests. Unit tests are the simple thing here, as you can probably hook them up to your existing CI infrastructure. However there might be integration and end-to-end tests that you want to create to increase confidence in changes when someone else (and also yourself) works on the project. So when you start of the project, include someone from your testing/QA/CI infrastructure team. You want to increase confidence in changes with your new piece of infrastructure and engineers working close to testing can definitely help. And speaking of confidence, there should be a way of making things work in development as close as possible to how they are in production. There should be a way to run it on a VM, on your laptop or some other way where you can be sure changes you make in development work in production. If you have a team that takes care of those things, get an engineer from that team involved. Make sure they know that you care about things working in development.&lt;/p&gt;&#xA;&lt;p&gt;Recently, with the increased focus on cross team collaboration, there is a big chance that you can do a lot of those things yourself. And you should, it&#39;s a great way to learn (although that doesn&#39;t mean you shouldn&#39;t talk to the engineers that work in those areas every day). But you can&#39;t do everything yourself, so depending on the scale of the project and your familiarity with all those areas, there will have to be delegation. And not all projects touch all of those things. You might not have data to persist. Or you already have an internal auth solution that you can plug in. However when in doubt it&#39;s always better to err on the side of caution and include more people or ask them if they think the project would benefit from it. The important part is to take the time to talk to people and let them know you want their input on the project or you want them to also work on the project. And then create a mailing list, or a forum group or an IRC channel or however you handle communication in your organization and invite all those engineers to join and make it clear that project communication will happen there. You want them to always know where they can get information about the project, its progress and an up-to-date status in case they want to check if the project touches things they work on. And not have to be afraid they might miss things.&lt;/p&gt;&#xA;&lt;p&gt;Because you&#39;re building a plant. Kind of.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Thanks to &lt;a href=&#34;https://twitter.com/benjammingh&#34;&gt;Ben Hughes&lt;/a&gt; for reading drafts of this, giving me feedback and being generally rad.&lt;/em&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/01/28/building-a-plant.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;As an infrastructure engineer you&#39;re building a plant. Not literally of course but it&#39;s also not </summary>
  </entry>
  <entry>
    <title>Learning to be On-Call</title>
    <updated>2015-01-06T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2015,2015-01-06:/01/06/learning-on-call.html</id>
    <content type="html">&lt;p&gt;I stumbled upon this great &lt;a href=&#34;https://medium.com/@thematthewgreen/on-call-dont-be-scared-4eef4ff2928f&#34;&gt;blog post about on-call&lt;/a&gt; the other day. It&#39;s a great article and you should definitely go read it first. It prompted me to think about my own experience with being on-call and while I don&#39;t have years of it, in the last 2.5 years I went from never having been on-call before to being somewhat experienced in it. And especially the closing quote of the aforementioned article about being scared of on-call really hit home for me:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Don’t be. While being on-call can be challenging, it is also very rewarding.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;This is why I wanted to share my personal development and experience about learning to be on-call. Because fundamentally I am convinced that it&#39;s not only a necessary but also a rewarding thing to do. When I started at Etsy &lt;a href=&#34;https://twitter.com/mrtazz/statuses/147115673137577984&#34;&gt;a bit over 3 years ago&lt;/a&gt; I had never worked anywhere where I had to be on-call. I was either too junior (engineers in training didn&#39;t have to be on-call) or I was working on research and actual shipped software where there were no production systems to look after. And when I applied for jobs I even actively sought out job positions where I didn&#39;t have to be on-call a lot as I saw it as a tedious, annoying and scary thing that I didn&#39;t want to do.&lt;/p&gt;&#xA;&lt;h3 id=&#34;how-i-got-into-this&#34;&gt;How I got into this&lt;/h3&gt;&#xA;&lt;p&gt;Then when I joined Etsy every engineer had to sign up for a week of general developer on-call per year (almost all of our on-call rotations are a week long). This is the general on-call rotation for anything relating to the web app of &lt;a href=&#34;https://etsy.com&#34;&gt;etsy.com&lt;/a&gt; where the knowledge of how things work an ops engineer usually has doesn&#39;t suffice. We have amazingly good ops engineers who can fix a ton of things themselves and if you have a really bad on-call week you get paged once as a developer. Back then we were small (or big) enough so that we could cover the year with every one being on-call at most once. That wasn&#39;t too bad and so I put my week in about 6 months after I started so I could learn some things about the web application before actually being on-call. Since my team works on developer tooling and not the website itself I chose this quite long period of time before my first on-call just because I wouldn&#39;t have that much exposure to the app in my regular workday. Lucky me, I happened to choose the week that included the weekend where we wanted to upgrade our main SPOF database. So needless to say, I was really scared of the on-call. I didn&#39;t have enough knowledge about the architecture to know where things could break or debug it and I had never been on-call before so even having to pay attention to whether or not I had cell reception all the time was already making me nervous. I also hadn&#39;t been at Etsy long enough to know how often I would get paged, how serious/time-sensitive a page would usually be, whether or not I could be underground for 30 minutes to take the subway home, which action should I use to tell PagerDuty that I&#39;m working on the incident, and what even would happen when I get paged and what to do next. Most of this was just me being nervous. We had a lot of documenation about being on-call and a lot of people to talk to. And I stayed up all night during the database upgrade and didn&#39;t even get paged a single time. The whole thing was planned really well and all the people who knew how the site worked were already online and it turned out to be an invaluable learning experience for me.&lt;/p&gt;&#xA;&lt;h3 id=&#34;getting-used-to-the-game&#34;&gt;Getting used to the game&lt;/h3&gt;&#xA;&lt;p&gt;Then after my first year or so we changed the on-call schedule a bit. We had more engineers than we needed to fill the dev on-call rotation. We started to have more specialized teams who would take on their own on-call and were thus excluded from the generic one. So we switched to a system where you could volunteer to be on-call every 4 weeks or so for a week. We set it up to be two tiered so if you&#39;ve never been on-call, you would be the L1 contact who gets paged first. If you really can&#39;t get to a computer or have no clue what to do, you can escalate to the L2 who is more senior and has experience with being on-call. And then after 6 months you were released from the rotation and a new round started where engineers could volunteer. I signed up immediately when this got introduced. I wanted to learn more about what it means to be on-call. The rotation was still super quiet and I almost never got paged. But just the fact that I would now have to bring a charged phone, a Mifi and a laptop with me wherever I went every 4 weeks made on-call less of a scary exception but a scheduled routine. This took away a lot of my fears. I learned a lot about how noisy of a rotation to expect, how to plan my day so that I would have cell reception all the time, and how to react when I got paged. I still felt awkward being on-call because I still almost never really knew the parts involved when I got paged. I would work as a communication broker to call in the right people but I could hardly ever fix things myself. Again I learned a ton from watching the people I called debug and fix problems, especially in parts of the app I had never touched before. But after a while it was also somewhat unsatisfying to almost never get paged and then if a page happened, not being able to actually do something about it.&lt;/p&gt;&#xA;&lt;h3 id=&#34;level-up-the-ops-rotation&#34;&gt;Level up: The Ops Rotation&lt;/h3&gt;&#xA;&lt;p&gt;In addition to that, by then I had worked on mostly infrastructure things. I worked on a lot of Chef recipes, upgraded all of etsy.com to a new release of PHP and reworked core parts of how software deployment worked. I touched all the things that would wake up an ops engineer (but thankfully never did) and I wanted to own up to the responsibility. But you only ever hear horror stories about ops on-call from almost anyone. Because once you have an automated system being able to wake you up at night (95% of Nagios alerts used to go to the Etsy ops rotation back then) it changes on-call a lot. So to own up to me having changed one of the biggest parts of our stack, I decided to sign up for shadowing the ops on-call engineer for a week. I got my phone hooked into Nagios. And &lt;a href=&#34;https://www.youtube.com/watch?v=uvqJ1mTkEuY&#34;&gt;it got real&lt;/a&gt;. I had added my email a couple of months earlier already to get a feel for the alert volume and to know whether I broke things I was working on but adding your phone is a different kind of real. I chose a week where one of our senior ops engineers would be on-call and I got woken up for everything for a week. It was pretty brutal. I got woken up in the middle of the night and had no idea what Nagios wanted from me. I would log onto IRC and get some information from &lt;a href=&#34;https://twitter.com/ickymettle&#34;&gt;Marcus&lt;/a&gt; what the alert was about and how to fix it. I mostly felt helpless and super slow with debugging what might be causing the production issues at hand. The week ended with a couple of sleepless nights and a site outage on Friday. And I can&#39;t even begin to explain how much I learned during that week. About systems I&#39;ve never seen before, about database replication, about hating disk space alerts, and how to work after being deprived of sleep because of a busy on-call night. And the learning was what got me hooked. A couple of months later I signed up for the ops on-call rotation for good and have been part of it for over a year now.&lt;/p&gt;&#xA;&lt;h3 id=&#34;long-story-short&#34;&gt;Long Story Short&lt;/h3&gt;&#xA;&lt;p&gt;I can honestly say leaning into on-call has been one of the best things I did for growing as an engineer. It put me way out of my comfort zone and I had to overcome a good chunk of impostor syndrome and fear for it. I write software and design systems with a different view now. I have way more experience with all the tools we use to manage our infrastructure - having to find something in Chef at 3am really helps learning your way around it - and a better intuition when it comes to adding things to it. When we added an on-call rotation to my team I was super relaxed because I knew it wouldn&#39;t be anything that I hadn&#39;t dealt with before in the ops rotation. It&#39;s a great feeling to know that you are doing your part to keep things running and you can bond with a lot of other people over sharing on-call pain and &lt;a href=&#34;https://speakerdeck.com/jnewland/optimizing-ops-for-happiness&#34;&gt;how to make things better&lt;/a&gt;. It&#39;s not always fun. In fact it&#39;s fitting that I&#39;m writing this blog post slightly sleep deprived, while I&#39;m on-call, have been woken up almost every night since Friday, had to manage to find someone to cover for me while I&#39;m traveling for a whole day and had to hook up notifications and mobile internet in another country for the first 2 days of on-call. However I&#39;m always happy when I&#39;m done with another on-call week and can look back on the things I learned. After all it&#39;s the challenges through which we grow.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2015/01/06/learning-on-call.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I stumbled upon this great &lt;a href=&#34;https://medium.com/@thematthewgreen/on-call-dont-be-scared-4e</summary>
  </entry>
  <entry>
    <title>2014 Reading List</title>
    <updated>2014-12-31T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2014,2014-12-31:/12/31/reading-list.html</id>
    <content type="html">&lt;p&gt;This year I tried again to keep up the flow of reading books. I&#39;m an awfully slow reader when it comes to books in general (not so much for blog posts interestingly) but I managed to read a handful of books and I wanted to share my thoughts about it. Mostly because I got inspired by reading &lt;a href=&#34;http://www.paperplanes.de/2014/12/30/reading-list-2014.html&#34;&gt;Mathias&#39; reading list&lt;/a&gt; but also because I wanted to have a track record of what I read and hopefully inspire myself to read even more next year.&lt;/p&gt;&#xA;&lt;p&gt;So without further ado, here is my list:&lt;/p&gt;&#xA;&lt;h3 id=&#34;germaine-greer---the-female-eunuchfemale_eunuch&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Female-Eunuch-Germaine-Greer/dp/006157953X&#34;&gt;Germaine Greer - The Female Eunuch&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;I started the year off with finally finishing Germaine Greer&#39;s feminist classic from 1970 about the role of women in modern society. I had known about the book for a couple of years and after having read &lt;a href=&#34;http://www.amazon.com/Will-Change-Men-Masculinity-Love/dp/0743456084&#34;&gt;Bell Hooks&#39; The Will to Change: Men, Masculinity, and Love&lt;/a&gt; last year I decided to finally read it. I definitely enjoyed it. Especially as a man it opens your eyes to a lot of things you never encounter in your daily life. It&#39;s very graphic at times and there are some long-winded parts in the middle but I would definitely recommend it to anyone who&#39;s interested in feminism. I also started reading her newest book &lt;a href=&#34;http://www.amazon.com/Whole-Woman-Germaine-Greer/dp/0385720033&#34;&gt;&#34;The Whole Woman&#34;&lt;/a&gt; this year which is the sequel she never wanted to write. And so far I like it and it&#39;s alarming how few things have changed since &#34;The Female Eunuch&#34;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;erik-hollnagel---the-etto-principle-efficiency-thoroughness-trade-offetto&#34;&gt;&lt;a href=&#34;http://www.amazon.com/ETTO-Principle-Efficiency-Thoroughness-Trade-Off/dp/0754676781/&#34;&gt;Erik Hollnagel - The ETTO Principle: Efficiency-Thoroughness Trade-Off&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;It&#39;s no secret that I&#39;m interested in &lt;a href=&#34;http://www.unwiredcouch.com/2014/08/04/human-error-getting-off-the-hook.html&#34;&gt;human factors and system safety&lt;/a&gt; and how to apply lessons learned to our field of creating and managing complex computer systems. So it also shouldn&#39;t be a surprise that this book really hit home for me. It&#39;s well written and touches on a myriad of different aspects about how we trade off thoroughness for efficiency and how production pressure changes our way of making decisions. It&#39;s a pretty fast read and I really enjoyed it. It also has a huge references and related literature section following each chapter which makes it great to start diving deeper into the topic.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-phoenix-project-a-novel-about-it-devops-and-helping-your-business-winphoenix&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Phoenix-Project-DevOps-Helping-Business/dp/0988262509&#34;&gt;The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;I originally started reading it in 2013 when it came out and I enjoyed it back then. But I somehow still dropped the ball and stopped reading it. I finally went back and finished it this summer. It&#39;s a good and interesting read and having worked in traditional plant production companies I liked a lot of the parallels in there. It gets a little weird at the end and the last quarter feels like the authors really had to wrap up the book. And no matter how you look at it, it&#39;s definitely business romanticism. But if you don&#39;t mind that, it&#39;s definitely entertaining.&lt;/p&gt;&#xA;&lt;h3 id=&#34;susan-cain---quiet-the-power-of-introverts-in-a-world-that-cant-stop-talkingquiet&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Quiet-Power-Introverts-World-Talking/dp/0307352153&#34;&gt;Susan Cain - Quiet: The Power of Introverts in a World That Can&#39;t Stop Talking&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;This is another one I started in 2013 and then dropped for no real reason. I finished it this year and thoroughly enjoyed it. I knew before I started reading that I fall on the introvert side of the scale but the book really helped recognizing some more patterns and making me feel better about it. This is also the only book I finished as a Kindle audiobook and while I likely won&#39;t do it again, it was an interesting experience. It&#39;s a great read and definitely recommended for anyone who works with other humans in their daily life.&lt;/p&gt;&#xA;&lt;h3 id=&#34;kourosh-dini---create-flow-with-omnifocus-2of_flow&#34;&gt;&lt;a href=&#34;http://www.usingomnifocus.com&#34;&gt;Kourosh Dini - Create Flow with OmniFocus 2&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;This one was kind of a surprise read for me. I&#39;ve &lt;a href=&#34;http://www.unwiredcouch.com/2014/05/13/omnifocus.html&#34;&gt;written before&lt;/a&gt; about how much I have OmniFocus is integrated in my life. And when this book popped up &lt;a href=&#34;http://simplicitybliss.com&#34;&gt;in one of my RSS feeds&lt;/a&gt; I decided to give it a read. It&#39;s definitely not a cheap book and I jumped over the first half as it&#39;s basically an introduction into OmniFocus which I already know how to use. The book isn&#39;t a total game changer, but the latter half gives some good food for thought on how to make the most of OmniFocus&#39; Perspectives and some unusual use cases for it.&lt;/p&gt;&#xA;&lt;h3 id=&#34;bonus-jon-cowie---customizing-chefchef&#34;&gt;&lt;a href=&#34;http://www.amazon.com/Customizing-Chef-Jon-Cowie/dp/149194935X&#34;&gt;Bonus: Jon Cowie - Customizing Chef&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;I added this as a bonus round, because while I definitely read it, I had the privilege to do so as a reviewer. I&#39;m really happy that &lt;a href=&#34;https://twitter.com/jonlives&#34;&gt;Jon&lt;/a&gt; asked me to review his book and while I had done a lot of Chef before, I learned tons about its internals from this book. If you work with Chef and want to get more out of it or even just understand some of the internals a little better, definitely read this book.&lt;/p&gt;&#xA;&lt;p&gt;I really enjoyed reading all those books this year. And one of my New Year&#39;s resolutions is definitely to read more next year. I&#39;ve planned to set some time aside every day to read and hope to have a longer list of things I read next year. If not, it sure isn&#39;t because of a small Kindle backlog.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2014/12/31/reading-list.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This year I tried again to keep up the flow of reading books. I&#39;m an awfully slow reader when it </summary>
  </entry>
  <entry>
    <title>3 Simple Things that improved my Work-Life Balance</title>
    <updated>2014-12-15T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2014,2014-12-15:/12/15/work-life-balance.html</id>
    <content type="html">&lt;p&gt;These days productivity and work life balance are two parts of the holy grail of modern life for a lot of people. We have an abundance of projects, things to work on, things that interest us and distractions to keep us from doing all the things we want to do. And so often the solution to this is basically &#34;work more hours&#34; or &#34;have more intelligent notification systems&#34; because more so often looks like better. And I fell into that trap. I worked insane hours (mostly because it was fun and I wanted to learn so much more), jumped on every project and task that seemed remotely interesting to me and had notifications from everything I had ever installed on my phone. I have been that guy who comes home at 1am after hanging out with friends and had this amazing idea how to fix something that couldn&#39;t wait until Monday or even just the next day. So I would hack on things until 3 or 4 am. This didn&#39;t happen often, but it definitely did happen occasionally. And it worked ok for some time. But eventually it all caught up to me and I felt overwhelmed with all the things that were going on. Projects, new things I wanted to learn, notifications, things I wanted to read and people I wanted to talk to or email. Still I was in a generally pretty good situation, since I had managers that told me to work less and made it very clear that this is not what they expected from me. And I wasn&#39;t even in a particularly bad situation, I wasn&#39;t really miserable, I still liked my job a lot and I wasn&#39;t close to a burnout or anything. I just knew I didn&#39;t want to continue like that because work should really be fun and constraint to ... well ... work hours. And it wasn&#39;t really for me anymore, I felt overwhelmed and at the same time like I didn&#39;t get anything done. So this year I started with some very basic realizations:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;There&#39;s always more work that you could do&lt;/li&gt;&#xA;&lt;li&gt;There are always more things to read, watch or catch up on&lt;/li&gt;&#xA;&lt;li&gt;Most notifications don&#39;t really need to interrupt you&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;the-workday&#34;&gt;The Workday&lt;/h3&gt;&#xA;&lt;p&gt;And I started to make some changes from there. The very first one was strict working hours. At the beginning of the year I decided that I will go home at 6.30pm every day. Unless something is really on fire. It really helped that I take the ferry to and from work everyday. So I settled for a ferry schedule that I wanted to take and stuck with it. There are no excuses. All the work I&#39;m doing in the evening will still be there the next day. And there is no work, work email or any such things after I got home. In order to further this more I also &lt;a href=&#34;https://twitter.com/mrtazz/status/536571409674555392&#34;&gt;deleted any work related email and calendar accounts from my personal laptop&lt;/a&gt; a couple of weeks ago. If I want to get more work done I have to get up and start work earlier. In reality this usually plays out to me being in the office around 10am or 10:30 with 30 to 45 minutes of working from home before that. Usually I check email and try to flag things I want to get done that day in &lt;a href=&#34;http://www.unwiredcouch.com/2014/05/13/omnifocus.html&#34;&gt;my OmniFocus&lt;/a&gt; at home as it&#39;s more quiet, earlier in the day, and less busy. Obviously there are exceptions to this, as I said already when things are on fire, when I&#39;m on-call of course, or when I&#39;m really in the zone and don&#39;t want to stop (although this is really really rare after 5:30pm to be honest). On regular days I stick to my working hours.&lt;/p&gt;&#xA;&lt;h3 id=&#34;reading-things&#34;&gt;Reading things&lt;/h3&gt;&#xA;&lt;p&gt;The next step was embracing the fact that there is always more to read. I&#39;m pretty &lt;a href=&#34;http://www.unwiredcouch.com/2014/08/29/email-happiness.html&#34;&gt;happy with my e-mail setup&lt;/a&gt; but it took some time to be ok with heavy filtering and only checking it occasionally. And in addition to not having any sort of notifications for my work email I have also turned off icon badges in the iPhone mail client (except for VIP mails from friends and family). The number of unread emails doesn&#39;t really mean anything other than that it causes you to keep checking it because it&#39;s a pattern of &#34;todo&#34; items. And you really want to get this number down. For no particular reason other than that it feels good to cross things off. So it&#39;s easy to get into the habit of keep doing it. I realized that the icon badge doesn&#39;t actually mean anything for me as all the emails I need to answer are in my OmniFocus so there is no need for badges on my email client. I also turned off unread count badges for basically everything else, but most notably &lt;a href=&#34;http://reederapp.com/ios/&#34;&gt;RSS feeds&lt;/a&gt; and &lt;a href=&#34;http://getpocket.com&#34;&gt;articles I&#39;ve saved for later&lt;/a&gt;. Reading things shouldn&#39;t be a chore but something you enjoy when you have the time. I always felt bad that I have so many things pile up in my different accounts. And it ended up being a constant hassle of cleaning up the lists in there, instead of enjoying the things I can read from it. So I stopped feeling bad about having an insane backlog of articles in my queue and now see it more as a big pool of interesting things to read when I have the time (thank you &lt;a href=&#34;https://twitter.com/mikebrittain/status/539198323471962112&#34;&gt;Mike for this&lt;/a&gt;).&lt;/p&gt;&#xA;&lt;h3 id=&#34;notifications-and-the-phone&#34;&gt;Notifications and the phone&lt;/h3&gt;&#xA;&lt;p&gt;So that leaves notifications. You have probably realized by now that every app on your phone competes for your attention. And even more so with notifications. Every single app wants to be able to push notifications to your phone. Even if it&#39;s just a game that wants to remind you what you&#39;re missing while you&#39;re not playing. So while realizing that a ton of things actually don&#39;t need my attention, I started to divide the things on my phone into 3 groups. The first one is allowed to push notifications, make sounds and interrupt me and they are basically only the phone and messages app for SMS. The second group is stuff that I care about enough to allow notifications but isn&#39;t urgent. Twitter clients, Foursquare and Pushover (which I use to tell me about IRC mentions when I&#39;m idle) notifications fall into that. Whenever I have time I&#39;ll skim through the notifications on the lock screen on my phone but nothing in that list is allowed to make a sound or vibrate the phone. And all the other apps on my phone don&#39;t get to push notifications at all. My notification setup has also much improved since I got a &lt;a href=&#34;https://getpebble.com&#34;&gt;Pebble&lt;/a&gt;. While it&#39;s not crucial, it makes checking notifications a matter of a handful of seconds by flicking my wrist versus checking my phone. The downside is that when it comes to vibration it&#39;s all or nothing on the Pebble. Right now it doesn&#39;t bother me much but is definitely something I&#39;m watching out for in case it gets annoying. And in addition to cleaning up notifications I also cleaned up my iPhone&#39;s home screen while I was at it. I only have things on there that I actually (want to) use every day. That way my phone looks and feels way less cluttered (and it&#39;s way more fun to have wallpapers).&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/iphone-screen.png&#34; alt=&#34;iPhone homescreen&#34; /&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;what-else&#34;&gt;What else?&lt;/h3&gt;&#xA;&lt;p&gt;Changing those simple habits has made a big impact in my life. I&#39;m definitely more exhausted when I get home because I&#39;m trying to get as much done as possible during the day. But at the same time I&#39;m super &lt;a href=&#34;https://twitter.com/mrtazz/statuses/467076737105674240&#34;&gt;excited to get back to work the next morning&lt;/a&gt;. My phone doesn&#39;t make a noise except for really important things, so although I have work email and calendars on there, when I just have it in my pocket or on a table it doesn&#39;t remind me of work things after work (I disconnect the Pebble when I get home as I don&#39;t have a need for it there). I actually feel less stressed out about my phone and interruptions all day and get more out of the things I actually want to do on my phone.&lt;/p&gt;&#xA;&lt;p&gt;There are still some things I want to improve though. I definitely don&#39;t spend as much time reading as I want to. Something I want to try there is take a page from &lt;a href=&#34;http://blog.travis-ci.com/2014-09-04-10-things-i-do-to-stay-productive/&#34;&gt;my friend Mathias&#39; book&lt;/a&gt; and get 30 minutes of reading in every morning before I head into the office. At the beginning of the year I have also started to keep a work journal to jot down things that happened during the day and that I worked on. And I would love to expand that to also include non-work related things.&lt;/p&gt;&#xA;&lt;p&gt;I&#39;m also notoriously bad about taking vacation days. I usually end up with a 2 to 3 week long vacation at the end of the year because I need to use up all my days. I really want to get back to taking a longer time off in the middle of the year to enjoy the summer and spread more days off over the year.&lt;/p&gt;&#xA;&lt;p&gt;What did you do to improve your work-life balance this year? &lt;a href=&#34;mailto:d@unwiredcouch.com&#34;&gt;Email me&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/mrtazz&#34;&gt;tweet me&lt;/a&gt; or better take some time and write a blog post about it!&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2014/12/15/work-life-balance.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;These days productivity and work life balance are two parts of the holy grail of modern life for </summary>
  </entry>
  <entry>
    <title>Code Reviews Considered Awesome</title>
    <updated>2014-10-21T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2014,2014-10-21:/10/21/code-review.html</id>
    <content type="html">&lt;p&gt;I think by now it is pretty much accepted that collaboration and working together is a lot better than assigning blame and yelling at each other. In the field of operating web services and infrastructure we have made the shift in the last years to improving techniques and simplifying processes, everybody is modelling infrastructure as code, nobody throws stuff over the wall anymore, developers are on-call and there is rarely any yelling (at least that&#39;s the ideal most companies strive for).&lt;/p&gt;&#xA;&lt;p&gt;But I think there is a very undervalued part of that whole situation. A lot of operations engineers (at least in my part of the internet) will happily claim they can&#39;t write code or write shitty code (by the way if you still think you don&#39;t write code as an ops engineer go read &lt;a href=&#34;http://cwebber.net/blog/2014/09/26/i-am-not-a-coder/&#34;&gt;Christopher Webber&#39;s great blog post&lt;/a&gt; about it). When in reality ops engineers write a ton of code and I have seen and reviewed amazing apps and tools being knocked out by people who will happily make excuses for their code whenever you talk about the awesome thing they wrote. The big advantage of working together is exchanging knowledge that was previously in siloed domains. It&#39;s great that developers carry pagers and know about deployment and how to write Chef recipes or Puppet modules. But that also means as an operations engineer you can tap into a giant stream of software engineering knowledge that developers have learned, improved and cared about for years. And one of those is code review.&lt;/p&gt;&#xA;&lt;p&gt;Code review is a great way to get free learning and feedback about the things you are working on. It&#39;s a way to get someone with a different context to think about whether your solution to a problem (and that&#39;s what basically all programming, scripting and automation is) makes sense to someone else. It&#39;s also a way to learn about paradigms, conventions and unknown techniques to make things better. I&#39;m a software engineer by trade and whenever I start with something new, work on a new project or try to solve a new problem I try to seek out code review. I recently worked on our Android app. And while I have worked with Java and written Android code before, it&#39;s been years and was in a completely different code base. So while I was writing down the code that would solve the problem I was having, it was very non-idiomatic when it came to our Android coding style. Once I was done I asked my coworker &lt;a href=&#34;https://twitter.com/hannahmitt&#34;&gt;Hannah&lt;/a&gt; if she could take a look at my code. And she was super excited about it and immediately jumped on it. And she gave me &lt;em&gt;tons&lt;/em&gt; of feedback. She showed me the app loader structure that would make my code much more &lt;a href=&#34;http://en.wikipedia.org/wiki/Don&amp;#39;t_repeat_yourself&#34;&gt;DRY&lt;/a&gt; and I learned a lot about how we approach Android development. And even though she initially wasn&#39;t completely familiar with the problem I was solving and it definitely took a bit longer for me to actually deploy the code I learned a ton.&lt;/p&gt;&#xA;&lt;p&gt;One of the keys here was definitely that she was so excited to review code for me. And this is where the reviewer comes in. Being asked for a code review means the person values your opinion and would love to get your feedback on something that is arguably important to them and trusts you to be able to improve it. It also means you now have to balance the fine line between not actually giving useful feedback and overdoing the code review and effectively blocking their progress. E.g. while it likely doesn&#39;t make sense to suggest an abstract factory pattern for a procedural script of python code, showing where it could greatly benefit from using functions is a simple way to improve things. Fundamentally how to give good code reviews is a complicated topic which I don&#39;t want to get into here. But the important part is that this is something you should be excited about and should let the person asking for the review know that you are.&lt;/p&gt;&#xA;&lt;p&gt;Often code reviews are still seen as a slow down, annoying and nothing that really adds value as you already know your code works. However seeing code reviews as an opportunity to learn, get another perspective and ultimatively a way of sharing knowledge is in my opinion way more accurate when done right (&lt;em&gt;right&lt;/em&gt; being used lax here as everyone has to define for themselves what that means). It is a great way to learn about different parts of your infrastructure&#39;s code, new programming paradigms and methods, how to communicate more effectively and in the end leads to a more resilient organization and enjoyable work and programming environment.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2014/10/21/code-review.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I think by now it is pretty much accepted that collaboration and working together is a lot better</summary>
  </entry>
  <entry>
    <title>My Rules for E-Mail Happiness</title>
    <updated>2014-08-29T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2014,2014-08-29:/08/29/email-happiness.html</id>
    <content type="html">&lt;p&gt;Over the last couple of days and maybe weeks a lot of my friends, coworkers and most of all people I follow on twitter have been overly excited about the beta availability of &lt;a href=&#34;http://www.mailboxapp.com&#34;&gt;an e-mail client&lt;/a&gt;. At first I was being regrettably &lt;a href=&#34;https://twitter.com/mrtazz/status/501909189577687040&#34;&gt;very snarky about it&lt;/a&gt; as in my opinion the mail client in question has some serious privacy and availability issues. But as more and more people got excited about it I took a step back and thought about why I couldn&#39;t understand the excitement and why people would give up their privacy for &#34;better e-mail&#34;. And it dawned on me that I have never actually seen e-mail as that problematic and annoying and that I actually like my setup a lot. This is why I decided to share how I do e-mail and why it works well for me (yes you may consider this one of those productivity blog posts).&lt;/p&gt;&#xA;&lt;h3 id=&#34;setting-the-stage&#34;&gt;Setting the stage&lt;/h3&gt;&#xA;&lt;p&gt;Before I start I want to make very clear that I&#39;m likely not a power email user and what works for me might not work for you. This is also mostly about how I manage my work email, as my personal email is low volume enough so that it&#39;s probably not interesting. I also use a &lt;a href=&#34;http://www.mutt.org&#34;&gt;somewhat esoteric e-mail client&lt;/a&gt; and while most of the things I&#39;ll talk about are generic, using mutt makes it a lot easier for me. And to give you a ballpark number for e-mail volume: I receive about 370 e-mails per day - your mileage may vary.&lt;/p&gt;&#xA;&lt;h3 id=&#34;so-how-do-i-use-e-mail&#34;&gt;So how &lt;em&gt;do&lt;/em&gt; I use e-mail?&lt;/h3&gt;&#xA;&lt;p&gt;The first two very important factors for me are filtering and &lt;a href=&#34;http://www.43folders.com/izero&#34;&gt;Inbox Zero&lt;/a&gt;. I am subscribed to a ton of mailing lists at work. Everything I deem interesting (and I&#39;m a super nosy person) I subscribe to, but I have strict rules about what goes into my inbox:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;E-mails addressed directly to me&lt;/li&gt;&#xA;&lt;li&gt;My team&#39;s mailing list&lt;/li&gt;&#xA;&lt;li&gt;Mailing lists of teams I work closely with&lt;/li&gt;&#xA;&lt;li&gt;Low volume mailing lists (less than 5 messages a day)&lt;/li&gt;&#xA;&lt;li&gt;Important automated e-mails (e.g. from Nagios)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Everything else gets filtered into separate mailboxes. No exceptions. If a low volume list gets more busy it gets filtered.&lt;/p&gt;&#xA;&lt;p&gt;With this setup I check my inbox a couple of times a day. The frequency depends on how busy I am obviously, but I check e-mail at most every 30 minutes and at least 5 times a day. And everything that is filtered I check once a day up until once a week, depending on how important the mailing list is. I also clear out all mailboxes at least once a week and archive all e-mail in there. This usually takes about 5 - 20 minutes and I do it before doing my weekly GTD review.&lt;/p&gt;&#xA;&lt;p&gt;In mutt I also use the &lt;a href=&#34;https://github.com/mrtazz/muttfiles/blob/master/mutt-colors-solarized-light-16.muttrc&#34;&gt;solarized light theme&lt;/a&gt; (as I do almost everywhere else) which helps a lot as e-mails are color coded differently. Read e-mails are gray, e-mails addressed to me directly or via cc are green and messages from mailing lists are blue. That way I can open up mutt, take a quick glance to see if I have new important email or if I can postpone going through my email. This is sometimes so fast that my terminal emulator warns me about the &lt;a href=&#34;https://twitter.com/mrtazz/statuses/467405164790693888&#34;&gt;shell being closed too fast again&lt;/a&gt; and there might be something wrong, which I still find hilarious. When I actually go through my e-mail, I file them into mailboxes depending on whether I want to read them later or already know that they need an answer and archive everything else. Following the GTD principle if I can answer the e-mail in 2 minutes I do it right away. Otherwise I move it to the corresponding mailbox from which it gets &lt;a href=&#34;http://www.unwiredcouch.com/2014/05/13/omnifocus.html&#34;&gt;pulled into my Omnifocus inbox&lt;/a&gt;. All of this is done with simple keyboard shortcuts that work on single or multiple messages.&lt;/p&gt;&#xA;&lt;p&gt;I also have e-mail set up on my iPhone with the iOS built-in mail client via IMAP. However I only ever skim e-mail on there and at most answer if it takes me less than 2 minutes. I also have the labeling enabled that tells me whether a messages was sent to me directly or via cc or just because I&#39;m part of a mailing list. That way I can also check very quickly if there is something in there that potentially needs my attention.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-important-part&#34;&gt;The important part&lt;/h3&gt;&#xA;&lt;p&gt;The most important part to take away from this is that &lt;strong&gt;you don&#39;t need to read all e-mail you get&lt;/strong&gt;. Especially in a big company there are enough things going on that you can&#39;t possibly keep up with everything. And that&#39;s ok. In addition to that what really works for me is using trusted clients that have been around for a while. I have been using mutt for years and I have most of its shortcuts in my muscle memory. When I came to work after a week of vacation and had &lt;a href=&#34;https://twitter.com/mrtazz/statuses/486165858809815040&#34;&gt;6000 emails in my inbox&lt;/a&gt; it took me 10 seconds to clear out all the automated emails based on their from addresses and cut the number of messages by 95%. The learning curve for mutt was pretty steep at the beginning but it has payed off over the years and since it&#39;s open source I know it will be around and not suddenly disappear (or at least it&#39;s unlikely). I also love being able to write my e-mail in vim and am a big fan of plain text e-mails. On my phone I also use the built-in e-mail client as it&#39;s likely to stay and not completely disappear or get shut down either. My usage on the phone is also light enough so I don&#39;t care about small changes in UX or functionality with OS upgrades. I have yet to encounter a bad surprise after upgrading my phone.&lt;/p&gt;&#xA;&lt;p&gt;When it comes to dealing with stress and the feeling of being overwhelmed with e-mail, the biggest change for me besides filtering was to turn off all notifications. No e-mail that I receive will ever make a sound or make my phone vibrate. There are no lock screen notifications on my phone besides e-mail from people in my iPhone VIP list which is mostly family and even then it just shows up. No sound, no vibration. I decide when I have time to read e-mail.&lt;/p&gt;&#xA;&lt;p&gt;As I said, most of these things are applicable no matter what e-mail client you use. I happen to use mutt (set up similar to how it&#39;s explained &lt;a href=&#34;http://stevelosh.com/blog/2012/10/the-homely-mutt/&#34;&gt;here&lt;/a&gt; and these are my &lt;a href=&#34;https://github.com/mrtazz/muttfiles&#34;&gt;config files&lt;/a&gt; in case you&#39;re interested), but there are a ton of good and proven clients out there (I used OSX Mail.app for years and always liked it). And plain old IMAP is honestly pretty cool. But most of all - in my opinion - the biggest problems with e-mail are social or rather psychological problems (trying to keep up with everything, wanting to get notified all the time) and not technological ones, and they can be solved.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2014/08/29/email-happiness.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Over the last couple of days and maybe weeks a lot of my friends, coworkers and most of all peopl</summary>
  </entry>
  <entry>
    <title>Bye Bye Fitbit</title>
    <updated>2014-08-21T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2014,2014-08-21:/08/21/bye-bye-fitbit.html</id>
    <content type="html">&lt;p&gt;About a year ago I decided that I had to do something about my fitness. Since moving to NYC about 1.5 years prior I went from having basketball training two to three times a week and a game on the weekend to basically not doing any sports. Needless to say this didn&#39;t really impact my fitness in any positive way. In addition I was also used to eat quite a lot since basketball training had been enough sports so I could easily burn it off again. And while I didn&#39;t have practice anymore I was still used to eat the same amount of food basically.&lt;/p&gt;&#xA;&lt;p&gt;So something needed to change. I had tried running several times, but since I find it utterly boring I never really got into the habit of doing it regularly. Plus there is no real instant feedback from running, so even when I managed to go, I never had the feeling of actually doing sports. Clearly I needed a way to track progress. So the first step was to get a scale. That way I would be able to at least track my weight. I decided to get the &lt;a href=&#34;http://www.fitbit.com/aria&#34;&gt;Fitbit Aria&lt;/a&gt; scale as I liked the idea of syncing it to an account where I can get pretty graphs. &lt;a href=&#34;http://shouldigraphit.com&#34;&gt;I like graphs&lt;/a&gt;. The next step then was to track how active I am and what I eat so that I could get a rough overview of general activity and calorie burn. As I had already created an account with Fitbit for the scale I decided to get the &lt;a href=&#34;http://www.fitbit.com/flex&#34;&gt;Fitbit flex&lt;/a&gt; wristband (I later replaced it with the now discontinued &lt;a href=&#34;http://www.fitbit.com/force&#34;&gt;Force&lt;/a&gt;) to track steps and calories.&lt;/p&gt;&#xA;&lt;p&gt;Now I had feedback and graphs for what I was doing all day, how active I was, how long/good I was sleeping and I kept track of what I was eating. Having this incentive meant that I would be going running or shooting some hoops for at least 20 minutes everyday before or after work. I also stopped eating everything I found (which seems to be big part of the secret of losing weight) as it would go into my food journal in the Fitbit application. And this worked really well. Over the course of a couple of months I lost about 11 kilos (about 24 lbs) and even had to &lt;a href=&#34;https://twitter.com/mrtazz/statuses/399937629078441984&#34;&gt;put new holes in my belt&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;But soon after all of this my habit of how I used the Fitbit changed. In early 2014 I decided that I didn&#39;t want to work long hours anymore and improve my work-life balance. This meant I took the conscious decision that I would leave work at around 6pm everyday to catch the ferry home. No more staying late unless things are on fire and no more working from home after I left the office. If I wanted to get more stuff done I&#39;d have to get up early. While the getting up early part didn&#39;t work very well at the beginning, this now meant that I would go to bed at a regular time (usually between 10-11pm) and get about 9-10h of sleep most nights. This however made my Fitbit sleep tracking basically obsolete for me. I knew that I slept well most nights and if I didn&#39;t it was mostly because I violated the rule and went to bed late (or I was on-call and got woken up at night). In addition to that I got a &lt;a href=&#34;https://getpebble.com&#34;&gt;Pebble&lt;/a&gt; and was now rocking dual wearables. Which really wasn&#39;t a pleasant feeling. Both the Fitbit and the Pebble aren&#39;t super big but having stuff hanging on your wrist all day meant that I would come home and take both of because it felt much better not to have anything on the wrists. And that feeling amplified when I went to bed. I felt much more relaxed and less restricted when I wouldn&#39;t wear anything on my wrists when I was sleeping. So most days I would take off the Fitbit (and Pebble) when I got home and not put it back on until the next morning (with the exception of being on-call where we &lt;a href=&#34;http://codeascraft.com/2014/06/19/opsweekly-measuring-on-call-experience-with-alert-classification/&#34;&gt;use sleep data to improve the on-call rotation&lt;/a&gt;). I still liked having graphs about steps, but mostly for the sake of having graphs. I didn&#39;t act on them in any way other than occasionally &lt;a href=&#34;https://twitter.com/mrtazz/statuses/483125970245660674&#34;&gt;bragging on twitter about how much I walked&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;So when I came home from a week of vacation in early July I decided to not put the Fitbit back on at all and see how it feels. And it was great! I felt much more free and less restricted. I hadn&#39;t been using the data it collected for anything really in almost 6 months. Plus I never really felt comfortable with the fact that details about my activity and calorie intake live on a server in the cloud. Thanks (partly) to the Fitbit I got back to a good intuition about how much I should eat and how much sport I should do every week. I now go to the gym regularly, have a way better sleep schedule and eat more consciously and more importantly less than 1.5 years ago (although there are definitely improvements to make there still). And if anything is off about food, sports or sleep I notice immediately as I start to feel unwell. This doesn&#39;t mean I would never ever use a fitness tracker again. If they eventually end up being less intrusive in daily life and maybe even come with a collection application I can install on my own servers I would happily try it again. But for now it&#39;s &#34;Bye Bye Fitbit&#34;.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2014/08/21/bye-bye-fitbit.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;About a year ago I decided that I had to do something about my fitness. Since moving to NYC about</summary>
  </entry>
  <entry>
    <title>Mirror GitHub repositories in pure shell</title>
    <updated>2014-08-16T00:00:00Z</updated>
    <id>tag:unwiredcouch.combits,2014-08-16:/2014/08/16/github-mirror-shell.html</id>
    <content type="html">&lt;p&gt;As I have &lt;a href=&#34;http://www.unwiredcouch.com/2013/10/30/uncloud-your-life.html&#34;&gt;written before&lt;/a&gt; I have slowly started to move my data out of cloud services where applicable. One part of that was setting up my own backup server at home based on &lt;a href=&#34;http://www.unwiredcouch.com/bits/2014/03/18/zfs-rsync-backups.html&#34;&gt;FreeBSD, zfs and rsync&lt;/a&gt;. One part I consider important data but didn&#39;t have on there was my (Open Source) code I host on GitHub. This also wasn&#39;t ever a priority as the code is public anyways so it wasn&#39;t a privacy issue for me, and I also trust GitHub to run backups so I wasn&#39;t overly concerned about my data vanishing. Still I wanted to have my own backup of things.&lt;/p&gt;&#xA;&lt;p&gt;So I started to look into how people mirror their repositories for backups, speed, availability and other things. There exist quite a lot of solutions out there which are mostly written in Ruby or Python. While this is fine and I would encourage you to look into those, I didn&#39;t want to deal with installing pip to install some Python script or installing yet another gem just for something that can be accomplished with a couple of lines of shell. So I wrote my own set of scripts in Bourne shell (one of the default installed shells in FreeBSD) so I could just cron them up on my backup box.&lt;/p&gt;&#xA;&lt;p&gt;First I needed a way to get a list of all my repositories. Thankfully GitHub has a &lt;a href=&#34;https://developer.github.com/v3/&#34;&gt;pretty great API&lt;/a&gt; so I can just get a list of all my repositories and their git clone URLs:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#!/bin/sh&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Usage:&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-4&#34;&gt;&lt;a href=&#34;#cb1-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# github_repo_list.sh mrtazz [34345k34j3k4b2jk3]&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-5&#34;&gt;&lt;a href=&#34;#cb1-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-6&#34;&gt;&lt;a href=&#34;#cb1-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# get a list of all public repos for a user&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-7&#34;&gt;&lt;a href=&#34;#cb1-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-z&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$1&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-8&#34;&gt;&lt;a href=&#34;#cb1-8&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;Usage:&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-9&#34;&gt;&lt;a href=&#34;#cb1-9&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;github_repo_list.sh USERNAME [TOKEN]&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-10&#34;&gt;&lt;a href=&#34;#cb1-10&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;exit&lt;/span&gt; 1&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-11&#34;&gt;&lt;a href=&#34;#cb1-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-12&#34;&gt;&lt;a href=&#34;#cb1-12&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-13&#34;&gt;&lt;a href=&#34;#cb1-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;!&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-z&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$2&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-14&#34;&gt;&lt;a href=&#34;#cb1-14&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;va&#34;&gt;TOKEN=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&amp;amp;access_token=&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${2}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-15&#34;&gt;&lt;a href=&#34;#cb1-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-16&#34;&gt;&lt;a href=&#34;#cb1-16&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-17&#34;&gt;&lt;a href=&#34;#cb1-17&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;CURL=$(&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;which&lt;/span&gt; curl&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-18&#34;&gt;&lt;a href=&#34;#cb1-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-z&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${CURL}&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-19&#34;&gt;&lt;a href=&#34;#cb1-19&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;co&#34;&gt;# fall back to /usr/local/bin/curl&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-20&#34;&gt;&lt;a href=&#34;#cb1-20&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;va&#34;&gt;CURL=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;/usr/local/bin/curl&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-21&#34;&gt;&lt;a href=&#34;#cb1-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-22&#34;&gt;&lt;a href=&#34;#cb1-22&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-23&#34;&gt;&lt;a href=&#34;#cb1-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;BASEURL=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;https://api.github.com/users/&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${1}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/repos?type=owner&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${TOKEN}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-24&#34;&gt;&lt;a href=&#34;#cb1-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;count=&lt;/span&gt;1&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-25&#34;&gt;&lt;a href=&#34;#cb1-25&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-26&#34;&gt;&lt;a href=&#34;#cb1-26&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;while&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${count}&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-gt&lt;/span&gt; 0&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-27&#34;&gt;&lt;a href=&#34;#cb1-27&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-28&#34;&gt;&lt;a href=&#34;#cb1-28&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;va&#34;&gt;lines=$(${CURL}&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${BASEURL}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;amp;page=&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${count}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;-s&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;grep&lt;/span&gt; git_url &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;cut&lt;/span&gt; -d&lt;span class=&#34;st&#34;&gt;&amp;quot; &amp;quot;&lt;/span&gt; -f6 &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;sed&lt;/span&gt; -e &lt;span class=&#34;st&#34;&gt;&amp;quot;s/[&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;,]//g&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-29&#34;&gt;&lt;a href=&#34;#cb1-29&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-30&#34;&gt;&lt;a href=&#34;#cb1-30&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;co&#34;&gt;# stop if we don&amp;#39;t get any more content. A bit hacky but I don&amp;#39;t want to&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-31&#34;&gt;&lt;a href=&#34;#cb1-31&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;co&#34;&gt;# parse HTTP header data to figure out the last page&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-32&#34;&gt;&lt;a href=&#34;#cb1-32&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${lines}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-33&#34;&gt;&lt;a href=&#34;#cb1-33&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;va&#34;&gt;count=&lt;/span&gt;0&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-34&#34;&gt;&lt;a href=&#34;#cb1-34&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;else&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-35&#34;&gt;&lt;a href=&#34;#cb1-35&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;kw&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;line&lt;/span&gt; in &lt;span class=&#34;va&#34;&gt;${lines}&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt; &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${line}&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;done&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-36&#34;&gt;&lt;a href=&#34;#cb1-36&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;va&#34;&gt;count=&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;expr&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$count&lt;/span&gt; + 1&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-37&#34;&gt;&lt;a href=&#34;#cb1-37&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-38&#34;&gt;&lt;a href=&#34;#cb1-38&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-39&#34;&gt;&lt;a href=&#34;#cb1-39&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;done&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This script takes a username and an optional access token and retrieves the public list of repositories for that user. It then outputs the git clone URLs one per line so it&#39;s easily stored in a text file or fed into other scripts. There are some minor inefficiencies and missing features in there as it curls one more time than needed to the GitHub API to figure out if there are more results and it also only supports public repositories as I don&#39;t have private ones at the moment. However changing the URL to call if I ever want to mirror private repositories is relatively easy and I don&#39;t care that much about the extra curl as this script is not gonna be run very frequently.&lt;/p&gt;&#xA;&lt;p&gt;This now gives me a list of all repositories on my account I want to mirror. The next step is actually mirroring them. For that I wrote a script that looks like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#!/bin/sh&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# take a list of git clone urls on STDIN and clone them if they don&amp;#39;t exist.&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-z&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$1&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-6&#34;&gt;&lt;a href=&#34;#cb2-6&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;Usage:&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-7&#34;&gt;&lt;a href=&#34;#cb2-7&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;github_repo_sync.sh directory&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-8&#34;&gt;&lt;a href=&#34;#cb2-8&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;exit&lt;/span&gt; 1&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-9&#34;&gt;&lt;a href=&#34;#cb2-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-10&#34;&gt;&lt;a href=&#34;#cb2-10&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-11&#34;&gt;&lt;a href=&#34;#cb2-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;GIT=$(&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;which&lt;/span&gt; git&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-12&#34;&gt;&lt;a href=&#34;#cb2-12&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-13&#34;&gt;&lt;a href=&#34;#cb2-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-z&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${GIT}&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-14&#34;&gt;&lt;a href=&#34;#cb2-14&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;co&#34;&gt;# if git is not in path fall back to /usr/local&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-15&#34;&gt;&lt;a href=&#34;#cb2-15&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-f&lt;/span&gt; /usr/local/bin/git&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-16&#34;&gt;&lt;a href=&#34;#cb2-16&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;va&#34;&gt;GIT=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;/usr/local/bin/git&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-17&#34;&gt;&lt;a href=&#34;#cb2-17&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;else&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-18&#34;&gt;&lt;a href=&#34;#cb2-18&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;You need to have git installed.&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-19&#34;&gt;&lt;a href=&#34;#cb2-19&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;bu&#34;&gt;exit&lt;/span&gt; 1&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-20&#34;&gt;&lt;a href=&#34;#cb2-20&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-21&#34;&gt;&lt;a href=&#34;#cb2-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-22&#34;&gt;&lt;a href=&#34;#cb2-22&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-23&#34;&gt;&lt;a href=&#34;#cb2-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# switch to archive directory&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-24&#34;&gt;&lt;a href=&#34;#cb2-24&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;cd&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$1&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-25&#34;&gt;&lt;a href=&#34;#cb2-25&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-26&#34;&gt;&lt;a href=&#34;#cb2-26&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;bu&#34;&gt;read&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;line&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-27&#34;&gt;&lt;a href=&#34;#cb2-27&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;va&#34;&gt;directory=$(&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${line}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;cut&lt;/span&gt; -d &lt;span class=&#34;st&#34;&gt;&amp;quot;/&amp;quot;&lt;/span&gt; -f 5&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-28&#34;&gt;&lt;a href=&#34;#cb2-28&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-29&#34;&gt;&lt;a href=&#34;#cb2-29&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;!&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-d&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${directory}&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-30&#34;&gt;&lt;a href=&#34;#cb2-30&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;va&#34;&gt;${GIT}&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;clone&lt;/span&gt; --mirror &lt;span class=&#34;va&#34;&gt;${line}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-31&#34;&gt;&lt;a href=&#34;#cb2-31&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;else&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-32&#34;&gt;&lt;a href=&#34;#cb2-32&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;bu&#34;&gt;cd&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${directory}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-33&#34;&gt;&lt;a href=&#34;#cb2-33&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;va&#34;&gt;${GIT}&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;fetch&lt;/span&gt; -p origin&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-34&#34;&gt;&lt;a href=&#34;#cb2-34&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;bu&#34;&gt;cd&lt;/span&gt; ..&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-35&#34;&gt;&lt;a href=&#34;#cb2-35&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-36&#34;&gt;&lt;a href=&#34;#cb2-36&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-37&#34;&gt;&lt;a href=&#34;#cb2-37&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;done&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This script checks for each entry in a list of git clone URLs passed in via STDIN and if the directory already exists it fetches changes and if not clones it into the given directory. The mirroring commands reflect the instructions in this &lt;a href=&#34;https://help.github.com/articles/duplicating-a-repository&#34;&gt;GitHub guide&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Now to tie those two together I just set up two cron entries to run those two commands:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;0&lt;/span&gt; 20 * * * ~/bin/github_repo_list.sh mrtazz 0f6 &lt;span class=&#34;op&#34;&gt;&amp;gt;&lt;/span&gt; /backup/github/github_repo_list.txt&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;0&lt;/span&gt; 21 * * * ~/bin/github_repo_sync.sh /backup/github &lt;span class=&#34;op&#34;&gt;&amp;lt;&lt;/span&gt; /backup/github/github_repo_list.txt&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;The first cron entry fetches the list of repositories and sticks them into a text file. The second one runs an hour later and actually syncs all the changes. I set it up to sync into the zfs pool that gets snapshotted every night anyways (as described &lt;a href=&#34;http://www.unwiredcouch.com/bits/2014/03/18/zfs-rsync-backups.html&#34;&gt;here&lt;/a&gt;) so I get that for free. I&#39;m not super happy with running this on a cron as there could be a smarter solution that checks for changes via the API and marks repositories as dirty, but this is the simplest thing that could work and way less work than interacting more with the API. In addition I would love to exclude forks from the backup since I don&#39;t really care about backing those up. But I&#39;ll leave this for iteration&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;I track changes to the script in my &lt;a href=&#34;https://github.com/mrtazz/bin&#34;&gt;bin folder repository on GitHub&lt;/a&gt;, so if you&#39;re interested in tracking changes to this setup, follow it there.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.combits/2014/08/16/github-mirror-shell.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;As I have &lt;a href=&#34;http://www.unwiredcouch.com/2013/10/30/uncloud-your-life.html&#34;&gt;written before&lt;</summary>
  </entry>
  <entry>
    <title>Human Error and Getting off the Hook</title>
    <updated>2014-08-04T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2014,2014-08-04:/08/04/human-error-getting-off-the-hook.html</id>
    <content type="html">&lt;p&gt;I&#39;ve been interested in the field of human error and system safety for a while now. My original interest in it got sparked by talking to &lt;a href=&#34;http://www.kitchensoap.com/&#34;&gt;John Allspaw&lt;/a&gt; and ultimately reading Sidney Dekker&#39;s &lt;a href=&#34;http://amzn.com/0754648265&#34;&gt;The Field Guide to Understanding Human Error&lt;/a&gt; which gives a very good introduction to the topic. The book gives a lot of examples of things that have gone bad - often in aircraft control - and even given the fact that I read most of it on a 14 hour long flight I can definitely recommend it. I have since then participated in a book club about the field guide and completed an informal course about learning how to facilitate a &lt;a href=&#34;http://codeascraft.com/2012/05/22/blameless-postmortems/&#34;&gt;blameless postmortem&lt;/a&gt; taught by John. This approach of figuring out what happened and why it happened in a blameless manner makes a lot of sense to me. I have worked in more traditional places before where incidents weren&#39;t investigated in such a way and I always had the feeling that there was something missing. That the full story was never really uncovered - not even close. Over time I have talked to quite a lot of people about the New View, this new way of thinking about what contributes to incidents and blamelessly investigating them. And when I talk to people about it who have never heard of this before or are new to the topic, there is usually one question that comes up really quickly and is usually something along the lines of:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;But isn&#39;t this just a cheap way of getting off the hook?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;This is why I decided to write down my thoughts about why this isn&#39;t the case and what the New View is about relating to responsibility and trying to prevent the same incident from happening again.&lt;/p&gt;&#xA;&lt;p&gt;First let&#39;s look into what we are working with every day. Be it in airtraffic control and flying airplanes, operating modern trains, working in a hospital and taking care of patients or keeping a website running. All of those are complex socio-technical systems. That means the systems as a whole consist of many many technological parts and humans as operators interact with them. And they are big and complex enough as so they are in itself intractable for any person. This means at no point is there a simple and clear plan to follow and at no point is it possible for anyone to fully describe the system end to end with all of its interactions. This means anyone working within the system has to choose carefully between checking every single step for any risk imaginable and actually getting work done (something that Erik Hollnagel calls ETTO or Efficiency-Thoroughness-Trade-Off). For example an airplane pilot might speed up going through the pre take-off checklisting because being extremely thorough almost certainly means introducing delays or maybe even missing the plane&#39;s flight slot. A doctor maybe only goes through the part of the patient report that is relevant to the immediate action or surgery they are about to do because of the huge number of patients they have to take care of. A software engineer wants to make something faster to provide a better experience for the user and subsequently brings down the site by exhausting available resources too fast.&lt;/p&gt;&#xA;&lt;p&gt;Now these very specific examples might seem like people slacking off and if they just did all those things according to the rules and regulations, everything would be fine and nothing can go wrong. And conversely if we fire the person that caused that deviation from the rules we have a perfectly simple reason why our complex system broke. This is a very natural approach to accident investigation. Even Nietzsche talked about it before.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;In the search for a cause of an accident we do tend to stop, in the words of Nietzsche, by ‘the first interpretation that explains the unknown in familiar terms’ and ‘to use the feeling of pleasure … as our criterion for truth.’&lt;/p&gt;&#xA;&lt;p class=&#34;cite&#34;&gt;&#xA;&amp;mdash; &lt;cite&gt;Erik Hollnagel, The ETTO Principle: Efficiency-Thoroughness Trade-Off (p. 10)&lt;/cite&gt;&#xA;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;The reality is however that in complex, intractable systems it&#39;s impossible to follow all the rules and attend to work with 100% thoroughness. There is even a behaviour called &lt;a href=&#34;http://en.wikipedia.org/wiki/Work-to-rule&#34;&gt;&#34;work-to-rule&#34;&lt;/a&gt; that describes the action of working exactly what the rules describe and thus causing a slowdown that can even come close to a stop.&lt;/p&gt;&#xA;&lt;p&gt;So now that we have established that people take shortcuts and thoroughness tradeoffs all the time, we can also safely assume - as those actions are likely what makes sense at the time - that other operators (would) do the same. Bringing us to a point where certain actions that just before seemed like the cause of trouble are now considered to be a natural behaviour of people working within the system. And as Sidney Dekker puts it so aptly:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Indeed, as soon as you have reason to believe that any other practitioner would have done the same thing as the one whose assessments and actions are now controversial, you should start looking at the system.&lt;/p&gt;&#xA;&lt;p class=&#34;cite&#34;&gt;&#xA;&amp;mdash; &lt;cite&gt;Sidney Dekker, The Field Guide to Understanding Human Error (p. 195)&lt;/cite&gt;&#xA;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;But is that really true? Maybe all the others who would have done this very thing a dozen times before just had better judgement? Maybe they just were more aware of the situation and noticed that it would be an appropriate response. Whereas in the failure case the operator just failed to recognize that now was not the time to do this. It turns out smart people have thought about this very thing before. The Austrian physicist and philosopher Ernst Mach came to &lt;a href=&#34;https://archive.org/download/erkenntnisundirr00machuoft/erkenntnisundirr00machuoft.pdf&#34;&gt;this conclusion in 1905&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Erkenntnis und Irrtum fließen aus denselben psychischen Quellen; nur der Erfolg vermag beide zu scheiden. Der klar erkannte Irrtum ist als Korrektiv ebenso erkenntnisfördend wie die positive Erkenntnis.&lt;/p&gt;&#xA;&lt;p class=&#34;cite&#34;&gt;&#xA;&amp;mdash; &lt;cite&gt;Ernst Mach, Erkenntnis und Irrtum (p. 116)&lt;/cite&gt;&#xA;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;This translates to something like &#34;knowledge and error flow from the same mental sources; only success can tell one from the other. A clearly recognized error as a corrective is fostering knowledge as much as positive realization.&#34;. Which makes it clear that the decision of whether or not something was &#34;the right thing to do&#34; or an error is defined by post-hoc analysis of the situation. An advantage the operator didn&#39;t have in the situation.&lt;/p&gt;&#xA;&lt;p&gt;So now what? Our precious theory about the bad apple is gone. Where do we go from there? Are we not allowed to talk about human actions at all anymore?&lt;/p&gt;&#xA;&lt;p&gt;Quite the opposite.&lt;/p&gt;&#xA;&lt;p&gt;Humans are a crucial part of socio-technical systems. But they are what makes systems safe. As we have said before, our complex systems are in large parts intractable and thus there is no way we could design a ruleset of things that we could have a machine execute and everything would be safe. The thousands of little adjustments, human operators carry out every minute are the pillars of our system safety. With the little crux that they sometimes also lead to adversarial outcomes. And this is the part we are interested in. How does something that is done over and over again seemingly suddenly lead to an incident? Why does it make sense for a person in that situation to act in the way they did? After all the basic assumption is that people don&#39;t come to work to do a bad job.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;There is a difference between explaining and excusing human performance.&lt;/p&gt;&#xA;&lt;p class=&#34;cite&#34;&gt;&#xA;&amp;mdash; &lt;cite&gt;Sidney Dekker, The Field Guide to Understanding Human Error (p. 196)&lt;/cite&gt;&#xA;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;So does the human operator in this New View get off the hook? The answer here is no. Because thinking about failure and outages in this way means the practitioner was never on the hook for explaining their behaviour in the first place. However being part of an incident on the very sharp end of the situation brings some new responsibilities with it. It means the human is now the specialist with most of the knowledge about how the system surprised us and broke down. They know best how they expected the system to react and what it actually did. They are the foremost authority on what detections they utilized and what to put in place to realize faster that something is going wrong. They know which tools they reached for, which they had to improvise, and which tools they were missing. This means they are very much on the hook. But on the hook for helping to find ways to make the system safer going forward.&lt;/p&gt;&#xA;&lt;p&gt;If this has sparked your interest in the field, my coworker &lt;a href=&#34;https://twitter.com/indec&#34;&gt;Ian&lt;/a&gt; has also recently published a set of resources on the &lt;a href=&#34;http://codeascraft.com/2014/07/18/just-culture-resources/&#34;&gt;Etsy Engineering blog&lt;/a&gt; to get started with the topic of System Safety, Human Error and Just Culture.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2014/08/04/human-error-getting-off-the-hook.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I&#39;ve been interested in the field of human error and system safety for a while now. My original i</summary>
  </entry>
  <entry>
    <title>Productive VIM with templates</title>
    <updated>2014-07-22T00:00:00Z</updated>
    <id>tag:unwiredcouch.combits,2014-07-22:/2014/07/22/productive-vim-with-templates.html</id>
    <content type="html">&lt;p&gt;I basically exist inside of vim all day. I write code in there, I write emails in VIM via &lt;a href=&#34;http://www.mutt.org&#34;&gt;mutt&lt;/a&gt;, I take notes with it and I write all my blog posts in VIM. I think it&#39;s clear that improving the way I work with VIM helps in a variety of scenarios. Over time I also noticed that I often start out with the same basic file structure and then fill it with content. For example jekyll blog posts always have the same header, meeting notes always have the same structure and I use a template to reply to recruiter emails in times where I&#39;m not looking for a job (a trick I learned from &lt;a href=&#34;https://twitter.com/katemats&#34;&gt;Kate Matsudaira&lt;/a&gt; in one of her &lt;a href=&#34;http://katemats.com/people-are-lazy/&#34;&gt;great blog posts&lt;/a&gt; about productivity).&lt;/p&gt;&#xA;&lt;p&gt;In the coding world VIM provides a great built-in functionality for that which is called &lt;a href=&#34;http://vimdoc.sourceforge.net/htmldoc/autocmd.html#skeleton&#34;&gt;&#34;skeleton files&#39;&lt;/a&gt;. This is a great way to always have a good to go version of C source or header files, Makefiles or RPM spec files. However this is all based on filetypes (or rather file endings) and since I write most of my notes and all my blog posts in &lt;a href=&#34;http://daringfireball.net/projects/markdown/&#34;&gt;Markdown&lt;/a&gt; for example and they all have the same file ending this doesn&#39;t help me much for having different templates. So I started to look around for VIM functionality or plugins that would just let me load templates from a specific location and maybe expand some variables (as I for example like to have the date auto inserted into meeting notes). I didn&#39;t want a full fledged templating engine, although I could certainly have installed and wrapped the &lt;a href=&#34;https://github.com/tobyS/vmustache&#34;&gt;Mustache implementation written in VimL&lt;/a&gt; to do that for me. But I wanted to keep it simple and apparently that solution didn&#39;t exist yet.&lt;/p&gt;&#xA;&lt;p&gt;This is why I wrote a VIM plugin called &lt;a href=&#34;https://github.com/mrtazz/vim-stencil&#34;&gt;vim-stencil&lt;/a&gt;. It&#39;s a handful of lines of VimL and it does exactly 2 things:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Load a template from a specified location&lt;/li&gt;&#xA;&lt;li&gt;Expand some variables (currently even only one: the date)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;So now with a simple call to &lt;code&gt;:Stencil&lt;/code&gt; in VIM I can choose a template for the type of file I&#39;m editing (yes it supports tab completion) and load that into my buffer. I even get the current date for free in templates where I choose to have it. No fuzz, no complicated setup. But a small thing that increases my productivity a lot.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.combits/2014/07/22/productive-vim-with-templates.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I basically exist inside of vim all day. I write code in there, I write emails in VIM via &lt;a href</summary>
  </entry>
  <entry>
    <title>Shared layout for project pages in Jekyll</title>
    <updated>2014-06-14T00:00:00Z</updated>
    <id>tag:unwiredcouch.combits,2014-06-14:/2014/06/14/jekyll-shared-project-layouts.html</id>
    <content type="html">&lt;p&gt;I use &lt;a href=&#34;http://jekyllrb.com/&#34;&gt;Jekyll&lt;/a&gt; a lot, especially for &lt;a href=&#34;http://unwiredcouch.com&#34;&gt;my website&lt;/a&gt;. And I quite like it a lot. I also write and open source the occasional software every now and then, which usually happens on &lt;a href=&#34;https://github.com/mrtazz&#34;&gt;my GitHub profile&lt;/a&gt;. And thankfully GitHub makes it &lt;a href=&#34;https://pages.github.com/&#34;&gt;dead easy&lt;/a&gt; to generate a nice looking page for your project. I&#39;ve used this feature for a long time now and have used a bunch of their awesome provided themes. However since I also host my site on GitHub Pages and thus all my projects are automatically available under a sub path there named after the project name.&lt;/p&gt;&#xA;&lt;p&gt;However last week I decided that I wanted to have them all be in a layout similar to my website so the whole page doesn&#39;t change just because you click on a link on my &lt;a href=&#34;http://www.unwiredcouch.com/projects.html&#34;&gt;projects page&lt;/a&gt;. But I also wanted to keep the code for the pages in the respective repo so it&#39;s all in one place while at the same time I didn&#39;t want to copy the layout into each repository.&lt;/p&gt;&#xA;&lt;p&gt;Thankfully there is trick you can use with GitHub Pages. If you add git submodules to your repository they are gettiing &lt;a href=&#34;https://help.github.com/articles/using-submodules-with-pages&#34;&gt;pulled in&lt;/a&gt; automatically on page build. So I created a &lt;a href=&#34;https://github.com/mrtazz/jekyll-layouts&#34;&gt;shared repository&lt;/a&gt; to hold the template I wanted for my projects. And now all I have to do to get a project page with the correct layout is:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;git checkout gh-pages&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;git submodule add https://github.com/mrtazz/jekyll-layouts.git _layouts&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;copy the &lt;code&gt;README.md&lt;/code&gt; of my project to &lt;code&gt;index.md&lt;/code&gt; and add the jekyll frontmatter:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code&gt;---&#xA;layout: project&#xA;title: project name&#xA;---&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;add a &lt;code&gt;_config.yml&lt;/code&gt; and fill out the following values:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code&gt;gaugesid: tracking code for the gaug.es gauge&#xA;projecturl: github url for the ribbon in the upper right corner&#xA;basesite: base URL to get the CSS from&#xA;markdown: kramdown&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;git push&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The only dependency now is that the CSS comes from my main website. Which I&#39;m fine with and is actually a feature because if I ever change something there I want the project pages to reflect that change also. The other downside is that if I change the project layout repository I will have to update the reference in all the project repositories. Which should be fairly straightforward with some automation and is at least better than copying files around and committing them to each repository.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.combits/2014/06/14/jekyll-shared-project-layouts.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I use &lt;a href=&#34;http://jekyllrb.com/&#34;&gt;Jekyll&lt;/a&gt; a lot, especially for &lt;a href=&#34;http://unwiredcouc</summary>
  </entry>
  <entry>
    <title>Computer Positivity</title>
    <updated>2014-05-21T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2014,2014-05-21:/05/21/computers-are-awesome.html</id>
    <content type="html">&lt;p&gt;Let&#39;s face it, we&#39;ve all been there, your database just decided to split brains, Linux just killed Apache on your web servers because another process was using a bit more memory, your app is broken because the type system of the language you wrote it in has interesting assumptions about what object you just passed to a function and your laptop keeps disconnecting from the Wi-Fi. It&#39;s fair to say computers are horrible right? And with all that certainty in mind, we reach for the small phone in our pocket, open an app, type into a text field and hit &#34;Tweet&#34;, so that the little message gets send off to thousands of servers, which process it, find and extract data and then make our proclamation available to millions of people all over the world within a second:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Computers are terrible. Nothing works.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;We all love to share our opinion and give talks about all the things that are wrong with computing. JavaScript is a popular topic, so is PHP, Redis, nodejs, Scala, Rails, Nagios, MongoDB and almost any other technology on different occasions. You can not spend a week (or sometimes even a day) without a new blog post about how some technology or piece of software (or better yet: everything) is broken lacking any positive take away.&lt;/p&gt;&#xA;&lt;p&gt;I was at Monitorama at the beginning of May which is always amazing and great to meet and talk with friends and other people who work in infrastructure and operations in the vastest sense. And it&#39;s easily one of my favorite conferences. I &lt;a href=&#34;https://vimeo.com/95247023&#34;&gt;got to give a talk&lt;/a&gt; there and close to the end before introducing how our Nagios setup works I asked the audience to raise their hand if they have strong feelings about Nagios. From what I could see almost everybody raised their hand. Then I asked them to raise the other hand if those feelings were love. Almost nobody did.&lt;/p&gt;&#xA;&lt;p&gt;We have arrived at a point where a piece of software (granted with some fixable inconveniences) monitors a complex system of computers, lets us know when something is broken and arguably enables a ton of businesses. And yet almost nobody has to say anything good about it. Everybody will tell you how terrible it is.&lt;/p&gt;&#xA;&lt;p&gt;This isn&#39;t about Nagios though. This is about general attitude. We work in a field where you can (compared to other professions) make a lot of money, usually don&#39;t have to be too concerned about unemployment (it&#39;s even kind of a sport already to complain and make fun of all the recruiter requests we get and be upset they are not perfectly tailored to what we want to work on) and generally get paid to solve problems. And then we start to complain about the fact that we can&#39;t always choose the problems we have to solve. We build complex systems with a myriad of interactions and components and then have the hubris to say we should understand them in their entirety and whoever doesn&#39;t is plain stupid.&lt;/p&gt;&#xA;&lt;p&gt;Let&#39;s be clear here. I don&#39;t think you can never complain about things. I don&#39;t think everything is unicorns and rainbows. And I don&#39;t think you are not allowed to say something when things are horrible. But as a profession I get the feeling we have started to basically take negativity for granted. And with that we set an awful example for peers and especially (young) people coming to our industry. We say &#34;computers are terrible&#34; when it really just means &#34;the computer does a thing that is really inconvenient for me right now&#34;. We have a machine in front of us that let&#39;s us boot other computers all around the world, talk to our families face-to-face wherever they might be and access any information known to mankind in an instant. Yet what we say is &#34;look at all the crap we have to put up with everyday, recognize our prowess&#34;. We could invent teleportation and enable everybody to be anywhere they want in an instant. As long as it sometimes puts us inconveniently a couple of meters away from our desired destination we would be tweeting that &#34;this is horrible and everything is broken&#34;.&lt;/p&gt;&#xA;&lt;p&gt;Technology has made a lot of things possible for me. I would have never thought that I would live in what might be the best city on earth, love every day I go to work and am able to work on things I&#39;m interested in, and have the opportunity to travel to conferences to have people listen to what I say about computers. Am I stressed, annoyed or even mad sometimes about yum resolving dependencies wrong, having to use a different way of comparing variables in PHP or the fact that my laptop goes to a blank screen again 20 seconds after I unlocked it? Yup. Does that make everything terrible? Nope.&lt;/p&gt;&#xA;&lt;p&gt;I&#39;m sure as hell happy and thankful I can work with computers every day, do interesting things and contribute to a platform where people create businesses and make a living on. Because computers are pretty amazing and I get to learn something new every day. And sometimes even feel almost &lt;a href=&#34;https://twitter.com/mrtazz/statuses/460423094054973440&#34;&gt;like a wizard&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2014/05/21/computers-are-awesome.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Let&#39;s face it, we&#39;ve all been there, your database just decided to split brains, Linux just kille</summary>
  </entry>
  <entry>
    <title>How OmniFocus controls my life</title>
    <updated>2014-05-13T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2014,2014-05-13:/05/13/omnifocus.html</id>
    <content type="html">&lt;p&gt;At this point it&#39;s pretty fair to say that &lt;a href=&#34;http://www.omnigroup.com/omnifocus&#34;&gt;OmniFocus&lt;/a&gt; rules my life. I&#39;ve started to really take GTD seriously about 2 years ago. I had tried a lot of different task managers before of course. I loved &lt;a href=&#34;https://culturedcode.com/things/&#34;&gt;Things&lt;/a&gt; when it originally came out as a beta and of course I had started to write &lt;a href=&#34;https://github.com/mrtazz/gtd-couch&#34;&gt;my own todo tracker&lt;/a&gt; like everybody else. But I had never actually read &lt;a href=&#34;http://www.amazon.com/Getting-Things-Done-Stress-Free-Productivity/dp/0142000280&#34;&gt;the book&lt;/a&gt; before because I thought I didn&#39;t need such a sophisticated todo tracker. That changed when I started a new job and moved to a different country. Suddenly there were so much more things to keep track of and do. So I read the book, pulled out Things again and tried to implement my version of GTD. However it became apparent to me very quickly that the way I want to use it (collect everything and have a lot of different ways to retrieve/view data) wouldn&#39;t work with Things. So I shelled out a lot of money and bought OmniFocus. And I have tried a couple of times to use a different tool again but nothing worked for me as good as OF does. Mainly because I have arrived at a setup that is very well integrated with my daily workflow.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-basics&#34;&gt;The Basics&lt;/h3&gt;&#xA;&lt;p&gt;I have OmniFocus running on my personal and work laptop as well as on the iPhone and iPad (although I hardly ever use it on there). They are all synced through webdav and owncloud on my personal servers. I mainly use it on the laptop and the iPhone client serves mostly for quickly inputting data or pulling up a list when I&#39;m on the go.&lt;/p&gt;&#xA;&lt;h3 id=&#34;collecting-all-the-things&#34;&gt;Collecting all the things&lt;/h3&gt;&#xA;&lt;p&gt;As every GTD guide ever will tell you, the system only works if it is your one and only system that contains everything. And thus you have to add all your todos and ideas in there. I try to heavily follow this approach as I found it to be very true for me that I lose confidence in the tool as soon as it doesn&#39;t contain my whole world. Paramount to this is the ability to enter new items from basically everywhere and support every way that could generate things for you to do. Luckily for me this means only a handful of things:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Random things that I come up with&lt;/li&gt;&#xA;&lt;li&gt;Email&lt;/li&gt;&#xA;&lt;li&gt;GitHub issues&lt;/li&gt;&#xA;&lt;li&gt;Jira&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This basically covers all variations of how I have new things landing on my plate. And thus I have made sure all those things find an easy way into my inbox.&lt;/p&gt;&#xA;&lt;h4 id=&#34;random-things&#34;&gt;Random things&lt;/h4&gt;&#xA;&lt;p&gt;I use &lt;a href=&#34;http://www.alfredapp.com/&#34;&gt;Alfred 2&lt;/a&gt; heavily on the desktop to quickly switch to or open apps, convert units, lookup people, and a myriad of other things. Naturally that means this is also the place where I should be inputting all new todos as they come to mind. For that I&#39;m using an &lt;a href=&#34;http://www.alfredforum.com/topic/1041-create-new-task-in-omnifocus-inbox&#34;&gt;awesome workflow&lt;/a&gt; that I found somewhere on the internet. It allows me to fire up the Alfred prompt and simply enter &lt;code&gt;todo do awesome thing @context&lt;/code&gt; and on hitting enter the new item is in my inbox with the correct context. This allows me literally add new things in a matter of seconds and bother later with filtering, remembering and doing them.&lt;/p&gt;&#xA;&lt;h4 id=&#34;email&#34;&gt;Email&lt;/h4&gt;&#xA;&lt;p&gt;Email is a little bit trickier. There are awesome plugins for Mail.app to work with Omnifocus and I hear they make it a breeze to get things done. However my email client of choice is &lt;a href=&#34;http://www.mutt.org/&#34;&gt;mutt&lt;/a&gt;. Which means there is a bit more hacking to do (as usual). However I found a great &lt;a href=&#34;https://github.com/mrtazz/bin/blob/master/mutt-to-omnifocus.py&#34;&gt;Python script&lt;/a&gt; that parses emails and adds them to Omnifocus. I also added this keybinding to my mutt configuration:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;macro index,pager \Ca &amp;quot;&amp;lt;enter-command&amp;gt;unset&#xA;wait_key&amp;lt;enter&amp;gt;&amp;lt;pipe-message&amp;gt;mutt-to-omnifocus.py&#xA;&amp;lt;enter&amp;gt;&amp;lt;save-message&amp;gt;=gtd-needs-reply/&amp;lt;enter&amp;gt;&amp;lt;sync-mailbox&amp;gt;&amp;quot;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Now all I have to do when reading an Email or browsing through the list is hit &lt;code&gt;Ctrl-a&lt;/code&gt; and mutt automatically creates a task in my Omnifocus inbox and moves the email out of my inbox into a folder I creatively called &lt;em&gt;gtd-needs-reply&lt;/em&gt; (I also have one called &lt;em&gt;gtd-to-read&lt;/em&gt; which I use for emails that I still have to read). This keeps my Email inbox clean and has the benefit since it adds an Omnifocus entry with the context &#34;Email&#34; that I can easily find all the emails I have to write with a custom perspective (more on that later).&lt;/p&gt;&#xA;&lt;h4 id=&#34;github-issues&#34;&gt;GitHub Issues&lt;/h4&gt;&#xA;&lt;p&gt;A decent amount of things to do for me are also generated via GitHub Issues. This can either be issues on one of the public GitHub projects I maintain or more often a code review &lt;a href=&#34;https://www.etsy.com&#34;&gt;at work&lt;/a&gt;. We use Pull Requests on GitHub Enterprise for code reviews at Etsy and if someone wants you to review code, they assign the pull request to you. Since there is no need for me to go through my Email for notifications about code I have to review, I wrote a simple script that runs every 10 minutes and checks whether I have issues assigned that are not yet in my Omnifcous. &lt;a href=&#34;https://github.com/mrtazz/bin/blob/master/ghfocus.rb&#34;&gt;This script&lt;/a&gt; reads a configuration file which can have an arbitrary number of GitHub (Enterprise) instances and asks for all issues assigned to a user owning the OAuth token. It then generates a ticket title based on the repo URL and issue number and adds a configurable context (Github or EtsyGithub for me) to it. It then creates an Omnifocus inbox tasks based on that data, again easily findable by context in Omnifocus.&lt;/p&gt;&#xA;&lt;h4 id=&#34;jira&#34;&gt;Jira&lt;/h4&gt;&#xA;&lt;p&gt;We use Jira at Etsy to manage tickets and workload and thus the majority of my work is captured in there. Since I don&#39;t want to have two places to look for things, I&#39;m also pulling all my Jira tickets into Omnifocus. This is done with basically the same script as the GitHub sync but uses &lt;a href=&#34;https://github.com/codehaus/jira4r&#34;&gt;jira4r&lt;/a&gt; as the input source. It then drops a todo item with the Jira project key and ticket number into my inbox with the context &lt;em&gt;Etsy:Jira&lt;/em&gt;. This makes it super easy to organize all the work I am assigned in Omnifocus. The only downside to that is that it&#39;s not a 2-way sync. Right now I clean up and close tasks in Omnifocus (and Jira) when I actually finish them or during the weekly review. I also only create tickets for myself in Jira and don&#39;t add tickets from Omnifocus when I create new todos with the &lt;em&gt;Etsy:Jira&lt;/em&gt; context. This wouldn&#39;t be very hard to do but I haven&#39;t found it to be super painful to do it manually.&lt;/p&gt;&#xA;&lt;h3 id=&#34;basic-structure&#34;&gt;Basic Structure&lt;/h3&gt;&#xA;&lt;p&gt;So now that I have an easy way to enter all the incoming work into Omnifcous, the next step is organizing all the things. For that I use folders heavily for the basic structure and something close to the Areas of Responsibility in the &lt;a href=&#34;http://www.amazon.com/Getting-Things-Done-Stress-Free-Productivity/dp/0142000280&#34;&gt;GTD book&lt;/a&gt;. I have top level folders for &lt;em&gt;Etsy&lt;/em&gt;, &lt;em&gt;Personal&lt;/em&gt;, &lt;em&gt;Talks&lt;/em&gt; and &lt;em&gt;Open Source&lt;/em&gt;. And under those another layer of folders which reflect finer grained areas of responsibility. You see the structure here:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/of_structure.png&#34; alt=&#34;of structure&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;Within those areas a have the actual projects I work on and usually a single action list project for miscellaneous things. I organize active and someday projects in there by putting someday projects in &lt;em&gt;On Hold&lt;/em&gt; status. This makes it easy to find projects I&#39;m working on by filtering for active ones in a perspective. The project view is the most important one for finding and organizing my work. I never fully got into using contexts for things other than automated tools that pull in data. I rarely find myself in actually different contexts where it makes sense to pull up a specific list and all my tries to get that working ended in confusion for me (ymmv).&lt;/p&gt;&#xA;&lt;h3 id=&#34;perspectives-all-the-way-down&#34;&gt;Perspectives all the way down&lt;/h3&gt;&#xA;&lt;p&gt;Based on that structure I have created a handful of custom perspectives to quickly find things I need. You can see the overview of my perspectives in the screenshot below.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/of_perspectives.png&#34; alt=&#34;of perspectives&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;The most important one is the &lt;em&gt;Today&lt;/em&gt; perspective. It holds all items that are due, overdue or flagged. This is my daily todo list with things I wanna get done today. The next ones are Etsy active projects, next actions and weekly summary. Those I pull up for planning daily tasks and writing my weekly summary. I also have a perspective for Personal active projects which I don&#39;t use that much but still pull up often enough to be valuable. The only crux with those perspectives is that they are mostly project and not context based. That means most of the perspectives don&#39;t sync to the iPhone. For now that is ok for me because I mostly use the iPhone to add stuff to the inbox and to check my daily todo list which I made a context based perspective. And &lt;a href=&#34;https://twitter.com/kcase/status/465904405141671938&#34;&gt;I&#39;ve also heard&lt;/a&gt; that project based perspectives will be syncing to the iPhone in the future. So that will help a lot.&lt;/p&gt;&#xA;&lt;h3 id=&#34;review-review-review&#34;&gt;Review, Review, Review&lt;/h3&gt;&#xA;&lt;p&gt;As every person that is trying to do their version of GTD will tell you, consistent reviews are the heart of a working system. And that is no different for me. I try to really be disciplined about my weekly reviews and try to do daily reviews but often only end up actually doing them 3 times a week or so. Which is not too bad as long as the weekly review is consistent.&lt;/p&gt;&#xA;&lt;h4 id=&#34;daily&#34;&gt;Daily&lt;/h4&gt;&#xA;&lt;p&gt;My daily review routine is pretty straight forward. I pull up the today list and mark everything as done I completed but haven&#39;t checked off yet. Then I pull up my active perspectives and flag stuff I wanna work on today. That&#39;s it, simple and easy.&lt;/p&gt;&#xA;&lt;h4 id=&#34;weekly&#34;&gt;Weekly&lt;/h4&gt;&#xA;&lt;p&gt;My weekly review is a bit more complex. I actually have a recurring project that becomes available every Friday and is due on Sunday and looks like this:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/of_weekly_review.png&#34; alt=&#34;of weekly review&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;This is my checklist to do my weekly review. So every weekend I will clear out and archive all email and filter unprocessed email into &lt;em&gt;gtd-to-read&lt;/em&gt; or &lt;em&gt;gtd-needs-reply&lt;/em&gt;. This is mostly mailing list stuff since I try to stay on Inbox Zero during the week. I then put every thing I can think of that has to be done into the inbox. I check my calendar from last week if there is anything left to be done from meetings and check next weeks calendar for stuff I have to prepare. I then hit the &lt;em&gt;Review&lt;/em&gt; button in Omnifocus and start reviewing all my projects. That usually starts with sorting all the inbox items into the folder structure and then going through all the other projects to mark things as completed and add new actions. This usually takes a bit longer for active projects, whereas on hold projects I can go over quickly because they don&#39;t usually have a lot of activity. I have set my default review cycle to 5 days in general. That means projects become available for review again after 5 days, so when I don&#39;t get to it on the Weekend and do my review on Monday morning, I still have the projects ready for review on Friday.&lt;/p&gt;&#xA;&lt;h3 id=&#34;verdict&#34;&gt;Verdict&lt;/h3&gt;&#xA;&lt;p&gt;For now I think I have found a good balance of using a lot of features of Omnifocus while still keeping it somewhat simple and not going overboard with the setup. Automating a lot of things - especially for inputting data - has made a big difference in trusting the system to be my only source of truth for work that needs to be done. My biggest problems are still making sure to take enough time for the reviews, keep adding todos and paying attention to my daily list even if I&#39;m stressed and some days also ... you know ... actually getting things done.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2014/05/13/omnifocus.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;At this point it&#39;s pretty fair to say that &lt;a href=&#34;http://www.omnigroup.com/omnifocus&#34;&gt;OmniFocus</summary>
  </entry>
  <entry>
    <title>My 5 years of GitHub</title>
    <updated>2014-03-28T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2014,2014-03-28:/03/28/5-years-github.html</id>
    <content type="html">&lt;p&gt;In early 2009 I was very much not the typical programmer. I had just spent 3 years part time in what was basically systems administration during my undergrad and 1 year of &lt;a href=&#34;http://en.wikipedia.org/wiki/Manufacturing_execution_system&#34;&gt;trying to connect chemical production plants to computers&lt;/a&gt;. I had to write code for some of my University assignments and had done some shell scripting in my spare time before (all the sysadmin stuff was Windows and there was not a lot of scripting involved there). However in general I had this idea that systems administration and IT was completely orthogonal to writing code and a lot of the Software Engineering classes I had up to the point didn&#39;t really spur my interest. They usually featured a lot of software processes, XML, SOAP, and simple C#.NET Windows applications. Nothing I was really interested in. But after graduating in 2007 and working full time I had this feeling every day that something was missing. I had no idea what I wanted to do with my computer degree, I loved working with computers but I felt I had nothing I was really good at. And the nature of my degree was that it was very practical. Which helped me a lot setting foot and getting started in the industry, but I felt like I was missing all the theoretical education you would get in a more traditional university setting. So I decided to go back to University and get a Masters degree. And I also quit my job and worked part time as an Embedded Systems developer. Which put me way more out of my comfort zone than I expected. But it also confronted me with a lot of new things regarding software development. My first project at work was actually a web based network sniffer that ran on a microcontroller. So I accidentally started learning more about web development while working at an Embedded shop. And another really fortunate accident was that one of our lead engineers - &lt;a href=&#34;https://github.com/nbraun&#34;&gt;Nathan&lt;/a&gt; - was really into git. And me being a subversion fan at the time resulted in some really interesting discussions which made me look into git.&lt;/p&gt;&#xA;&lt;h3 id=&#34;enter-twitter-twsh-and-github&#34;&gt;Enter Twitter, twsh and GitHub&lt;/h3&gt;&#xA;&lt;p&gt;I had signed up for Twitter in mid 2007 while I was writing my Bachelor thesis and literally had no idea what I was supposed to do with it. In my circle of coworkers and friends who worked with computers I was most of the time one of the first to explore new things and thus I didn&#39;t know a single person with a twitter account. I don&#39;t even remember how I heard about Twitter in a world that doesn&#39;t have Twitter. But I had &lt;a href=&#34;https://twitter.com/mrtazz/statuses/130573092&#34;&gt;extremely interesting tweets&lt;/a&gt; back then already of course. Fast forward to 2009 my new found interest in programming from my new job and the programming I had to do for class assignments in university meant that I was constantly trying out new things and experimenting with the concepts I learned. So at some point I decided I wanted to have a twitter command line client and started to write &lt;a href=&#34;https://github.com/mrtazz/twsh&#34;&gt;the twitter shell&lt;/a&gt;. It was painful and slow and I had no idea what I was doing. It was living there in a subversion repository on my Mac mini at home and I wanted to open source it eventually. I had no idea what that really meant either. But I had used a lot of open source software and was always fascinated by the idea that I could just look into how things work.&lt;/p&gt;&#xA;&lt;p&gt;I first looked into hosting it on Google code but I found it to be ugly and weird. And a lot of people in my twitter stream were talking about git and this new thing called GitHub. Since there was nothing really tying me into subversion, I moved the code over to git and signed up for a GitHub account on March 28th 2009.&lt;/p&gt;&#xA;&lt;h3 id=&#34;brave-new-world&#34;&gt;Brave New World&lt;/h3&gt;&#xA;&lt;p&gt;And it &lt;em&gt;literally&lt;/em&gt; changed my world. I suddenly found a lot of people who were doing so many interesting things. And it encouraged me to work on all the ideas I had floating in my mind but thought were useless or boring. I found out about the programming communities behind languages like ruby or python. How to package software to be installed from PyPi. I started thinking about how to split software into projects as libraries and how to design APIs. I wrote API wrappers for things like &lt;a href=&#34;https://github.com/mrtazz/InstapaperLibrary&#34;&gt;Instapaper&lt;/a&gt;, &lt;a href=&#34;https://github.com/mrtazz/notifo.py&#34;&gt;a Notifo library&lt;/a&gt; or a tool to import YAML based groceries lists into the &lt;a href=&#34;http://sophiestication.com/groceries/&#34;&gt;iPhone Groceries app&lt;/a&gt; and I also heard about continuous integration for the first time.&lt;/p&gt;&#xA;&lt;p&gt;And I was fascinated by the idea of having a build system do all those things I usually ran commands for automatically. I read up on it and tried to get &lt;a href=&#34;https://github.com/integrity/integrity&#34;&gt;Integrity&lt;/a&gt; up and running, which seemed to be the most accessible solution to me at the time. And having worked on the notifo library I wanted it to push to my phone whenever a build would break or work (yes in general it was quiet enough for me back then that I wanted all of the notifications). So the time had come to contribute to an Open Source project and figure out how to ruby and write unit tests and all of those things. I wrote the notifier, submitted a pull request and after some feedback and improvements, &lt;a href=&#34;https://twitter.com/sr&#34;&gt;Simon&lt;/a&gt; merged my notifier into master and I was super excited. I was finally able to have it running on my own CI instance and know the status of my builds with just a quick glance at my phone:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/integrity-notifo.png&#34; alt=&#34;integrity pull request merged&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;After that I was less terrified of contributing to Open Source and just trying out things. I kept perusing the GitHub explore page and found all those interesting projects. I went into something like an Open Source rampage and tried to contribute to and open source as much as possible. I even signed up for &lt;a href=&#34;https://github.com/blog/178-it-s-a-calendar-about-nothing&#34;&gt;Calendar About Nothing&lt;/a&gt; and maintained something like 120 days with consecutive contributions at some point. And whenever I decided to push a new project I would meet and engage with more people and learn new things. For example I wrote the &lt;a href=&#34;http://www.unwiredcouch.com/2010/04/21/plustache.html&#34;&gt;C++ implementation&lt;/a&gt; of Mustache templating for fun and met &lt;a href=&#34;https://twitter.com/janl&#34;&gt;Jan&lt;/a&gt; because of that. Which then led to me meeting a lot of other awesome people in Berlin and around the internet.&lt;/p&gt;&#xA;&lt;p&gt;And even though twsh never actually got finished and I lost interest in it, I can definitely say that GitHub has changed my computing life to the amazing. And I probably wouldn&#39;t be where I am now without it.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2014/03/28/5-years-github.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;In early 2009 I was very much not the typical programmer. I had just spent 3 years part time in w</summary>
  </entry>
  <entry>
    <title>Backups with rsync and zfs</title>
    <updated>2014-03-18T00:00:00Z</updated>
    <id>tag:unwiredcouch.combits,2014-03-18:/2014/03/18/zfs-rsync-backups.html</id>
    <content type="html">&lt;p&gt;As I &lt;a href=&#34;http://www.unwiredcouch.com/2013/10/30/uncloud-your-life.html&#34;&gt;mentioned before&lt;/a&gt; I&#39;m running my own backup on a server that is running in my apartment. I didn&#39;t really talk a lot about how this works, other than it is running on a HP Microserver with an encrypted ZFS RAID. So I wanted to also quickly jot down how the backup works. This is only set up for a single user right now because I&#39;m the only one using it.&lt;/p&gt;&#xA;&lt;p&gt;For me a backup has two important parts:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Have data in a different location&lt;/li&gt;&#xA;&lt;li&gt;Be able to restore data from the past&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The time sensitivity of those two properties are pretty different for me. For example I have chosen for myself that I&#39;m happy with only being able to restore deleted data from the last day. So if I create something and delete it 5 hours later, I&#39;m ok with not being able to recover it. On the other hand I&#39;m very aware of the fact that my mailserver can disappear at any given time:&lt;/p&gt;&#xA;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;en&#34;&gt;&lt;p&gt;that moment when you want to make dinner and your mailserver disappears&lt;/p&gt;&amp;mdash; Daniel Schauenberg (@mrtazz) &lt;a href=&#34;https://twitter.com/mrtazz/statuses/411689583370592256&#34;&gt;December 14, 2013&lt;/a&gt;&lt;/blockquote&gt;&#xA;&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&#xA;&lt;p&gt;This is why I want to copy data to a remote location as often as possible (which for me means about every 15 minutes). And my setup is heavily based around those ideas. The core of the backup system is ZFS and a separate file system for each machine I want to backup. In order to have the ability to go back in time I use &lt;a href=&#34;http://docs.oracle.com/cd/E19253-01/819-5461/gbcya/index.html&#34;&gt;zfs snapshots&lt;/a&gt;. Every night the following script runs on my backup server and creates a snapshot for the day:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#!/bin/sh&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# simple script to snapshot locations on a ZFS backup pool&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-4&#34;&gt;&lt;a href=&#34;#cb1-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;timestamp=&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;date&lt;/span&gt; +%Y-%m-%d-%H:%M:%S&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-5&#34;&gt;&lt;a href=&#34;#cb1-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;volume&lt;/span&gt; in &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;ls&lt;/span&gt; /backup&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-6&#34;&gt;&lt;a href=&#34;#cb1-6&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;Creating snapshot for &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${volume}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; at date &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${timestamp}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-7&#34;&gt;&lt;a href=&#34;#cb1-7&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;ex&#34;&gt;/sbin/zfs&lt;/span&gt; snapshot backup/&lt;span class=&#34;va&#34;&gt;${volume}&lt;/span&gt;@&lt;span class=&#34;va&#34;&gt;${timestamp}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-8&#34;&gt;&lt;a href=&#34;#cb1-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;done&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;And to make sure that I really do have snapshots I have this simple nagios script to tell me if the snapshotting worked last night.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#!/bin/sh&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# nagios script to check age of backup snapshots&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;YESTERDAY=&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;date&lt;/span&gt; -v-1d +%Y-%m-%d&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-6&#34;&gt;&lt;a href=&#34;#cb2-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;EXITCODE=&lt;/span&gt;0&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-7&#34;&gt;&lt;a href=&#34;#cb2-7&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-8&#34;&gt;&lt;a href=&#34;#cb2-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;backup&lt;/span&gt; in &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;ls&lt;/span&gt; /backup&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-9&#34;&gt;&lt;a href=&#34;#cb2-9&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;ex&#34;&gt;zfs&lt;/span&gt; list -t snapshot &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;grep&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${backup}&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;grep&lt;/span&gt; -q &lt;span class=&#34;va&#34;&gt;${YESTERDAY}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-10&#34;&gt;&lt;a href=&#34;#cb2-10&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$?&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;!=&lt;/span&gt; 0&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-11&#34;&gt;&lt;a href=&#34;#cb2-11&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;Snapshot of &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${backup}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; missing for &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${YESTERDAY}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;.&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-12&#34;&gt;&lt;a href=&#34;#cb2-12&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;va&#34;&gt;EXITCODE=&lt;/span&gt;2&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-13&#34;&gt;&lt;a href=&#34;#cb2-13&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-14&#34;&gt;&lt;a href=&#34;#cb2-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;done&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-15&#34;&gt;&lt;a href=&#34;#cb2-15&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-16&#34;&gt;&lt;a href=&#34;#cb2-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${EXITCODE}&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;==&lt;/span&gt; 0&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-17&#34;&gt;&lt;a href=&#34;#cb2-17&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;All backup volumes were snapshotted on &lt;/span&gt;&lt;span class=&#34;va&#34;&gt;${YESTERDAY}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;.&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-18&#34;&gt;&lt;a href=&#34;#cb2-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-19&#34;&gt;&lt;a href=&#34;#cb2-19&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-20&#34;&gt;&lt;a href=&#34;#cb2-20&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;exit&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${EXITCODE}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;And this check (which runs on all my servers because I have zpools everywhere) to tell me about the disk health of the backup zpool:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#!/bin/sh&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# check for zpool health&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;ZPOOL=&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;which&lt;/span&gt; zpool&lt;span class=&#34;kw&#34;&gt;`&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;EXITSTATUS=&lt;/span&gt;0&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-6&#34;&gt;&lt;a href=&#34;#cb3-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;IFS=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;$&amp;#39;&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-7&#34;&gt;&lt;a href=&#34;#cb3-7&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-8&#34;&gt;&lt;a href=&#34;#cb3-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;line&lt;/span&gt; in &lt;span class=&#34;va&#34;&gt;$(${ZPOOL}&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;list&lt;/span&gt; -o name,health &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;grep&lt;/span&gt; -v NAME &lt;span class=&#34;kw&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;grep&lt;/span&gt; -v ONLINE&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-9&#34;&gt;&lt;a href=&#34;#cb3-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-10&#34;&gt;&lt;a href=&#34;#cb3-10&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$line&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-11&#34;&gt;&lt;a href=&#34;#cb3-11&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;va&#34;&gt;EXITSTATUS=&lt;/span&gt;2&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-12&#34;&gt;&lt;a href=&#34;#cb3-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;done&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-13&#34;&gt;&lt;a href=&#34;#cb3-13&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-14&#34;&gt;&lt;a href=&#34;#cb3-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$EXITSTATUS&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;==&lt;/span&gt; 0&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-15&#34;&gt;&lt;a href=&#34;#cb3-15&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;bu&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;All pools are healthy.&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-16&#34;&gt;&lt;a href=&#34;#cb3-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-17&#34;&gt;&lt;a href=&#34;#cb3-17&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-18&#34;&gt;&lt;a href=&#34;#cb3-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;exit&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$EXITSTATUS&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;With this setup in place I can simply copy files into the file system that belongs to that machine and it will get snapshotted every night. And what&#39;s an awesome tool to copy data? That&#39;s right, &lt;a href=&#34;http://rsync.samba.org&#34;&gt;rsync&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;My backup script runs once every 15 minutes and looks like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#!/bin/sh&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Backup script to pull in changes from remote hosts&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-5&#34;&gt;&lt;a href=&#34;#cb4-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;backup&lt;/span&gt; in &lt;span class=&#34;va&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;ls&lt;/span&gt; /backup&lt;span class=&#34;va&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-6&#34;&gt;&lt;a href=&#34;#cb4-6&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;grep&lt;/span&gt; -q &lt;span class=&#34;va&#34;&gt;${backup}&lt;/span&gt; ~/.backupexcludes&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-7&#34;&gt;&lt;a href=&#34;#cb4-7&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;bu&#34;&gt; [&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;$?&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;!=&lt;/span&gt; 0&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt;; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-8&#34;&gt;&lt;a href=&#34;#cb4-8&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;/usr/local/bin/rsync&lt;/span&gt; -e &lt;span class=&#34;st&#34;&gt;&amp;#39;ssh -o BatchMode=yes -o ConnectTimeout=10&amp;#39;&lt;/span&gt; \&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-9&#34;&gt;&lt;a href=&#34;#cb4-9&#34;&gt;&lt;/a&gt;--archive --delete --timeout=5 &lt;span class=&#34;va&#34;&gt;${backup}&lt;/span&gt;:. /backup/&lt;span class=&#34;va&#34;&gt;${backup}&lt;/span&gt;/&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-10&#34;&gt;&lt;a href=&#34;#cb4-10&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-11&#34;&gt;&lt;a href=&#34;#cb4-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;done&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This allows me to have machines that I used to backup but are no longer online in an excludes list. That way rsync (and ssh) doesn&#39;t hang or error for something that doesn&#39;t need to be backed up anymore anyways. And in case a machine is unavailable or disappears the timeout settings in that script make sure it just gets skipped and retried on the next run.&lt;/p&gt;&#xA;&lt;p&gt;I&#39;m pretty happy with the setup, my backup server pulls in data from all my servers on the internet and stores it (forever?). It is chef&#39;d for the most part (though there is always more to automate) and is pretty simple in my opinion. The backup situation for my laptop is not ideal yet, as I manually back it up by running rsync. I want to set the backup server up to also serve some of the backup filesystems as Timemachine targets, so I can just use Timemachine on my laptop and have it automatically run the backups.&lt;/p&gt;&#xA;&lt;p&gt;But in the meantime I can add a new backup with this one weird trick:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;zfs&lt;/span&gt; create /backup/newhost &lt;span class=&#34;kw&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;chown&lt;/span&gt; -R mrtazz:mrtazz /backup/newhost&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;</content>
    <link href="https://unwiredcouch.combits/2014/03/18/zfs-rsync-backups.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;As I &lt;a href=&#34;http://www.unwiredcouch.com/2013/10/30/uncloud-your-life.html&#34;&gt;mentioned before&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Git - Put the stupid back in stupid content tracker</title>
    <updated>2014-02-17T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2014,2014-02-17:/02/17/git-stupid.html</id>
    <content type="html">&lt;p&gt;Git describes itself as a &lt;a href=&#34;https://www.kernel.org/pub/software/scm/git/docs/&#34;&gt;stupid content tracker&lt;/a&gt;. While this was surely meant as a clever pun and an understatement, there is some truth to it. When you go to seek out workflows with git and try to understand how people use it, there is a myriad of flows and recommendations. Most of them focus on the areas of git which are often considered to be on a higher level of the usage ladder. Rebasing, squashing, cherry-picking and all those features. And most often they are considered to be part of your everyday workflow. And while I&#39;m in no position to judge whether those techniques are ideal for certain teams and their workflows I think they are most of the time way too complex to work in larger teams and across people with different skill levels. Once you tell people they should squash/rebase on all branches when merging upstream and alias pull to pull --rebase but not when you have merged a feature branch and not pushed it yet so remember this when you write code and concentrate on the next deploy you&#39;re probably gonna have a bad time.&lt;/p&gt;&#xA;&lt;p&gt;See this is not what you should have to remember to commit the code you just wrote to disk. I&#39;ve seen such recommendations and the following complaints when the workflow breaks down a couple of times now. It even led me to compose this fascinating tweet at one point:&lt;/p&gt;&#xA;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;en&#34;&gt;&#xA;&lt;p&gt;Before complaining about git&#xA;please consider answering these 2 questions:&amp;#10;1. Were you trying to be&#xA;overly clever?&amp;#10;2. Were you expecting svn?&#xA;&lt;/p&gt;&#xA;&amp;mdash; Daniel Schauenberg (@mrtazz)&#xA;&lt;a href=&#34;https://twitter.com/mrtazz/statuses/341841535165415424&#34;&gt;June 4, 2013&lt;/a&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&#xA;&lt;h3 id=&#34;the-example&#34;&gt;The Example&lt;/h3&gt;&#xA;&lt;p&gt;But in all seriousness in the end the most important thing about git is that it lets you commit changes to disk in a way so that your future self can figure out what changed later. And I want to highlight why I think it makes more sense to start simple and then figure out if additional features really make sense for you.&lt;/p&gt;&#xA;&lt;p&gt;Let&#39;s take an example workflow you can find on the internet and take a look:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;git pull --rebase instead of git pull&lt;/p&gt;&#xA;&lt;p&gt;git rebase -i @{u} before git push&lt;/p&gt;&#xA;&lt;p&gt;(on “feature”)&lt;/p&gt;&#xA;&lt;p&gt;git merge master&lt;/p&gt;&#xA;&lt;p&gt;to make feature compatible with latest master&lt;/p&gt;&#xA;&lt;p&gt;(on “master”)&lt;/p&gt;&#xA;&lt;p&gt;git merge --no-ff feature to ship a feature&lt;/p&gt;&#xA;&lt;p&gt;However if “feature” contains only 1 commit, avoid the merge commit:&lt;/p&gt;&#xA;&lt;p&gt;(on “master”)&lt;/p&gt;&#xA;&lt;p&gt;git cherry-pick feature&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;It doesn&#39;t matter where this is from because I don&#39;t want to disrespect the author or their ability to choose a workflow that works for them. It just is a good example (of which you can find hundreds that are similar on the web) of what a lot of people think a git workflow has to be like and cargo cult it into their setup. After all if you&#39;re not using all features of git you must be missing out on precious productivity right?&lt;/p&gt;&#xA;&lt;p&gt;Back to the example. Have you kept track and can remember without looking when to merge, rebase or cherry-pick? You are basically doing the same thing - bringing new commits to your branch - and you have to do 3 different things depending on some circumstances. But this isn&#39;t even the most error prone part. Let&#39;s consider you work on a fairly active project with a lot of people. You are maybe even doing continuous integration and continuous deployment and trunk/master gets commited to all the time. You are working on a feature in a branch (btw while we&#39;re at it read &lt;a href=&#34;http://whilefalse.blogspot.de/2013/02/branching-is-easy-so.html&#34;&gt;Camille Fourniers&#39; excellent blog post&lt;/a&gt; to find out why you actually shouldn&#39;t do this in a continuous deployment setup) and want to pull in changes from master. So you merge master as per the instructions. You notice someone else has pushed to the feature branch in the meantime. You update the local branch with &lt;code&gt;pull --rebase&lt;/code&gt; as per the instructions again and push up your changes. If you ever had to do this you won&#39;t be surprised that your working tree now looks something like this:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/feature-rebase.png&#34; alt=&#34;rebase on the feature branch&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;You now have the same commit with two different SHA IDs on different branches. This might not look like a big problem right now. But I for one don&#39;t like to have multiple IDs for the same thing and also think that having two commits doing the same thing is not an ideal situation.&lt;/p&gt;&#xA;&lt;p&gt;But even if you work alone on your feature branch and don&#39;t need to rebase before pushing you will eventually run into a similar situation on your master branch. You have worked on your feature branch for a while. You opened a pull request, incorporated feedback and pushed it back up to the branch. People have linked to your commits in tickets to note that it fixes stuff they&#39;ve been waiting on. Now the big moment has come and you want to integrate with master. You pull in changes from origin, you run &lt;code&gt;git merge --no-ff feature-branch&lt;/code&gt; to bring in the changes with a clean merge commit. You run &lt;code&gt;git push&lt;/code&gt; but there have been upstream changes. So you bring them in again as always with &lt;code&gt;git pull --rebase&lt;/code&gt;. Now you can push and everything&#39;s fine right? Well almost, except that last rebase has rewritten all your commits from your feature branch (if you additionally ran &lt;code&gt;git rebase -i&lt;/code&gt; before pushing you are probably very well aware of this). You might think that this is ok or even intended since you wanted to clean up your commits anyways. And that this makes it much cleaner and easier to read. However what you effectively just did was rewrite (git) history and remove public references of changes. Everybody who linked to your commits now has links pointing to a non existing resource (they will still be there until you eventually clean up the remote feature branch but this is just details in my opinion). Pull requests don&#39;t get automatically closed and you sure don&#39;t remember to do it by hand and all references in there are useless anyways. And all just for a little bit of beautification of how you actually did your work.&lt;/p&gt;&#xA;&lt;h3 id=&#34;so-what-are-you-saying&#34;&gt;So what are you saying?&lt;/h3&gt;&#xA;&lt;p&gt;Does that mean you should never use rebase? Am I saying that only the basic git commands are supposed to be part of a workflow? Do I call all these developers using advanced techniques stupid?&lt;/p&gt;&#xA;&lt;p&gt;N-O-P-E&lt;/p&gt;&#xA;&lt;p&gt;I do use rebase in some occasions, I don&#39;t think it&#39;s the devil&#39;s work. There are legitimate reasons to use it and it sure is helpful sometimes. However when you&#39;re starting to get into git or migrating to it and building a workflow for your team it often makes the most sense to start with the simplest thing that could possibly work. git add, commit, push, pull, merge. All these are safe operations and don&#39;t break anything for others and most likely don&#39;t bring you into weird situations where you&#39;re totally stuck and lost. There might come a time where you bring rebase and its siblings into the&lt;/p&gt;&#xA;&lt;p&gt;mix. But then there should be a reason and it hopefully is because it helps you be more productive and removes confusion in your team. And I sure hope you know how it works and what you&#39;re getting yourself into. Because it can be what you end up with but it shouldn&#39;t be where you start. Keep it stupid simple.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2014/02/17/git-stupid.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Git describes itself as a &lt;a href=&#34;https://www.kernel.org/pub/software/scm/git/docs/&#34;&gt;stupid cont</summary>
  </entry>
  <entry>
    <title>Context specific dotfiles</title>
    <updated>2014-02-03T00:00:00Z</updated>
    <id>tag:unwiredcouch.combits,2014-02-03:/2014/02/03/dotoverride.html</id>
    <content type="html">&lt;p&gt;I have a &lt;a href=&#34;https://github.com/mrtazz/muttfiles&#34;&gt;collection&lt;/a&gt; &lt;a href=&#34;https://github.com/mrtazz/vimfiles&#34;&gt;of&lt;/a&gt; &lt;a href=&#34;https://github.com/mrtazz/zshfiles&#34;&gt;various&lt;/a&gt; &lt;a href=&#34;https://github.com/mrtazz/dotfiles&#34;&gt;dotfiles&lt;/a&gt; which I use to configure the most important tools I use everyday. Naturally all those are kept in git and shared between all the machines I work on. The problem is that there might be things I don&#39;t want to store publicly. This might include shell aliases to hostnames, git user emails I only use at work, etc. I used to manage this by having a different branch checked out on machines at work and would just merge in master whenever something changes. However this was super tedious as I had to remember to switch to the right branch depending on whether I wanted to make public or private changes. And after changing something I had to remember to switch back to the correct branch and not accidentally push the private branch to public GitHub. What it effectively ended up being was a whole bunch of dirty repos on different machines that were never in sync and partly had duplicate changes and partly only worked on that box anyways. And whenever I wanted to bring them back in sync it was a huge pain. So I decided to adopt a new strategy for managing context specific dotfiles.&lt;/p&gt;&#xA;&lt;p&gt;I added a git repo &lt;code&gt;~/.dotoverrides&lt;/code&gt; to all the machines I work on (or at least most of them) which contains a &lt;code&gt;vimrc&lt;/code&gt;, a &lt;code&gt;zshrc&lt;/code&gt; and so on. On my work machines this is pushed to a repo on our internal GitHub Enterprise instance so I can easily share it between machines. And all my regular dotfiles now source those override files at the very end.&lt;/p&gt;&#xA;&lt;p&gt;So in my regular &lt;code&gt;.vimrc&lt;/code&gt; I have something like this:&lt;/p&gt;&#xA;&lt;pre class=&#34;vim&#34;&gt;&lt;code&gt;&amp;quot; source overrides configs&#xA;if filereadable($HOME.&amp;quot;/.dotoverrides/vimrc&amp;quot;)&#xA;  exec &amp;quot;:source &amp;quot;. $HOME . &amp;quot;/.dotoverrides/vimrc&amp;quot;&#xA;endif&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;In my &lt;code&gt;.zshrc&lt;/code&gt; I have this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;[&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;-f&lt;/span&gt;  &lt;span class=&#34;va&#34;&gt;${HOME}&lt;/span&gt;/.dotoverrides/zshrc&lt;span class=&#34;bu&#34;&gt; ]&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;bu&#34;&gt;source&lt;/span&gt; &lt;span class=&#34;va&#34;&gt;${HOME}&lt;/span&gt;/.dotoverrides/zshrc&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;And in git (only works if you have at least v1.7.10) I&#39;ve added this stanza:&lt;/p&gt;&#xA;&lt;pre class=&#34;config&#34;&gt;&lt;code&gt;[include]&#xA;  path = ~/.dotoverrides/gitconfig&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Now I can easily share and push/pull my regular dotfiles in public GitHub and don&#39;t have to pay attention whether or not I&#39;m on the correct branch and if I&#39;m not accidentally pushing to the wrong remote. Whenever I need to use different settings on a work machine I just make sure to add it to the overrides file and have it ready as soon as I open a new shell, run a git command or open vim again.&lt;/p&gt;&#xA;&lt;p&gt;So much easier!&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.combits/2014/02/03/dotoverride.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I have a &lt;a href=&#34;https://github.com/mrtazz/muttfiles&#34;&gt;collection&lt;/a&gt; &lt;a href=&#34;https://github.com</summary>
  </entry>
  <entry>
    <title>Creating Encrypted Home Directories in FreeBSD</title>
    <updated>2013-12-28T00:00:00Z</updated>
    <id>tag:unwiredcouch.combits,2013-12-28:/2013/12/28/encrypted-homedirs.html</id>
    <content type="html">&lt;p&gt;I run FreeBSD with ZFS on all my servers and I generally want to have my home directories encrypted. Since ZFS native encryption is not yet in FreeBSD, I create two ZFS filesystems, which are then encrypted with &lt;a href=&#34;http://www.freebsd.org/doc/handbook/disks-encrypting.html&#34;&gt;GELI encryption&lt;/a&gt; and build a new ZFS pool. This pool is then used as my home directory. In order to simplify this, I have a shell script that takes the username and size as input and creates keys and all partitions as well as the zpool.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#!/bin/sh&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;USERHOME=$1&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-4&#34;&gt;&lt;a href=&#34;#cb1-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;va&#34;&gt;SIZE=$2&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-5&#34;&gt;&lt;a href=&#34;#cb1-5&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-6&#34;&gt;&lt;a href=&#34;#cb1-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;zfs&lt;/span&gt; create -omountpoint=/encrypted tank/encrypted&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-7&#34;&gt;&lt;a href=&#34;#cb1-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;zfs&lt;/span&gt; create tank/encrypted/keys&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-8&#34;&gt;&lt;a href=&#34;#cb1-8&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;zfs&lt;/span&gt; create -omountpoint=none tank/encrypted/zvols&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-9&#34;&gt;&lt;a href=&#34;#cb1-9&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;zfs&lt;/span&gt; create -ocompression=on tank/encrypted/zvols/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-10&#34;&gt;&lt;a href=&#34;#cb1-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;zfs&lt;/span&gt; create -V &lt;span class=&#34;va&#34;&gt;${SIZE}&lt;/span&gt;G tank/encrypted/zvols/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk0&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-11&#34;&gt;&lt;a href=&#34;#cb1-11&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;zfs&lt;/span&gt; create -V &lt;span class=&#34;va&#34;&gt;${SIZE}&lt;/span&gt;G tank/encrypted/zvols/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk1&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-12&#34;&gt;&lt;a href=&#34;#cb1-12&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-13&#34;&gt;&lt;a href=&#34;#cb1-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;zfs&lt;/span&gt; create tank/encrypted/keys/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-14&#34;&gt;&lt;a href=&#34;#cb1-14&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;dd&lt;/span&gt; if=/dev/random of=/encrypted/keys/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk0 bs=64 count=1&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-15&#34;&gt;&lt;a href=&#34;#cb1-15&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;dd&lt;/span&gt; if=/dev/random of=/encrypted/keys/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk1 bs=64 count=1&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-16&#34;&gt;&lt;a href=&#34;#cb1-16&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;geli&lt;/span&gt; init -s 4096 -K /encrypted/keys/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk0 \&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-17&#34;&gt;&lt;a href=&#34;#cb1-17&#34;&gt;&lt;/a&gt;/dev/zvol/tank/encrypted/zvols/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk0&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-18&#34;&gt;&lt;a href=&#34;#cb1-18&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;geli&lt;/span&gt; init -s 4096 -K /encrypted/keys/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk1 \&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-19&#34;&gt;&lt;a href=&#34;#cb1-19&#34;&gt;&lt;/a&gt;/dev/zvol/tank/encrypted/zvols/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk1&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-20&#34;&gt;&lt;a href=&#34;#cb1-20&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-21&#34;&gt;&lt;a href=&#34;#cb1-21&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;geli&lt;/span&gt; attach -k /encrypted/keys/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk0 \&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-22&#34;&gt;&lt;a href=&#34;#cb1-22&#34;&gt;&lt;/a&gt;/dev/zvol/tank/encrypted/zvols/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk0&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-23&#34;&gt;&lt;a href=&#34;#cb1-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;geli&lt;/span&gt; attach -k /encrypted/keys/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk1 \&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-24&#34;&gt;&lt;a href=&#34;#cb1-24&#34;&gt;&lt;/a&gt;/dev/zvol/tank/encrypted/zvols/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk1&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-25&#34;&gt;&lt;a href=&#34;#cb1-25&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-26&#34;&gt;&lt;a href=&#34;#cb1-26&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;zpool&lt;/span&gt; create &lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;-home raidz \&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-27&#34;&gt;&lt;a href=&#34;#cb1-27&#34;&gt;&lt;/a&gt;/dev/zvol/tank/encrypted/zvols/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk0.eli \&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-28&#34;&gt;&lt;a href=&#34;#cb1-28&#34;&gt;&lt;/a&gt;/dev/zvol/tank/encrypted/zvols/&lt;span class=&#34;va&#34;&gt;${USERHOME}&lt;/span&gt;/disk1.eli&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;I try to keep the script updated on &lt;a href=&#34;https://github.com/mrtazz/bin/blob/master/create_encrypted_zfs_home.sh&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.combits/2013/12/28/encrypted-homedirs.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I run FreeBSD with ZFS on all my servers and I generally want to have my home directories encrypt</summary>
  </entry>
  <entry>
    <title>My Tmux Setup</title>
    <updated>2013-11-15T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2013,2013-11-15:/11/15/my-tmux-setup.html</id>
    <content type="html">&lt;p&gt;I&#39;ve been using &lt;a href=&#34;http://tmux.sourceforge.net&#34;&gt;tmux&lt;/a&gt; as my main terminal multiplexer for about 3 years now and have refined my configuration over time to fit my daily workflow. Which is usually a mix of writing code, chef recipes, remote login into different servers and various shell tasks. This is a flexible setup that doesn&#39;t concentrate too much on doing a specific thing or replacing an IDE inside of tmux. The &lt;a href=&#34;https://github.com/mrtazz/dotfiles/blob/master/tmux.conf&#34;&gt;configuration&lt;/a&gt; and &lt;a href=&#34;https://github.com/mrtazz/zshfiles/blob/master/zshrc&#34;&gt;shell aliases&lt;/a&gt; are up on GitHub if you want to check them out.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-basics&#34;&gt;The Basics&lt;/h3&gt;&#xA;&lt;p&gt;Let&#39;s start with the basics. By default tmux uses &lt;code&gt;ctrl-b&lt;/code&gt; as its prefix key for commands and escaping. But the years of using screen have ingrained in my muscle memory to use &lt;code&gt;ctrl-a&lt;/code&gt;, so I switched with this simple setting:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;unbind&lt;/span&gt; C-b&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;kw&#34;&gt;set&lt;/span&gt; &lt;span class=&#34;ex&#34;&gt;-g&lt;/span&gt; prefix C-a&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;I also added a couple of important baseline settings to make tmux in general look nice in colored terminals and work with unicode in the display window as well as in the status bar. I also wanted to have the window numbering start at 1, since it doesn&#39;t make sense to me for accessing succesive windows to start on the right side of the keyboard and then continue on the left side. And I also wanted to have a simple shortcut (&lt;code&gt;ctrl-a r&lt;/code&gt;) to reload configuration in a live tmux session whenever I change something.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# force a reload of the config file&#xA;unbind r&#xA;bind r source-file ~/.tmux.conf&#xA;&#xA;# start window numbering at 1 for easier switching&#xA;set -g base-index 1&#xA;&#xA;# colors&#xA;set -g default-terminal &amp;quot;screen-256color&amp;quot;&#xA;&#xA;# unicode&#xA;setw -g utf8 on&#xA;set -g status-utf8 on&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The next important change was modifying the status bar. There are a lot of crazy things you can do and overload your tmux status bar with more information than you could ever need. I try to balance the contents of my status bar to only have information in there I actually care about. This means I have the local hostname and the name of the current session on the left side and then all the windows. The right side contains the current battery status (when I&#39;m on a laptop), the status of my mail (inbox, to read, to answer) and the time and date. Although I see less and less benefit of having the mail check in there and will probably remove it soon (currently it&#39;s only showing the inbox mail count). I also have the status bar configured to show terminal bells in red so I always know when there is something that needs attention in a window (I have weechat and mutt set to alert via terminal bells). For the colorscheme I use a &lt;a href=&#34;https://github.com/seebi/tmux-colors-solarized&#34;&gt;solarized light&lt;/a&gt; theme as you can see in the screenshot:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/tmux-status.png&#34; alt=&#34;tmux status bar&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;And the configuration for my status bar looks like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# status bar config&#xA;set -g status-left &amp;quot;#h:[#S]&amp;quot;&#xA;set -g status-left-length 50&#xA;set -g status-right-length 50&#xA;set -g status-right &amp;quot;⚡ #(~/bin/tmux-battery) [✉#(~/bin/imap_check.py)] %H:%M %d-%h-%Y&amp;quot;&#xA;setw -g window-status-current-format &amp;quot;|#I:#W|&amp;quot;&#xA;set-window-option -g automatic-rename off&#xA;&#xA;# listen to alerts from all windows&#xA;set -g bell-action any&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This is the base configuration I use for basic project sessions with tmux. I have two simple shell aliases to make it easier to re-attach to a session and create new ones based on the current directory I&#39;m in:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;alias&lt;/span&gt; tma=&lt;span class=&#34;st&#34;&gt;&amp;#39;tmux attach -d -t&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;bu&#34;&gt;alias&lt;/span&gt; git-tmux=&lt;span class=&#34;st&#34;&gt;&amp;#39;tmux new -s $(basename $(pwd))&amp;#39;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;With those I can ran &lt;code&gt;tma &amp;lt;tab&amp;gt;&lt;/code&gt; in any shell and get a tab completion list for all the current sessions running. Which is handy when logging into a machine or generally working in a new shell. The second one I usually use when I checked something in a local project (which are usually in git hence the name of the alias) and then decided that I want a proper workspace but don&#39;t have an existing session already. The alias will just create a new session on the spot and name it after the current directory name. This also has the big advantage that all new shells spawned inside of tmux (e.g. opening a new window with &lt;code&gt;ctrl-a c&lt;/code&gt;) will be started in that directory. Within those open sessions I have some more important shortcuts I use often. They allow me to cycle through panes (vertical or horizontal splits in a window created with &lt;code&gt;ctrl-a V&lt;/code&gt; and &lt;code&gt;ctrl-a H&lt;/code&gt;) with &lt;code&gt;ctrl-a a&lt;/code&gt; and to switch between windows with &lt;code&gt;ctrl-a &amp;lt;tab&amp;gt;&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# rebind pane tiling&#xA;bind V split-window -h&#xA;bind H split-window&#xA;&#xA;# quick pane cycling&#xA;unbind ^A&#xA;bind ^A select-pane -t :.+&#xA;&#xA;# screen like window toggling&#xA;bind Tab last-window&#xA;bind Escape copy-mode&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;And last but not least in every basic setup - as an avid vim user - movement commands live on the home row of course. And different panes can be selected with &lt;code&gt;ctrl-a&lt;/code&gt; and the corresponding movement command.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# vim movement bindings&#xA;set-window-option -g mode-keys vi&#xA;bind h select-pane -L&#xA;bind j select-pane -D&#xA;bind k select-pane -U&#xA;bind l select-pane -R&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;next-level&#34;&gt;Next Level&lt;/h3&gt;&#xA;&lt;p&gt;I used to use tmux sessions in multiple tabs in iTerm for a long time. However these sessions became very long living and whenever I needed to update iTerm (which wasn&#39;t that often to be honest) I had to recreate the tabs again as I wanted. Additionally I felt it was unnecessary to have multiple ways of doing basically the same thing (iTerm tabs and tmux windows/sessions) when I can just decide to use one. So I decided to switch to tmux as the main working environment on the laptop for everything. This means I have a tmux session on my laptop dedicated to communication which has a window that runs mosh with an attached tmux session from the server where I run weechat. And another window that does the same to my work VM which runs my work IRC client. And another window that just runs mutt for email reading. This means at any given time I have two nested tmux sessions as you can see in the screenshot below:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/images/nested-tmux.png&#34; alt=&#34;nested tmux&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;This lets me reattach the communications session even when I accidentally close my terminal and have it be exactly how I left it off. Even when I don&#39;t connect to a remote host, I often have nested tmux sessions locally since I use it basically like terminal tabs. This is very useful but needs one more setting in the configuration to work. Since both nested tmux sessions expect the same meta command, I have this stanza in my configuration:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;bind-key a  send-prefix&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;This sends the command prefix to the inner tmux session when I hit &lt;code&gt;ctrl-a a&lt;/code&gt; thus enabling me to execute commands in nested tmux sessions.&lt;/p&gt;&#xA;&lt;p&gt;In order to easily switch between sessions I mainly use to important commands. The first one is the tmux built-in &lt;code&gt;ctrl-a s&lt;/code&gt; which gives me a list of all current sessions on the system (the same list the &lt;code&gt;tma&lt;/code&gt; tab completion gives me) and I can easily switch sessions from within a tmux session. However this means finding the session I want in a list that might contain 20 or more sessions. And all I really want is to switch to the session named &#34;chef&#34;. This is why I added another extremely useful shortcut:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# bind fast session switching&#xA;unbind S&#xA;bind S command-prompt &amp;quot;switch -t %1&amp;quot;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Now when I hit &lt;code&gt;ctrl-a S&lt;/code&gt; I get a &lt;code&gt;(switch)&lt;/code&gt; prompt where I can enter the name of the session I want (or just the prefix as long as it is unique) and switch to that session when hitting &lt;code&gt;Return&lt;/code&gt;. This is super helpful since I have most of my sessions named after the directory/project name anyways. So I usually know which session to switch to.&lt;/p&gt;&#xA;&lt;h3 id=&#34;we-have-to-go-deeper&#34;&gt;We have to go deeper&lt;/h3&gt;&#xA;&lt;p&gt;But this is not the end yet. I have one more very useful bit of configuration I use everyday which is related to how I remote login into servers. For this purpose I have a tmux session on a server called &#34;jumpsessions&#34; in which I open a new tmux window whenever I ssh into a server. However this got very confusing after a while and I had no idea what all those windows were. So I added this little bit into my &lt;code&gt;~/.ssh/config&lt;/code&gt;:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb9&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb9-1&#34;&gt;&lt;a href=&#34;#cb9-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;Host&lt;/span&gt; *&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-2&#34;&gt;&lt;a href=&#34;#cb9-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;PermitLocalCommand&lt;/span&gt; yes&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-3&#34;&gt;&lt;a href=&#34;#cb9-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ex&#34;&gt;LocalCommand&lt;/span&gt; if [[ &lt;span class=&#34;va&#34;&gt;$TERM&lt;/span&gt; == screen* ]]&lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;bu&#34;&gt;printf&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;\033k%h\033&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;fi&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This runs a local command on each ssh login on the server I login in. With the effect that it prints the local hostname with an escape sequence that triggers tmux to set the window title to that hostname. This means if I now open the list of windows (&lt;code&gt;ctrl-a w&lt;/code&gt;) I can see to which server each window is connected. And this is also the reason why I have automatic window renaming turned off.&lt;/p&gt;&#xA;&lt;p&gt;But of course I don&#39;t want to browse through all of those windows to get to a server, so I just use the &#34;find-window&#34; command in tmux (&lt;code&gt;ctrl-a f&lt;/code&gt;) and enter the server name (which is also the window name) and will automatically switch to the correct session on hitting enter.&lt;/p&gt;&#xA;&lt;p&gt;And as the final stage of inception, I often run a screen session on those servers to execute long running commands. Which means I&#39;m now three levels deep into terminal multiplexers and it still works like a charm.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2013/11/15/my-tmux-setup.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I&#39;ve been using &lt;a href=&#34;http://tmux.sourceforge.net&#34;&gt;tmux&lt;/a&gt; as my main terminal multiplexer fo</summary>
  </entry>
  <entry>
    <title>Uncloud your Life</title>
    <updated>2013-10-30T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2013,2013-10-30:/10/30/uncloud-your-life.html</id>
    <content type="html">&lt;p&gt;There has been a lot of talk lately about privacy in the cloud and owning your own data. I&#39;m not linking any articles here, since there are so many and I don&#39;t think anyone has missed it. However it spurred a new and awesome debate about hosting your own applications and thinking about where your data is stored and who manages it. I have thought about writing this for a while and always felt there wasn&#39;t enough to write about. But in the spirit of sharing and getting back into writing I decided to do it nonetheless.&lt;/p&gt;&#xA;&lt;p&gt;The setup I&#39;m describing has grown pretty organically and is heavily based on what I use and how I work everyday. This is also probably a bit too technical to be considered a general purpose manual. But that will have to do for now. I am also a heavy FreeBSD user, as it makes a lot of things easier and more enjoyable for me. So my setup is also very biased towards that.&lt;/p&gt;&#xA;&lt;h3 id=&#34;email&#34;&gt;Email&lt;/h3&gt;&#xA;&lt;p&gt;Maybe one of the most important parts is email. I switched from hosted email providers to self hosted (first on a friend&#39;s server) in 2005, when the 12MB Inbox I had wasn&#39;t big enough anymore and before GMail was widely available in Germany (at least I only knew one person with a GMail account back then). So nothing has changed for me there. I also think email is considered to be one of the more painful things to self host although I don&#39;t think this is true. I run a setup based on &lt;a href=&#34;http://www.freebsd.org&#34;&gt;FreeBSD&lt;/a&gt;, &lt;a href=&#34;http://www.sendmail.com/sm/open_source/&#34;&gt;sendmail&lt;/a&gt; and the &lt;a href=&#34;http://www.dovecot.org&#34;&gt;Dovecot IMAP server&lt;/a&gt; which is not very complicated to set up. Especially the FreeBSD/sendmail part literally takes 10 minutes. I don&#39;t really run spam filtering since it hasn&#39;t been a problem (I do filter some known spam addresses in my procmail rules though). I read my email in &lt;a href=&#34;http://www.mutt.org&#34;&gt;mutt&lt;/a&gt; on the laptop where it is synced with &lt;a href=&#34;http://offlineimap.org&#34;&gt;offlineimap&lt;/a&gt; and also run mutt in a tmux session on my mailserver to access it from anywhere. On iOS devices I use the built-in Mail application and have come to love &lt;a href=&#34;http://www.triage.cc&#34;&gt;Triage&lt;/a&gt; for quickly going through email when I have a minute.&lt;/p&gt;&#xA;&lt;h3 id=&#34;calendars-and-contacts&#34;&gt;Calendars and Contacts&lt;/h3&gt;&#xA;&lt;p&gt;Another very important aspect of my daily synced data are calendars and contacts. Especially with the iPhone and iPad being in constant use, I want that data to be synced everywhere. I used to use iCloud for that and it works beautifully and I wanted something which works equally flawless. After some trial and error I found &lt;a href=&#34;http://owncloud.org&#34;&gt;ownCloud&lt;/a&gt; which provides CalDav and CardDav services as well as general WebDAV. The setup guides are really good and include most of the common clients. I nevertheless ran into some problems with the initial setup on iOS and OSX clients because of when and where they expect slashes or protocol headers. However this is a configuration/documentation issue, which is annoying but can be solved.&lt;/p&gt;&#xA;&lt;h3 id=&#34;file-sync&#34;&gt;File sync&lt;/h3&gt;&#xA;&lt;p&gt;I used to use &lt;a href=&#34;http://dropbox.com&#34;&gt;Dropbox&lt;/a&gt; a lot. I loved the simplicity and being able to have files in sync everywhere. I even put my git repos in there at some point so I could continue working from every computer I used. With time I used it less and less as I simplified my workflows a lot but it was still important to have a proper file sync solution, mostly for convenince options like syncing &lt;a href=&#34;http://www.alfredapp.com&#34;&gt;Alfred&lt;/a&gt; preferences. But I wanted to get all my documents out of a location that somebody else had under control. Thankfully ownCloud also comes with a client to sync the WebDAV directory between computers. So I basically set that up and copied everything over from Dropbox. It has been working really well so far, though I don&#39;t have heavy requirements for syncing and files in there don&#39;t change that often.&lt;/p&gt;&#xA;&lt;h3 id=&#34;gtdtodo-tracking&#34;&gt;GTD/Todo tracking&lt;/h3&gt;&#xA;&lt;p&gt;I track everything in &lt;a href=&#34;http://www.omnigroup.com/omnifocus&#34;&gt;OmniFocus&lt;/a&gt;. Literally. Work stuff, personal stuff, movies I want to watch, books I want to read, it pulls in GitHub issues and Jira tickets that are assigned to me, I plan blog posts I want to write and talks I want to give in there. I extensively use custom perspectives to get data out. It&#39;s safe to say that it&#39;s an important piece of software for me. Luckily Omni products support syncing via WebDAV and have been for a while. Thus it was very easy to switch from the hosted Omni Sync Server, which works flawlessly, to just use WebDAV endpoint of ownCloud. I have since also looked around to find out if there are alternatives to OmniFocus if I ever wanted to switch away from OSX. Sadly it seems to be that self hosting is rarely an option for any app and I have only found a handful that even provided a synchronisation mechanism that does not involve DropBox, Apple or their own cloud sync solution.&lt;/p&gt;&#xA;&lt;h3 id=&#34;note-taking&#34;&gt;Note taking&lt;/h3&gt;&#xA;&lt;p&gt;Note taking was also an important part that had to continue to work for me. I don&#39;t take a lot of notes all the time. But when I need to jot something down, it must not matter whether I&#39;m on my phone or in VIM on my laptop. I was a very happy &lt;a href=&#34;http://simplenote.com&#34;&gt;Simplenote&lt;/a&gt; customer and still think it&#39;s the best cloud based note taking platform there is. I even wrote a &lt;a href=&#34;https://github.com/mrtazz/simplenote.vim&#34;&gt;VIM plugin&lt;/a&gt; for it so I&#39;d never have to leave my trusty editor. This also meant a solution that would replace it needed a decent iOS client, notes I can access from VIM, support for Markdown and a syncing engine that is ideally based on WebDAV, since I was already running that. And after some searching I actually found this unicorn of note taking solutions. It&#39;s simply called &lt;a href=&#34;http://www.notebooksapp.com&#34;&gt;Notebooks&lt;/a&gt; and it&#39;s a simple app that displays the folders and files in a WebDav directory, let&#39;s you edit text files and view them in Markdown mode. And even take and attach pictures. It comes as a Universal App for iPhone and iPad and has an OSX client in a beta version, which I don&#39;t use because I can just edit all the files in VIM. Which makes me very happy.&lt;/p&gt;&#xA;&lt;h3 id=&#34;password-syncing&#34;&gt;Password syncing&lt;/h3&gt;&#xA;&lt;p&gt;The only application I haven&#39;t found a satisfying self hosted solution yet is password syncing. I use &lt;a href=&#34;https://agilebits.com/onepassword&#34;&gt;1Password&lt;/a&gt; and am very happy with it. However the only non-LAN solutions for syncing that it provides are Dropbox and iCloud. So I switched to Wi-fi sync for my passwords. It&#39;s not ideal and there will come a point where I am on my iPad and don&#39;t have a password there and am too lazy to open the laptop to sync. However since all passwords for my crucial services are already synced this won&#39;t be the end of the world and can very likely wait until I am on a nother device or have both the laptop and the iPad open. So I&#39;m not 100% happy with it but it is one of those &#34;good enough&#34; solutions.&lt;/p&gt;&#xA;&lt;h3 id=&#34;irc-and-instant-messaging&#34;&gt;IRC and Instant Messaging&lt;/h3&gt;&#xA;&lt;p&gt;Being able to idle on IRC and have a proper chat client at hand everywhere has always been important to me and for that I have run terminal based clients in a screen or tmux session for years now. Since I (similarly to email) never used any of the cloud based solutions, I was already running &lt;a href=&#34;http://wiki.znc.in/ZNC&#34;&gt;ZNC&lt;/a&gt; and &lt;a href=&#34;http://www.bitlbee.org/main.php/news.r.html&#34;&gt;Bitlbee&lt;/a&gt;. And since the changes in GTalk earlier this year which broke a lot of stuff for me, I also already had a &lt;a href=&#34;http://web.jabber.ccc.de&#34;&gt;Jabber account&lt;/a&gt; which I was using for chat and OTR.&lt;/p&gt;&#xA;&lt;h3 id=&#34;backup&#34;&gt;Backup&lt;/h3&gt;&#xA;&lt;p&gt;How to handle backups was one of the bigger concerns I had. Now that I would be hosting all my data I needed a proper plan so when one of my servers dies I&#39;m not losing everything that was on there. Like probably almost every Mac user, I used to use &lt;a href=&#34;http://www.haystacksoftware.com/arq/&#34;&gt;Arq&lt;/a&gt; to backup my laptop to an encrypted S3 bucket. However that was only ever the client side. And I was happy with it because it included my mail folder and thus I had a backup of my email. And when I stopped using that to not push all my date to S3 I also didn&#39;t backup my email anymore. After some thought it was clear to me that I wanted to have a backup in a location with as much control as possible. I decided to buy an &lt;a href=&#34;http://www8.hp.com/us/en/products/proliant-servers/product-detail.html?oid=5336619#!tab=features&#34;&gt;HP Microserver&lt;/a&gt; and put it in my apartment. It runs FreeBSD (surprise!) and has a 2x2TB encrypted ZFS RAID. The backup location for each of my machines on that RAID is an independent filesystem so I can snapshot it regularly and go back in time if I have to. The server pulls in data from my servers via rsync and that&#39;s how I do backups. It&#39;s less automated than I want it to be right now and I still have to configure it to server as a TimeMachine destination for my laptop. But this is already a pretty good solution for me.&lt;/p&gt;&#xA;&lt;h3 id=&#34;where-i-still-use-the-cloud&#34;&gt;Where I still use the cloud&lt;/h3&gt;&#xA;&lt;p&gt;I&#39;ve extensively talked about how I moved my data into self hosted applications and what I use for those use cases. However that doesn&#39;t mean that I&#39;m completely free of cloud based applications. Obviously there are a variety of applications that don&#39;t support this yet or where it&#39;s not even something that would work without changing the product a lot. That means I still use Dropbox to sync &lt;a href=&#34;http://www.papersapp.com&#34;&gt;Papers&lt;/a&gt; or automatically pull in pictures from Instagram. Since Google Reader died I switched to &lt;a href=&#34;https://feedbin.me&#34;&gt;Feedbin&lt;/a&gt; and have no intention to stop using it, I have my Kindle books at Amazon, my music in the iTunes Cloud, I use a variety of infrastructure software as a service to &lt;a href=&#34;http://www.unwiredcouch.com/2012/09/15/getting-started-with-monitoring.html&#34;&gt;monitor my servers&lt;/a&gt; and I run my &lt;a href=&#34;https://github.com/roidrage/s3itch&#34;&gt;public image sharing&lt;/a&gt; and &lt;a href=&#34;https://github.com/mrtazz/katana&#34;&gt;custom URL shortener&lt;/a&gt; on S3 and Heroku and this blog on GitHub Pages. The difference for me is, that most of this data I don&#39;t necessarily regard as private as the ones I pulled into my own hosting. I will probably experiment with how I can do some of this on my own in the future, but it is less important to me right now.&lt;/p&gt;&#xA;&lt;h3 id=&#34;why-are-you-telling-me-all-this&#34;&gt;Why are you telling me all this?&lt;/h3&gt;&#xA;&lt;p&gt;As I said in the first section, this is not considered a manual of how to host your own data. While I try to keep my &lt;a href=&#34;https://github.com/mrtazz/cookbooks&#34;&gt;Chef cookbooks&lt;/a&gt; for this stuff up to date, they are very custom tailored and probably not of great use for everybody. If you want to get started and host your own data, I highly recommend checking out &lt;a href=&#34;https://github.com/al3x/sovereign&#34;&gt;Alex Payne&#39;s Sovereign Project&lt;/a&gt;. It&#39;s an Ansible project which installs a lot of the things I&#39;ve been talking about here and is definitely much easier to get started with. I do hope though I was able to share some ideas and make hosting your own data sound a little less scary.&lt;/p&gt;&#xA;&lt;p&gt;I also realize that even with an easy to get started guide and a collection of Chef recipes this is not something every person can run and you need some understanding of (and tolerance for) running your own services. There has been some work going on for some time to make it easier to host your own services and even have decentralized applications. The newest one I am aware of is called &lt;a href=&#34;http://decentralize.it&#34;&gt;Grand Decentral Station&lt;/a&gt; and looks very promising. I would love to see some of these ideas flourish and be pushed forward. And maybe have a future in which we can not only pay people to run services for us, but also to develop services we can run ourselves as easy as it is to set up a TV or a Roomba today.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2013/10/30/uncloud-your-life.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;There has been a lot of talk lately about privacy in the cloud and owning your own data. I&#39;m not </summary>
  </entry>
  <entry>
    <title>Infrastructure upgrades with Chef</title>
    <updated>2013-08-02T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2013,2013-08-02:/08/02/infrastructure-upgrades-with-chef.html</id>
    <content type="html">&lt;p&gt;I wrote about how we roll out infrastructure upgrades with Chef on Etsy&#39;s &lt;a href=&#34;https://codeascraft.com&#34;&gt;engineering blog&lt;/a&gt;. You can find the post &lt;a href=&#34;https://codeascraft.com/2013/08/02/infrastructure-upgrades-with-chef/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2013/08/02/infrastructure-upgrades-with-chef.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I wrote about how we roll out infrastructure upgrades with Chef on Etsy&#39;s &lt;a href=&#34;https://codeas</summary>
  </entry>
  <entry>
    <title>IRC notifications with logstash</title>
    <updated>2012-11-03T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2012,2012-11-03:/11/03/irc-notifications-with-logstash.html</id>
    <content type="html">&lt;p&gt;I have spent some time in the last weeks to learn more about &lt;a href=&#34;http://logstash.net/&#34;&gt;logstash&lt;/a&gt; and used the kind of bad state of my IRC notifications as the fun side project to get into it. I now have a pretty useful (well for me) setup which I thought I&#39;d share.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-irc-setup&#34;&gt;The IRC setup&lt;/h3&gt;&#xA;&lt;p&gt;My basic setup revolves around using the &lt;a href=&#34;http://znc.in&#34;&gt;ZNC&lt;/a&gt; bouncer which keeps me always connected. I still use &lt;a href=&#34;http://www.weechat.org/&#34;&gt;weechat&lt;/a&gt; in a remote tmux session most of the time, but like to have the option to switch clients without losing my connection or backlog. I also use &lt;a href=&#34;http://growl.info/&#34;&gt;Growl&lt;/a&gt; pretty heavily in combination with OSX notification center to alert me of special keywords or all messages in certain channels. Past solutions included running the IRC client locally with a growl plugin or remote tail-ing a notification logfile. Those solutions were close to what I wanted but tied too much to the client, when I really wanted to have notifications directly from my bouncer. And since znc has a &lt;a href=&#34;http://wiki.znc.in/Log&#34;&gt;module to log&lt;/a&gt; all messages to various logfiles, I decided to get my notifications from there.&lt;/p&gt;&#xA;&lt;h3 id=&#34;enter-logstash&#34;&gt;Enter logstash&lt;/h3&gt;&#xA;&lt;p&gt;I had read about logstash before and decided to give it a try for this. I won&#39;t go into detail about installing and running it here, but check out the &lt;a href=&#34;http://logstash.net/docs/1.1.4/tutorials/getting-started-simple&#34;&gt;getting started&lt;/a&gt; for a good introduction.&lt;/p&gt;&#xA;&lt;p&gt;For the first important step, we need logstash to listen to changes in the bouncer&#39;s logfiles. This is pretty easy and can be accomplished with the following logstash configuration bits:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode javascript&#34;&gt;&lt;code class=&#34;sourceCode javascript&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;input &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34;&gt;&lt;/a&gt;  file &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34;&gt;&lt;/a&gt;    path &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;/home/username/.znc/users/zncuser/moddata/log/*&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-4&#34;&gt;&lt;a href=&#34;#cb1-4&#34;&gt;&lt;/a&gt;    type &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;znclog&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-5&#34;&gt;&lt;a href=&#34;#cb1-5&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-6&#34;&gt;&lt;a href=&#34;#cb1-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Per default the log module puts all log files under &lt;code&gt;users/youruser/moddata/log/&lt;/code&gt; and creates a logfile per day which is named after the channel name and date. The logstash input just reads all files that are in there and adds a type to the captured logs to be able to better identify them in subsequent filters. The pattern is not really ideal since older logfiles are not interesting for notifications but are also kept open. So at the moment I work around that by moving my logfiles to a backup partition every night, but there might be a better way to do it.&lt;/p&gt;&#xA;&lt;p&gt;The next step is to remove lines which I&#39;m never interested in for notifications, like my own messages and JOIN/QUIT messages for example. For this the logstash &lt;code&gt;grep&lt;/code&gt; filter definitions are very useful:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode javascript&#34;&gt;&lt;code class=&#34;sourceCode javascript&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34;&gt;&lt;/a&gt;filter &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34;&gt;&lt;/a&gt;  grep &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34;&gt;&lt;/a&gt;    type &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;znclog&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34;&gt;&lt;/a&gt;    match &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;@message&amp;quot;&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;\[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;[0-9:]{8}&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;\]&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;(.+?)&amp;lt;USERNAME&amp;gt;&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34;&gt;&lt;/a&gt;    negate &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;true&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-6&#34;&gt;&lt;a href=&#34;#cb2-6&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-7&#34;&gt;&lt;a href=&#34;#cb2-7&#34;&gt;&lt;/a&gt;  grep &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-8&#34;&gt;&lt;a href=&#34;#cb2-8&#34;&gt;&lt;/a&gt;    type &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;znclog&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-9&#34;&gt;&lt;a href=&#34;#cb2-9&#34;&gt;&lt;/a&gt;    match &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;@message&amp;quot;&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;\*\*\*&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; (Quits|Joins|Parts|.+ sets mode: |.+ is now known as)&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-10&#34;&gt;&lt;a href=&#34;#cb2-10&#34;&gt;&lt;/a&gt;    negate &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;true&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-11&#34;&gt;&lt;a href=&#34;#cb2-11&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-12&#34;&gt;&lt;a href=&#34;#cb2-12&#34;&gt;&lt;/a&gt;&lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;The grep filter is also very useful for another criterion on which I want notifications, namely for all of my private messages. Since all channel names per IRC convention have a &lt;code&gt;#&lt;/code&gt; in the name, we can just assume that logfiles without that sign are for private messages. It is important to set &lt;code&gt;drop =&amp;gt; false&lt;/code&gt; here since we don&#39;t want grep to drop the log line (which is default behaviour).&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode javascript&#34;&gt;&lt;code class=&#34;sourceCode javascript&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34;&gt;&lt;/a&gt;grep &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34;&gt;&lt;/a&gt;  type &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;znclog&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34;&gt;&lt;/a&gt;  match &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;@source&amp;quot;&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;#&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34;&gt;&lt;/a&gt;  add_tag &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;pmnotification&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34;&gt;&lt;/a&gt;  negate &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;true&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-6&#34;&gt;&lt;a href=&#34;#cb3-6&#34;&gt;&lt;/a&gt;  drop &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;false&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-7&#34;&gt;&lt;a href=&#34;#cb3-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This also needs to be added to the filter section and tags all messages coming from logfiles without a &lt;code&gt;#&lt;/code&gt; in the name with &lt;code&gt;&#34;pmnotifcation&#34;&lt;/code&gt;. Now let&#39;s go to the actual parsing of log events. Since there are going to be some repeated patterns and I wanted to have an easy way to add new ones, I have a &#39;pattern library file&#39; which is included in the configuration.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode javascript&#34;&gt;&lt;code class=&#34;sourceCode javascript&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;at&#34;&gt;NOTIFYME&lt;/span&gt; (pizza&lt;span class=&#34;op&#34;&gt;|&lt;/span&gt;cupcakes&lt;span class=&#34;op&#34;&gt;|&lt;/span&gt;fire)&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34;&gt;&lt;/a&gt;IRCNOTIFY &lt;span class=&#34;op&#34;&gt;%{&lt;/span&gt;DATA&lt;span class=&#34;op&#34;&gt;}%{&lt;/span&gt;NOTIFYME&lt;span class=&#34;op&#34;&gt;}%{&lt;/span&gt;GREEDYDATA&lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34;&gt;&lt;/a&gt;IRCTIME [&lt;span class=&#34;dv&#34;&gt;0-9&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;:&lt;/span&gt;]&lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;at&#34;&gt;IRCCHANNELS&lt;/span&gt; (nunagios&lt;span class=&#34;op&#34;&gt;|&lt;/span&gt;chef&lt;span class=&#34;op&#34;&gt;|&lt;/span&gt;food)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;The terms in capital letters can be used as regex placeholders. The interesting ones are &lt;code&gt;NOTIFYME/IRCNOTIFY&lt;/code&gt; which are used as a collection of regexes on which I want to show a notification and &lt;code&gt;IRCCHANNELS&lt;/code&gt; which are basically the channel names for which I want notifications for all messages. In order to get those notifications I set up a set of grok filters.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode javascript&#34;&gt;&lt;code class=&#34;sourceCode javascript&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34;&gt;&lt;/a&gt;grok &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-2&#34;&gt;&lt;a href=&#34;#cb5-2&#34;&gt;&lt;/a&gt;  match &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;@source&amp;quot;&lt;/span&gt;&lt;span class=&#34;op&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;%{IRCCHANNELS}&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-3&#34;&gt;&lt;a href=&#34;#cb5-3&#34;&gt;&lt;/a&gt;  add_tag &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;channelnotification&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-4&#34;&gt;&lt;a href=&#34;#cb5-4&#34;&gt;&lt;/a&gt;  exclude_tags &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;pmnotification&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-5&#34;&gt;&lt;a href=&#34;#cb5-5&#34;&gt;&lt;/a&gt;  patterns_dir &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;/home/username/logstash-patterns&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-6&#34;&gt;&lt;a href=&#34;#cb5-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This grok ruleset grabs all events from the channels based on the &lt;code&gt;IRCCHANNELS&lt;/code&gt; match and tags them with the &lt;code&gt;&#34;channelnotification&#34;&lt;/code&gt; tag. PMs are excluded from that match because they have already matched.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode javascript&#34;&gt;&lt;code class=&#34;sourceCode javascript&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34;&gt;&lt;/a&gt;grok &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-2&#34;&gt;&lt;a href=&#34;#cb6-2&#34;&gt;&lt;/a&gt;  pattern &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;\[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;%{IRCTIME:irctime}&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;\]&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;(.+?)&amp;lt;%{DATA:ircsender}&amp;gt;%{GREEDYDATA:ircmessage}&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-3&#34;&gt;&lt;a href=&#34;#cb6-3&#34;&gt;&lt;/a&gt;  tags &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;channelnotification&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-4&#34;&gt;&lt;a href=&#34;#cb6-4&#34;&gt;&lt;/a&gt;  patterns_dir &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;/home/username/logstash-patterns&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-5&#34;&gt;&lt;a href=&#34;#cb6-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-6&#34;&gt;&lt;a href=&#34;#cb6-6&#34;&gt;&lt;/a&gt;grok &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-7&#34;&gt;&lt;a href=&#34;#cb6-7&#34;&gt;&lt;/a&gt;  pattern &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;\[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;%{IRCTIME:irctime}&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;\]&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;(.+?)&amp;lt;%{DATA:ircsender}&amp;gt;%{GREEDYDATA:ircmessage}&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-8&#34;&gt;&lt;a href=&#34;#cb6-8&#34;&gt;&lt;/a&gt;  tags &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;pmnotification&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-9&#34;&gt;&lt;a href=&#34;#cb6-9&#34;&gt;&lt;/a&gt;  patterns_dir &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;/home/username/logstash-patterns&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-10&#34;&gt;&lt;a href=&#34;#cb6-10&#34;&gt;&lt;/a&gt;&lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;These rulesets extract the timestamp, sender and message data for the notifications into separate fields so they are easily accessible later on. I have the same ruleset for channel notifications and private messages, because I didn&#39;t find a way to match any tag (the &lt;code&gt;tags&lt;/code&gt; setting requires an event to match all given tags) so I couldn&#39;t combine them into one rule. Though this seems like something that should be fixable.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode javascript&#34;&gt;&lt;code class=&#34;sourceCode javascript&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34;&gt;&lt;/a&gt;grok &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-2&#34;&gt;&lt;a href=&#34;#cb7-2&#34;&gt;&lt;/a&gt;  pattern &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;\[&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;%{IRCTIME:irctime}&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;\]&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;(.+?)&amp;lt;%{DATA:ircsender}&amp;gt;%{IRCNOTIFY:ircmessage}&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-3&#34;&gt;&lt;a href=&#34;#cb7-3&#34;&gt;&lt;/a&gt;  add_tag &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;notification&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-4&#34;&gt;&lt;a href=&#34;#cb7-4&#34;&gt;&lt;/a&gt;  exclude_tags &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;pmnotification&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-5&#34;&gt;&lt;a href=&#34;#cb7-5&#34;&gt;&lt;/a&gt;  patterns_dir &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;/home/username/logstash-patterns&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-6&#34;&gt;&lt;a href=&#34;#cb7-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;And finally the last pattern ruleset matches the regexes that are defined for all events and parses them into the fields mentioned before. Notice that all rulesets include a &lt;code&gt;patterns_dir&lt;/code&gt; section which points to the folder with the regex defintions file described above.&lt;/p&gt;&#xA;&lt;p&gt;The last part of the logstash ruleset is defining an output for the notifications. For a while I just appended them to a logfile and tail-ed that from my laptop over ssh. This worked ok, but I had problems with duplicate notifications when restarting the polling script and wasn&#39;t really happy with this solution. And since I already had Redis running on that host, I thought I&#39;d give that a try.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb8&#34;&gt;&lt;pre class=&#34;sourceCode javascript&#34;&gt;&lt;code class=&#34;sourceCode javascript&#34;&gt;&lt;span id=&#34;cb8-1&#34;&gt;&lt;a href=&#34;#cb8-1&#34;&gt;&lt;/a&gt;output &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-2&#34;&gt;&lt;a href=&#34;#cb8-2&#34;&gt;&lt;/a&gt;  redis &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-3&#34;&gt;&lt;a href=&#34;#cb8-3&#34;&gt;&lt;/a&gt;    host &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-4&#34;&gt;&lt;a href=&#34;#cb8-4&#34;&gt;&lt;/a&gt;    data_type &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;list&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-5&#34;&gt;&lt;a href=&#34;#cb8-5&#34;&gt;&lt;/a&gt;    key &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;notifications&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-6&#34;&gt;&lt;a href=&#34;#cb8-6&#34;&gt;&lt;/a&gt;    tags &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;pmnotification&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-7&#34;&gt;&lt;a href=&#34;#cb8-7&#34;&gt;&lt;/a&gt;    password &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;secret&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-8&#34;&gt;&lt;a href=&#34;#cb8-8&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-9&#34;&gt;&lt;a href=&#34;#cb8-9&#34;&gt;&lt;/a&gt;  redis &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-10&#34;&gt;&lt;a href=&#34;#cb8-10&#34;&gt;&lt;/a&gt;    host &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-11&#34;&gt;&lt;a href=&#34;#cb8-11&#34;&gt;&lt;/a&gt;    data_type &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;list&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-12&#34;&gt;&lt;a href=&#34;#cb8-12&#34;&gt;&lt;/a&gt;    key &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;notifications&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-13&#34;&gt;&lt;a href=&#34;#cb8-13&#34;&gt;&lt;/a&gt;    tags &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;channelnotification&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-14&#34;&gt;&lt;a href=&#34;#cb8-14&#34;&gt;&lt;/a&gt;    password &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;secret&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-15&#34;&gt;&lt;a href=&#34;#cb8-15&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-16&#34;&gt;&lt;a href=&#34;#cb8-16&#34;&gt;&lt;/a&gt;  redis &lt;span class=&#34;op&#34;&gt;{&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-17&#34;&gt;&lt;a href=&#34;#cb8-17&#34;&gt;&lt;/a&gt;    host &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-18&#34;&gt;&lt;a href=&#34;#cb8-18&#34;&gt;&lt;/a&gt;    data_type &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;list&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-19&#34;&gt;&lt;a href=&#34;#cb8-19&#34;&gt;&lt;/a&gt;    key &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;notifications&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-20&#34;&gt;&lt;a href=&#34;#cb8-20&#34;&gt;&lt;/a&gt;    tags &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; [&lt;span class=&#34;st&#34;&gt;&amp;quot;notification&amp;quot;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-21&#34;&gt;&lt;a href=&#34;#cb8-21&#34;&gt;&lt;/a&gt;    password &lt;span class=&#34;kw&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;#39;secret&amp;#39;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-22&#34;&gt;&lt;a href=&#34;#cb8-22&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-23&#34;&gt;&lt;a href=&#34;#cb8-23&#34;&gt;&lt;/a&gt;&lt;span class=&#34;op&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;The output config basically just says the for every type of notification log event, append it to a Redis list with the name &lt;code&gt;&#39;notifications&#39;&lt;/code&gt; on the instance running on localhost.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-client-side&#34;&gt;The client side&lt;/h3&gt;&#xA;&lt;p&gt;The last part now is actually getting the notifications into growl on the OSX side of things. For this I have Growl setup to forward everything to notification center and run the following script on my Mac:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb9&#34;&gt;&lt;pre class=&#34;sourceCode python&#34;&gt;&lt;code class=&#34;sourceCode python&#34;&gt;&lt;span id=&#34;cb9-1&#34;&gt;&lt;a href=&#34;#cb9-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;im&#34;&gt;import&lt;/span&gt; sys&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-2&#34;&gt;&lt;a href=&#34;#cb9-2&#34;&gt;&lt;/a&gt;&lt;span class=&#34;im&#34;&gt;import&lt;/span&gt; gntp&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-3&#34;&gt;&lt;a href=&#34;#cb9-3&#34;&gt;&lt;/a&gt;&lt;span class=&#34;im&#34;&gt;import&lt;/span&gt; json&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-4&#34;&gt;&lt;a href=&#34;#cb9-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;im&#34;&gt;import&lt;/span&gt; redis&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-5&#34;&gt;&lt;a href=&#34;#cb9-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;im&#34;&gt;import&lt;/span&gt; gntp.notifier&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-6&#34;&gt;&lt;a href=&#34;#cb9-6&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-7&#34;&gt;&lt;a href=&#34;#cb9-7&#34;&gt;&lt;/a&gt;r &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; redis.StrictRedis(host&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;#39;ircserver&amp;#39;&lt;/span&gt;,&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-8&#34;&gt;&lt;a href=&#34;#cb9-8&#34;&gt;&lt;/a&gt;                      port&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;6379&lt;/span&gt;, db&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;,&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-9&#34;&gt;&lt;a href=&#34;#cb9-9&#34;&gt;&lt;/a&gt;                      password&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;secret&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-10&#34;&gt;&lt;a href=&#34;#cb9-10&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-11&#34;&gt;&lt;a href=&#34;#cb9-11&#34;&gt;&lt;/a&gt;app &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;irc-growl&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-12&#34;&gt;&lt;a href=&#34;#cb9-12&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-13&#34;&gt;&lt;a href=&#34;#cb9-13&#34;&gt;&lt;/a&gt;&lt;span class=&#34;cf&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;:&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-14&#34;&gt;&lt;a href=&#34;#cb9-14&#34;&gt;&lt;/a&gt;    key, logline &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; r.blpop(&lt;span class=&#34;st&#34;&gt;&amp;quot;notifications&amp;quot;&lt;/span&gt;)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-15&#34;&gt;&lt;a href=&#34;#cb9-15&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;try&lt;/span&gt;:&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-16&#34;&gt;&lt;a href=&#34;#cb9-16&#34;&gt;&lt;/a&gt;        log &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; json.loads(logline)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-17&#34;&gt;&lt;a href=&#34;#cb9-17&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;pp&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;im&#34;&gt;as&lt;/span&gt; e:&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-18&#34;&gt;&lt;a href=&#34;#cb9-18&#34;&gt;&lt;/a&gt;        title &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;Failure loading logline: &amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;bu&#34;&gt;str&lt;/span&gt;(logline)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-19&#34;&gt;&lt;a href=&#34;#cb9-19&#34;&gt;&lt;/a&gt;        message &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;error(&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;{0}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;)&amp;quot;&lt;/span&gt;.&lt;span class=&#34;bu&#34;&gt;format&lt;/span&gt;(e)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-20&#34;&gt;&lt;a href=&#34;#cb9-20&#34;&gt;&lt;/a&gt;        gntp.notifier.mini(message, applicationName&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;app, title&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;title)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-21&#34;&gt;&lt;a href=&#34;#cb9-21&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;cf&#34;&gt;continue&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-22&#34;&gt;&lt;a href=&#34;#cb9-22&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-23&#34;&gt;&lt;a href=&#34;#cb9-23&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;try&lt;/span&gt;:&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-24&#34;&gt;&lt;a href=&#34;#cb9-24&#34;&gt;&lt;/a&gt;        channel &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;-&amp;quot;&lt;/span&gt;.join(log[&lt;span class=&#34;st&#34;&gt;&amp;quot;@source&amp;quot;&lt;/span&gt;].split(&lt;span class=&#34;st&#34;&gt;&amp;quot;/&amp;quot;&lt;/span&gt;)[&lt;span class=&#34;op&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;].split(&lt;span class=&#34;st&#34;&gt;&amp;quot;_&amp;quot;&lt;/span&gt;)[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;:&lt;span class=&#34;op&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-25&#34;&gt;&lt;a href=&#34;#cb9-25&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;pp&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;im&#34;&gt;as&lt;/span&gt; e:&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-26&#34;&gt;&lt;a href=&#34;#cb9-26&#34;&gt;&lt;/a&gt;        title &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;Failure parsing channel name in: &amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;bu&#34;&gt;str&lt;/span&gt;(log[&lt;span class=&#34;st&#34;&gt;&amp;quot;@source&amp;quot;&lt;/span&gt;])&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-27&#34;&gt;&lt;a href=&#34;#cb9-27&#34;&gt;&lt;/a&gt;        message &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;error(&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;{0}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;)&amp;quot;&lt;/span&gt;.&lt;span class=&#34;bu&#34;&gt;format&lt;/span&gt;(e)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-28&#34;&gt;&lt;a href=&#34;#cb9-28&#34;&gt;&lt;/a&gt;        gntp.notifier.mini(message, applicationName&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;app, title&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;title)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-29&#34;&gt;&lt;a href=&#34;#cb9-29&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;cf&#34;&gt;continue&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-30&#34;&gt;&lt;a href=&#34;#cb9-30&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-31&#34;&gt;&lt;a href=&#34;#cb9-31&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;try&lt;/span&gt;:&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-32&#34;&gt;&lt;a href=&#34;#cb9-32&#34;&gt;&lt;/a&gt;        title &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; (&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;%s&lt;/span&gt;&lt;span class=&#34;st&#34;&gt; in &lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;%s&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;%&lt;/span&gt; (log[&lt;span class=&#34;st&#34;&gt;&amp;quot;@fields&amp;quot;&lt;/span&gt;][&lt;span class=&#34;st&#34;&gt;&amp;quot;ircsender&amp;quot;&lt;/span&gt;][&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;],&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-33&#34;&gt;&lt;a href=&#34;#cb9-33&#34;&gt;&lt;/a&gt;                  channel.encode(&lt;span class=&#34;st&#34;&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;)))&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-34&#34;&gt;&lt;a href=&#34;#cb9-34&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;pp&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;im&#34;&gt;as&lt;/span&gt; e:&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-35&#34;&gt;&lt;a href=&#34;#cb9-35&#34;&gt;&lt;/a&gt;        title &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;Failure parsing ircsender in: &amp;quot;&lt;/span&gt; &lt;span class=&#34;op&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;bu&#34;&gt;str&lt;/span&gt;(log)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-36&#34;&gt;&lt;a href=&#34;#cb9-36&#34;&gt;&lt;/a&gt;        message &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;error(&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;{0}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;)&amp;quot;&lt;/span&gt;.&lt;span class=&#34;bu&#34;&gt;format&lt;/span&gt;(e)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-37&#34;&gt;&lt;a href=&#34;#cb9-37&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;bu&#34;&gt;print&lt;/span&gt; title&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-38&#34;&gt;&lt;a href=&#34;#cb9-38&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;bu&#34;&gt;print&lt;/span&gt; message&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-39&#34;&gt;&lt;a href=&#34;#cb9-39&#34;&gt;&lt;/a&gt;        gntp.notifier.mini(message, applicationName&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;app, title&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;title)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-40&#34;&gt;&lt;a href=&#34;#cb9-40&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;cf&#34;&gt;continue&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-41&#34;&gt;&lt;a href=&#34;#cb9-41&#34;&gt;&lt;/a&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-42&#34;&gt;&lt;a href=&#34;#cb9-42&#34;&gt;&lt;/a&gt;    message &lt;span class=&#34;op&#34;&gt;=&lt;/span&gt; (log[&lt;span class=&#34;st&#34;&gt;&amp;quot;@fields&amp;quot;&lt;/span&gt;][&lt;span class=&#34;st&#34;&gt;&amp;quot;ircmessage&amp;quot;&lt;/span&gt;][&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;]).encode(&lt;span class=&#34;st&#34;&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;)&lt;/span&gt;&#xA;&lt;span id=&#34;cb9-43&#34;&gt;&lt;a href=&#34;#cb9-43&#34;&gt;&lt;/a&gt;    gntp.notifier.mini(message, applicationName&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;app, title&lt;span class=&#34;op&#34;&gt;=&lt;/span&gt;title)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This uses the python gntp library to talk to Growl and the redis client to talk to Redis. Specifically for the Redis connection I use &lt;code&gt;blpop&lt;/code&gt;, which pops an element (in our case a notification) from the list and if there is none waits for the next one to come in. For every notification it parses out the timestamp, channel, sender and message from the fields I set in the logstash grok rules, formats it nicely, sends it to growl and then gets the next one or waits for new notifications to come in.&lt;/p&gt;&#xA;&lt;h2 id=&#34;verdict&#34;&gt;Verdict&lt;/h2&gt;&#xA;&lt;p&gt;There are still some improvements I want to make. Mostly around moving the old log files or only reading the newest one. And improving the script so it survives network disconnects and possibly run it under launchd. Also if I&#39;m not running the script to pull notifications, they are piling up in Redis at the moment. So next time I connect, I get an abundance of new notifications. Notification center batches them nicely to not litter the whole screen and only the last 20 are in the sidebar. So it&#39;s not really a problem, but I thought about running a cron to prune the list to a maximum of 20 notifications or so.&lt;/p&gt;&#xA;&lt;p&gt;I now have a setup where I get my notifications directly from the bouncer logs and can display them on any (OSX) host which has the script set up. It should also be fairly simple to adapt this to other notification display systems. The setup is no longer bound to which IRC client I use or whether or not I constantly have it running on a server. Plus the alerting keywords and channels are easily extended because I only have to add patterns to the library file and not touch the config itself.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2012/11/03/irc-notifications-with-logstash.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I have spent some time in the last weeks to learn more about &lt;a href=&#34;http://logstash.net/&#34;&gt;logst</summary>
  </entry>
  <entry>
    <title>Getting started with monitoring on the cheap and easy</title>
    <updated>2012-09-15T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2012,2012-09-15:/09/15/getting-started-with-monitoring.html</id>
    <content type="html">&lt;p&gt;This post started out as a writeup of tools and services I use to monitor my small (currently 3) set of personal servers. However thinking about it, it made more sense to me to structure it as a small guide on how to get started with monitoring without having to invest too much time, effort and money. Since I don&#39;t use that at the moment, I won&#39;t cover instrumentation and monitoring of application metrics but go more into general service availabilty and machine level metrics. The prices I mention are (to my best knowledge) up to date for the current time, but are of course subject to change.&lt;/p&gt;&#xA;&lt;h3 id=&#34;my-setup&#34;&gt;My setup&lt;/h3&gt;&#xA;&lt;p&gt;I have a small set of servers which I&#39;m using for basic services. These include mail server, IMAP, backup MX, &lt;a href=&#34;http://wiki.znc.in/ZNC&#34;&gt;IRC bouncer&lt;/a&gt; and general remote shell for running &lt;a href=&#34;http://www.mutt.org/&#34;&gt;mutt&lt;/a&gt;, &lt;a href=&#34;http://www.weechat.org/&#34;&gt;weechat&lt;/a&gt;, &lt;a href=&#34;http://www.newsbeuter.org/&#34;&gt;newsbeuter&lt;/a&gt; and other terminal based applications. I recently got around to more or less properly create &lt;a href=&#34;https://github.com/mrtazz/cookbooks&#34;&gt;cookbooks&lt;/a&gt; for this as I am running &lt;a href=&#34;http://opscode.com&#34;&gt;chef&lt;/a&gt; for configuration management. This also prompted me to finally set up monitoring and alerting for the services I care about.&lt;/p&gt;&#xA;&lt;h3 id=&#34;external-service-monitoring&#34;&gt;External service monitoring&lt;/h3&gt;&#xA;&lt;p&gt;Servers are not very useful when their services are not accessible from the outside world. So you want to monitor this from an external source which usually tries to establish a connection to specified TCP ports. The general first service to use is &lt;a href=&#34;http://pingdom.com&#34;&gt;pingdom&lt;/a&gt;. They provide a great service with great statistics. However since I want to monitor more than the free plan offers (and possibly more than the cheapest paid plan also), I was looking into an alternative. Since I already have an account at &lt;a href=&#34;http://zerigo.com&#34;&gt;zerigo&lt;/a&gt; for some DNS services, I decided to give their &lt;a href=&#34;http://zerigo.com/watchdog&#34;&gt;Watchdog service&lt;/a&gt; a try. It&#39;s $15 per 3 months and allows 50 service checks for 10 hosts with checking time down to every 5 minutes. This is more than enough for my needs and comes down to $5 a month. The only drawback is that they only provide email notifications (which can be somewhat mitigated with &lt;a href=&#34;http://ifttt.com&#34;&gt;ifttt&lt;/a&gt; or the mail to text gateway of your mobile provider) to one user and a not really great statistics overview. Otherwise it works pretty great.&lt;/p&gt;&#xA;&lt;h3 id=&#34;process-monitoring&#34;&gt;Process monitoring&lt;/h3&gt;&#xA;&lt;p&gt;The next step is to monitor the processes which are actually providing those services. For this I&#39;m running a &lt;a href=&#34;https://github.com/sensu&#34;&gt;Sensu&lt;/a&gt; instance on &lt;a href=&#34;http://heroku.com&#34;&gt;Heroku&lt;/a&gt; in the setup I &lt;a href=&#34;http://unwiredcouch.com/2012/07/31/deploy-sensu-heroku.html&#34;&gt;described before&lt;/a&gt;. Sensu is an awesome monitoring framework which provides a lot of flexibility, so it&#39;s definitely worth checking out. Since it runs on two small Heroku instances I can host the server and API for free which works pretty well. As basic checks I test for running sendmail, cron and dovecot processes. If the checks fail the given threshold, an alert is pushed to an IRC channel on my &lt;a href=&#34;http://grove.io&#34;&gt;grove.io&lt;/a&gt; organization. Admittingly this is a little bit overkill since the basic plans for grove.io start at $10, but I like to play and experiment with chat based interfaces to infrastructure automation and monitoring. An alternative would be to use &lt;a href=&#34;http://campfirenow.com&#34;&gt;Campfire&lt;/a&gt; which is free for a small amount of users. I am also playing with the idea of having a &lt;a href=&#34;http://boxcar.io&#34;&gt;Boxcar&lt;/a&gt; handler either for Sensu itself or alerting to Boxcar from IRC. Boxcar is a pretty sweet service which handles push notifications to mobile phones and I&#39;m already using it for notifications from my IRC bouncer and &lt;a href=&#34;http://ifttt.com&#34;&gt;ifttt.com&lt;/a&gt;. And since I&#39;m also running an instance of &lt;a href=&#34;http://github.com/github/hubot&#34;&gt;Hubot&lt;/a&gt; (also on a free Heroku instance) it should be rather trivial to have the bot listen for patterns and send Boxcar notifications upon match.&lt;/p&gt;&#xA;&lt;h3 id=&#34;log-processing&#34;&gt;Log processing&lt;/h3&gt;&#xA;&lt;p&gt;Since I don&#39;t want to log into several servers to quickly check different logfiles, I&#39;m sending all of my log data to &lt;a href=&#34;http://papertrailapp.com&#34;&gt;Papertrail&lt;/a&gt;. They provide an easy endpoint to send log lines from various systems such as syslog, rsyslog or directly from an application with an rsyslog handler. Their basic free plan allows for 100MB of log data per month with a searchable archive of 1 week. This amount should be enough for a small set of systems with average log data. After that you get 1GB of log lines in the first stage of paid plans for $7, which is still a decent trade. The big advantage is that I can now log into a web interface and see specific log information (for example about chef runs) across all of my servers.&lt;/p&gt;&#xA;&lt;h3 id=&#34;machine-level-metrics&#34;&gt;Machine level metrics&lt;/h3&gt;&#xA;&lt;p&gt;Additionally I also gather machine level metrics for all of my servers. These include basic information about CPU and memory usage, disk space and uptime. All of these metrics are gathered by &lt;a href=&#34;http://collectd.org&#34;&gt;collectd&lt;/a&gt; and its various plugins and are sent to &lt;a href=&#34;http://metrics.librato.com&#34;&gt;Librato Metrics&lt;/a&gt; for graphing. This is a lot easier and less hassle than managing your own &lt;a href=&#34;http://graphite.wikidot.com/&#34;&gt;Graphite&lt;/a&gt; instance. And you only pay for the metrics you actually send. The data I currently send there are basic metrics from 2 servers and the number of Sensu check occurrences and it adds up to something around $5 a month.&lt;/p&gt;&#xA;&lt;h3 id=&#34;verdict&#34;&gt;Verdict&lt;/h3&gt;&#xA;&lt;p&gt;This setup gives me (in my opinion) a pretty good monitoring solution for my personal infrastructure. Since I don&#39;t consume a lot of resources for the services I depend on, I can usually use the free or cheapest plan available. With the cheapest options it&#39;s around $10 a month and even adding grove.io and paid Papretrail into the mix only brings you to a bit more than $25 a month. Of course depending heavily on 3rd party services opens a whole new discussion about &lt;a href=&#34;http://whoownsmyavailability.com&#34;&gt;availability&lt;/a&gt; which you should be aware of.&lt;/p&gt;&#xA;&lt;p&gt;For configuration examples for the services mentioned above, you can check out my &lt;a href=&#34;https://github.com/mrtazz/cookbooks&#34;&gt;chef cookbooks&lt;/a&gt;. They are mostly run on FreeBSD but should be somewhat easy to adapt to a different environment.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2012/09/15/getting-started-with-monitoring.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This post started out as a writeup of tools and services I use to monitor my small (currently 3) </summary>
  </entry>
  <entry>
    <title>Deploying Sensu monitoring on Heroku</title>
    <updated>2012-07-31T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2012,2012-07-31:/07/31/deploy-sensu-heroku.html</id>
    <content type="html">&lt;h3 id=&#34;sensu---trying-to-unsuck-monitoring&#34;&gt;Sensu - trying to unsuck monitoring&lt;/h3&gt;&#xA;&lt;p&gt;Some months ago I wanted to set up monitoring for a handful of servers I use for personal stuff. As a first solution &lt;a href=&#34;http://nagios.org&#34;&gt;Nagios&lt;/a&gt; came to mind. However for several reasons I didn&#39;t want to set it up and configure it. And I really didn&#39;t want to dedicate an existing server to do monitoring or get a new one just for that purpose. Around that time I also read about &lt;a href=&#34;https://github.com/sensu/sensu&#34;&gt;Sensu&lt;/a&gt;, a new approach to monitoring, which is a result of Nagios not being a good fit for the monitoring needs at &lt;a href=&#34;http://www.sonian.com/&#34;&gt;Sonian&lt;/a&gt;. Its technology stack is Ruby, Redis and AMQP. I immediately thought it should be possible to put this on the &lt;a href=&#34;https://devcenter.heroku.com/articles/cedar/&#34;&gt;Heroku Cedar stack&lt;/a&gt; and run it on an instance there, which would make a nice solution for monitoring a small number of systems. So I hacked away and with a lot of help (and patience) from &lt;a href=&#34;https://twitter.com/portertech&#34;&gt;Sean Porter&lt;/a&gt;, the adaptions to make the server and API part of Sensu deployable on Heroku are in the new &lt;a href=&#34;https://github.com/sensu/sensu/tree/v0.9.6&#34;&gt;0.9.6 release&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;setting-up-the-sensu-repository&#34;&gt;Setting up the Sensu repository&lt;/h3&gt;&#xA;&lt;p&gt;In order to get started and configure your Sensu instance, clone the &lt;a href=&#34;https://github.com/mrtazz/sensu-heroku-app&#34;&gt;example repository&lt;/a&gt; from Github.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; clone https://github.com/mrtazz/sensu-heroku-example&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;The example includes a basic folder layout for running a server or API instance on Heroku. All configuration files can be dropped in the &lt;code&gt;config/&lt;/code&gt; folder. They will be picked up by the process when Sensu starts. The example repo also includes a basic handler (&lt;code&gt;bin/showme.rb&lt;/code&gt;), which prints event data to STDOUT. There are a lot more handlers in the Sensu &lt;a href=&#34;https://github.com/sensu/sensu-community-plugins&#34;&gt;community plugins&lt;/a&gt; repository on Github. Since handlers are just ruby scripts, you can download the handlers you want and also put it in the &lt;code&gt;bin/&lt;/code&gt; directory. Don&#39;t forget to add the correct configuration file for the handler in the &lt;code&gt;config/&lt;/code&gt; directory also. A great overview how to configure Sensu can be found on Joe Miller&#39;s &lt;a href=&#34;http://joemiller.me&#34;&gt;blog&lt;/a&gt; and there is also an official &lt;a href=&#34;https://github.com/sensu/sensu/wiki/Install-Guide&#34;&gt;install guide&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;deployment&#34;&gt;Deployment&lt;/h3&gt;&#xA;&lt;p&gt;In order to deploy Sensu to Heroku, you need to create two apps. One will be the Sensu API instance and the other one the Sensu server. It doesn&#39;t really matter, which one you start with. The important thing is, that you only need to add the RabbitMQ and Redis plugins once and can then reuse the settings on the second instance.&lt;/p&gt;&#xA;&lt;p&gt;So create the first instance on the cedar stack from within the example repo and add the plugins:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;heroku&lt;/span&gt; create --stack cedar awesome-sensu-server&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;heroku&lt;/span&gt; plugins:install redistogo&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;heroku&lt;/span&gt; plugins:install rabbitmq&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;heroku&lt;/span&gt; config:add API_PORT=80&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;You have to add the &lt;code&gt;API_PORT&lt;/code&gt; environment variable to the server instance, since otherwise it will assume it&#39;s running the API itself and assign the instance locale port from the &lt;code&gt;PORT&lt;/code&gt; environment variable to use as the API port. After that is done, push the code to Heroku and scale up a worker process:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; push heroku master&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;heroku&lt;/span&gt; ps:scale app=1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;For the API instance create a new branch in the repo or clone the example repo into a new location. Then initialize the API:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;heroku&lt;/span&gt; create --stack cedar awesome-sensu-api&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;heroku&lt;/span&gt; config:add REDISTOGO_URL=&lt;span class=&#34;st&#34;&gt;&amp;quot;value from server instance&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;heroku&lt;/span&gt; config:add RABBITMQ_URL=&lt;span class=&#34;st&#34;&gt;&amp;quot;value from server instance&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Now change the Procfile to start up the API instead of the Sensu server like this:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;app&lt;/span&gt;: sensu-api -v -c config/config.json -d config/&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Commit the changes and push it to the Heroku app:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; push heroku-api master&lt;/span&gt;&#xA;&lt;span id=&#34;cb6-2&#34;&gt;&lt;a href=&#34;#cb6-2&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;heroku&lt;/span&gt; ps:scale app=1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Now all you have to do is set up clients and voila, you have Heroku hosted monitoring. If you&#39;re not yet familiar with setting up clients, I highly recommend Joe Miller&#39;s &lt;a href=&#34;http://joemiller.me&#34;&gt;blog&lt;/a&gt; again. He&#39;s a strong contributor to Sensu and has written an abundance of blog posts and tutorials about it. And of course there is also the &lt;a href=&#34;https://github.com/sensu/sensu/wiki/&#34;&gt;sensu wiki&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;further-improvements&#34;&gt;Further improvements&lt;/h3&gt;&#xA;&lt;p&gt;A definite improvement for plugins and handlers would be to be able to also read configuration from environment variables. At the moment the way to go is to add a configuration JSON file in the config folder. This is fine except for the fact that you&#39;d also have API keys commited to the repo.&lt;/p&gt;&#xA;&lt;p&gt;And obviously more bugs will probably come up, once more people run Sensu on Heroku. I&#39;ve been running a low volume instance for a couple of weeks now and it works pretty great so far.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2012/07/31/deploy-sensu-heroku.html" rel="alternate"></link>
    <summary type="html">&lt;h3 id=&#34;sensu---trying-to-unsuck-monitoring&#34;&gt;Sensu - trying to unsuck monitoring&lt;/h3&gt;&#xA;&lt;p&gt;Some months</summary>
  </entry>
  <entry>
    <title>Setting up workstations with Chef (Newbie Edition)</title>
    <updated>2011-08-25T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2011,2011-08-25:/08/25/setting-up-workstations-with-chef-newbie-edition.html</id>
    <content type="html">&lt;p&gt;I have wanted to reinstall and cleanly set up my iMac at home for some time now. And since there was a new release of Mac OS X around the corner, it seemed like the perfect opportunity to do so. All my past setups and reinstalls were guided by a useful &lt;a href=&#34;https://gist.github.com/513101&#34;&gt;gist&lt;/a&gt; I forked from &lt;a href=&#34;http://kennethreitz.com&#34;&gt;Kenneth Reitz&lt;/a&gt; some time ago and adopted to my needs. However this time I wanted to do it a bit differently, I wanted to take this as an opportunity to dive into configuration management with &lt;a href=&#34;http://opscode.com/chef&#34;&gt;Chef&lt;/a&gt;. As I prepared my configuration I found a lot of things confusing and not so well documented for a complete newbie. Thus I wanted to share my experience and maybe provide an overview and easier access into the world of Chef. After all once you have your setup it is a pretty nice way to keep your workstations&#39; configuration in sync and have a documented way how you got there.&lt;/p&gt;&#xA;&lt;p&gt;The setup I am going to describe is based heavily on Joshua Timberman&#39;s &lt;a href=&#34;http://jtimberman.posterous.com/managing-my-workstations-with-chef&#34;&gt;post&lt;/a&gt; about managing Mac OS X workstations with Chef. If you already know Chef, go read it, it&#39;s great. As all my workstations are running OS X, the steps described are only actually tested on this OS, but should hopefully apply for any other supported OS as well. And of course the setup should be installable to the environment of a normal user (no need to wake up root just because you want to add a plugin to your shell).&lt;/p&gt;&#xA;&lt;p&gt;However as I am very new to Chef and configuration management, some things may not be described 100% accurately, so read this post with two big hands of salt (or two cups of coffee).&lt;/p&gt;&#xA;&lt;h3 id=&#34;configu-what&#34;&gt;Configu-what?&lt;/h3&gt;&#xA;&lt;p&gt;If you are not familiar with configuration management, you can go read it on the &lt;a href=&#34;http://en.wikipedia.org/wiki/Configuration_Management&#34;&gt;Wikipedias&lt;/a&gt;. But in a nutshell it is the possibility to have an automated build with one build target which is &#39;set up the machine production ready&#39;. As in a classical automated software build, the system knows what needs to be done to complete the build target and can track what has already been done. Therefore all steps are idempotent, which means executing a step multiple times always leads to the same result (and no duplicated resources). Therefore it is important that you treat your configuration in the same way you would treat your automated build: There are no steps executed outside the system. If you force yourself to use your configuration management system for every install and configuration you will see how it simplifies your life, at least when you set up a new machine again. Chef is one implementation for such a management system (other popular choices are &lt;a href=&#34;http://projects.puppetlabs.com/projects/puppet&#34;&gt;Puppet&lt;/a&gt; and &lt;a href=&#34;http://cfengine.com&#34;&gt;cfengine&lt;/a&gt;). Chef is (mainly) written in Ruby and supports cookbooks written in Ruby itself or the Chef DSL which we will see in a later example.&lt;/p&gt;&#xA;&lt;h3 id=&#34;to-the-cloud&#34;&gt;To the Cloud!!&lt;/h3&gt;&#xA;&lt;p&gt;Chef comes in two flavours: &lt;a href=&#34;http://wiki.opscode.com/display/chef/Chef+Server&#34;&gt;Chef Server&lt;/a&gt; and &lt;a href=&#34;http://wiki.opscode.com/display/chef/Chef+Solo&#34;&gt;Chef Solo&lt;/a&gt;. The main difference here is that with Chef server everything related to your configuration is managed on a server and machines register on it to get their configuration and then perform all actions locally with &lt;code&gt;chef-client&lt;/code&gt;. Chef Solo on the other hand is basically a client run where you have to download your configuration manually beforehand. The downloaded configuration is then used by the executable to set up your machine. So in a Solo run there is no external resource involved, but there are also some features which are only available in the server edition. For managing my own configuration I decided if I am going to learn Chef I might as well do it with the full stack. However setting up Chef server is a real hassle as many different technologies are involved and is not really recommended for someone new to Chef. Fortunately &lt;a href=&#34;http://www.opscode.com&#34;&gt;Opscode&lt;/a&gt; (the company behind Chef) provides a so-called &#39;Hosted Chef&#39; service, which really just means a Chef server in the cloud. And as it is free up until 5 nodes, it is a great way to get started with Chef.&lt;/p&gt;&#xA;&lt;h3 id=&#34;clients-nodes-knife-cookbook-recipe&#34;&gt;Clients, nodes, knife, cookbook, recipe?&lt;/h3&gt;&#xA;&lt;p&gt;The basic terminology can be a bit confusing (especially as half of the search results usually link to gourmet sites). So let&#39;s try to clear some terminology right upfront:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Cookbooks: Basic Chef configuration/distribution unit&lt;/li&gt;&#xA;&lt;li&gt;Recipe: Subunit of cookbooks. All basic steps are taken in recipes&lt;/li&gt;&#xA;&lt;li&gt;Client: A client which connects to the Chef server, level at which certificates are issued&lt;/li&gt;&#xA;&lt;li&gt;Node: An actual machine which asks the server for its configuration&lt;/li&gt;&#xA;&lt;li&gt;Roles: Collection of cookbooks which can be assigned to nodes&lt;/li&gt;&#xA;&lt;li&gt;Knife: Command line client to interact with the Chef server&lt;/li&gt;&#xA;&lt;li&gt;Data bags: JSON encoded information which doesn&#39;t fit anywhere else to store&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This might still be a bit confusing, but let&#39;s just start with our configuration to see how these parts all play together. The big benefit of Chef (I&#39;m sure it&#39;s the same with most of the other systems), which is also a point which is often discussed as a weakness, is the fact that everything really is Ruby or json. This means it is source code, which again means we can easily manage it with an SCM (I will use git in the examples, but it really applies to your favourite SCM, too). So let&#39;s start with creating our configuration repository:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;fu&#34;&gt;mkdir&lt;/span&gt; chef-repo &lt;span class=&#34;kw&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;bu&#34;&gt;cd&lt;/span&gt; chef-repo&lt;/span&gt;&#xA;&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;fu&#34;&gt;git&lt;/span&gt; init .&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Now that we have our repository set up, we can start to add cookbooks. There are in general two ways to get cookbooks into your repository.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;create the files and folder yourself&lt;/li&gt;&#xA;&lt;li&gt;knife (the command line client, remember?)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Knife is definitely the better way as you can create cookbook scaffolds, add cookbooks directly from the community site or use one of the great plugins (like pulling cookbooks directly from Github). But to get a better understanding of the cookbook basics, we&#39;ll create everything by hand now.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-first-cookbook&#34;&gt;The first cookbook&lt;/h3&gt;&#xA;&lt;p&gt;As an example cookbook we&#39;ll want to install &lt;a href=&#34;https://github.com/robbyrussell/oh-my-zsh&#34;&gt;oh-my-zsh&lt;/a&gt; with our own custom &lt;code&gt;.zshrc&lt;/code&gt;. Although this is probably not such a common install as &lt;code&gt;git&lt;/code&gt; for example, it is a reasonably easy one and a good example for how to automate steps which would normally be done manually. The steps we want to automate are:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;download and install oh-my-zsh&lt;/li&gt;&#xA;&lt;li&gt;install our custom &lt;code&gt;.zshrc&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;So first of all let&#39;s create the basic folder structure:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;fu&#34;&gt;mkdir&lt;/span&gt; -p cookbooks/oh-my-zsh/recipes&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;fu&#34;&gt;mkdir&lt;/span&gt; -p cookbooks/oh-my-zsh/templates/default&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;fu&#34;&gt;touch&lt;/span&gt; cookbooks/oh-my-zsh/recipes/default.rb&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;fu&#34;&gt;touch&lt;/span&gt; cookbooks/oh-my-zsh/templates/default/dot.zshrc.erb&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;fu&#34;&gt;touch&lt;/span&gt; cookbooks/oh-my-zsh/README.rdoc&lt;/span&gt;&#xA;&lt;span id=&#34;cb2-6&#34;&gt;&lt;a href=&#34;#cb2-6&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;fu&#34;&gt;touch&lt;/span&gt; cookbooks/oh-my-zsh/metadata.rb&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;The rough knife equivalent (which creates all the possible folders for the cookbook) would be &lt;code&gt;knife cookbook create oh-my-zsh -o./cookbooks&lt;/code&gt;. However in order to get our oh-my-zsh cookbook working, we only need the files and folders shown above. The &lt;code&gt;README.rdoc&lt;/code&gt; and &lt;code&gt;metadata.rb&lt;/code&gt; files are just for metadata about the cookbook and only the Ruby file is directly parsed by the Chef server for information. But every cookbook should also contain a README which explains its purpose in a spoken language (you create README files for all of your projects, don&#39;t you?).&lt;/p&gt;&#xA;&lt;p&gt;In order to setup the cookbook, first insert your current &lt;code&gt;.zshrc&lt;/code&gt; into &lt;code&gt;oh-my-zsh/templates/default/dot.zshrc.erb&lt;/code&gt;. This makes it available to our recipes as a template file. Now we want to configure the actual recipe. Therefore enter the following into &lt;code&gt;oh-my-zsh/recipes/default.rb&lt;/code&gt;:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode ruby&#34;&gt;&lt;code class=&#34;sourceCode ruby&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34;&gt;&lt;/a&gt;    script &lt;span class=&#34;st&#34;&gt;&amp;quot;oh-my-zsh install from github&amp;quot;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34;&gt;&lt;/a&gt;      interpreter &lt;span class=&#34;st&#34;&gt;&amp;quot;bash&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34;&gt;&lt;/a&gt;      url = https:&lt;span class=&#34;ot&#34;&gt;//&lt;/span&gt;github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34;&gt;&lt;/a&gt;      code &amp;lt;&amp;lt;-&lt;span class=&#34;kw&#34;&gt;EOS&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ot&#34;&gt;        curl -sLf #{&lt;/span&gt;url&lt;span class=&#34;ot&#34;&gt;} -o - | sh&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-6&#34;&gt;&lt;a href=&#34;#cb3-6&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ot&#34;&gt;        rm #{&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;]&lt;span class=&#34;ot&#34;&gt;}/.zshrc&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-7&#34;&gt;&lt;a href=&#34;#cb3-7&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ot&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;EOS&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-8&#34;&gt;&lt;a href=&#34;#cb3-8&#34;&gt;&lt;/a&gt;      not_if { &lt;span class=&#34;dt&#34;&gt;File&lt;/span&gt;.directory? &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;]&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/.oh-my-zsh&amp;quot;&lt;/span&gt; }&lt;/span&gt;&#xA;&lt;span id=&#34;cb3-9&#34;&gt;&lt;a href=&#34;#cb3-9&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;kw&#34;&gt;end&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This just executes the shell script passed to the &lt;code&gt;code&lt;/code&gt; directive. The used interpreter is &lt;code&gt;bash&lt;/code&gt; and the &lt;code&gt;not_if&lt;/code&gt; directive secures the idempotency of this step. The script is only executed if the directory &lt;code&gt;~/.oh-my-zsh&lt;/code&gt; does not exist. The shell script just contains the usual oh-my-zsh installer and removes the generic &lt;code&gt;.zshrc&lt;/code&gt; which is important for the next step. As we want to install our own config file but don&#39;t want to do it everytime, we use the following Chef block (written to &lt;code&gt;oh-my-zsh/recipes/default.rb&lt;/code&gt; directly after the install script):&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode ruby&#34;&gt;&lt;code class=&#34;sourceCode ruby&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34;&gt;&lt;/a&gt;    template &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;]&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/.zshrc&amp;quot;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34;&gt;&lt;/a&gt;      mode   &lt;span class=&#34;bn&#34;&gt;0700&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34;&gt;&lt;/a&gt;      owner  &lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;USER&amp;#39;&lt;/span&gt;]&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34;&gt;&lt;/a&gt;      group  &lt;span class=&#34;dt&#34;&gt;Etc&lt;/span&gt;.getgrgid(&lt;span class=&#34;dt&#34;&gt;Process&lt;/span&gt;.gid).name&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-5&#34;&gt;&lt;a href=&#34;#cb4-5&#34;&gt;&lt;/a&gt;      source &lt;span class=&#34;st&#34;&gt;&amp;quot;dot.zshrc.erb&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-6&#34;&gt;&lt;a href=&#34;#cb4-6&#34;&gt;&lt;/a&gt;      variables({ &lt;span class=&#34;st&#34;&gt;:home&lt;/span&gt; =&amp;gt; &lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;] })&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-7&#34;&gt;&lt;a href=&#34;#cb4-7&#34;&gt;&lt;/a&gt;      not_if { &lt;span class=&#34;dt&#34;&gt;File&lt;/span&gt;.exist? &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;]&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/.zshrc&amp;quot;&lt;/span&gt; }&lt;/span&gt;&#xA;&lt;span id=&#34;cb4-8&#34;&gt;&lt;a href=&#34;#cb4-8&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;kw&#34;&gt;end&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This creates the file given as the template parameter (our zsh config file) with the given properties. It makes sure the file is owned and only readable by us, takes the content from the &lt;code&gt;dot.zshrc.erb&lt;/code&gt; template and passes &lt;code&gt;variables&lt;/code&gt; to the renderer. As you might have already seen, templates are just &lt;a href=&#34;http://ruby-doc.org/stdlib/libdoc/erb/rdoc/classes/ERB.html&#34;&gt;ERB&lt;/a&gt;. This means we can use the ERB syntax (&lt;code&gt;&amp;lt;%= var %&amp;gt;&lt;/code&gt;) within a template to insert dynamic content passed from the recipe.&lt;/p&gt;&#xA;&lt;p&gt;One additional step, we might want to take, is source &lt;code&gt;.profile&lt;/code&gt; in our config file. This is especially useful if you use environment management like &lt;a href=&#34;http://beginrescueend.com/rvm/install/&#34;&gt;rvm&lt;/a&gt;, &lt;a href=&#34;http://pypi.python.org/pypi/virtualenv&#34;&gt;virtualenv&lt;/a&gt; or &lt;a href=&#34;https://github.com/spawngrid/kerl&#34;&gt;kerl&lt;/a&gt;. These usually need to be activated in the shell config. In order to make sure that they are present in every shell the activation step is written into &lt;code&gt;.profile&lt;/code&gt;. Therefore we also want to source it in our zsh config. The &lt;code&gt;not_if&lt;/code&gt; method here also conserves the idempotency of the step.&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode ruby&#34;&gt;&lt;code class=&#34;sourceCode ruby&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34;&gt;&lt;/a&gt;    script &lt;span class=&#34;st&#34;&gt;&amp;quot;source .profile in .zshrc&amp;quot;&lt;/span&gt; &lt;span class=&#34;kw&#34;&gt;do&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-2&#34;&gt;&lt;a href=&#34;#cb5-2&#34;&gt;&lt;/a&gt;      interpreter &lt;span class=&#34;st&#34;&gt;&amp;quot;bash&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-3&#34;&gt;&lt;a href=&#34;#cb5-3&#34;&gt;&lt;/a&gt;      code &amp;lt;&amp;lt;-&lt;span class=&#34;kw&#34;&gt;EOS&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-4&#34;&gt;&lt;a href=&#34;#cb5-4&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ot&#34;&gt;      echo &amp;quot;source #{&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;]&lt;span class=&#34;ot&#34;&gt;}/.profile&amp;quot; &amp;gt;&amp;gt; #{&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;]&lt;span class=&#34;ot&#34;&gt;}/.zshrc&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-5&#34;&gt;&lt;a href=&#34;#cb5-5&#34;&gt;&lt;/a&gt;&lt;span class=&#34;ot&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;kw&#34;&gt;EOS&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-6&#34;&gt;&lt;a href=&#34;#cb5-6&#34;&gt;&lt;/a&gt;      not_if &lt;span class=&#34;st&#34;&gt;&amp;quot;grep \&amp;quot;source &lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;]&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/.profile\&amp;quot; &lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;]&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/.zshrc&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb5-7&#34;&gt;&lt;a href=&#34;#cb5-7&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;kw&#34;&gt;end&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;h3 id=&#34;the-server-comes-into-play&#34;&gt;The server comes into play&lt;/h3&gt;&#xA;&lt;p&gt;After finishing these steps, we can upload the cookbook to our server. In order to be able to do this, the server needs to be set up, so if you haven&#39;t already &lt;a href=&#34;http://www.opscode.com/hosted-chef/&#34;&gt;sign up&lt;/a&gt; for a free hosted chef. After creating your organization, put your client and validation certificates in &lt;code&gt;~/.chef&lt;/code&gt;. I find this to be a convenient place for all your Chef related configuration, but you can of course choose another directory (just make sure that you also adapt subsequent steps in this post accordingly). Now we can upload our cookbook with:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;ex&#34;&gt;knife&lt;/span&gt; cookbook upload oh-my-zsh&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;We have a cookbook on the server now, but no node uses it, yet (we also don&#39;t have nodes set up at the moment but bear with me here). In order to match nodes to cookbooks Chef employs the concept of &#39;run lists&#39;. These are basically lists of recipes which can be added to a node so that it knows what to install. As run lists are mostly very similar between nodes of the same category, we can set up a role for it in Chef. A role is just a specific set of attributes and a run list which is mapped to a name. As there may be multiple machines we use as workstations we create a role &#39;workstation&#39; in the roles directory of our Chef repository:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;fu&#34;&gt;mkdir&lt;/span&gt; -p roles&lt;/span&gt;&#xA;&lt;span id=&#34;cb7-2&#34;&gt;&lt;a href=&#34;#cb7-2&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;fu&#34;&gt;touch&lt;/span&gt; roles/workstation.rb&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Again this is just Ruby so we add the following information to &lt;code&gt;workstation.rb&lt;/code&gt;:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb8&#34;&gt;&lt;pre class=&#34;sourceCode ruby&#34;&gt;&lt;code class=&#34;sourceCode ruby&#34;&gt;&lt;span id=&#34;cb8-1&#34;&gt;&lt;a href=&#34;#cb8-1&#34;&gt;&lt;/a&gt;    name &lt;span class=&#34;st&#34;&gt;&amp;quot;workstation&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-2&#34;&gt;&lt;a href=&#34;#cb8-2&#34;&gt;&lt;/a&gt;    description &lt;span class=&#34;st&#34;&gt;&amp;quot;development workstations&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-3&#34;&gt;&lt;a href=&#34;#cb8-3&#34;&gt;&lt;/a&gt;    run_list(&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-4&#34;&gt;&lt;a href=&#34;#cb8-4&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;st&#34;&gt;&amp;quot;recipe[oh-my-zsh]&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb8-5&#34;&gt;&lt;a href=&#34;#cb8-5&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;Now every node which is assigned the &#39;workstation&#39; role will know that it has to install chef &lt;code&gt;oh-my-zsh&lt;/code&gt; recipe. Let&#39;s upload the role to our server:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb9&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb9-1&#34;&gt;&lt;a href=&#34;#cb9-1&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;ex&#34;&gt;knife&lt;/span&gt; upload role from file workstation.rb&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;In the management web interface (or via &lt;code&gt;knife&lt;/code&gt;) we can now assign the role &#39;workstation&#39; to specific nodes. However we first need a client which is allowed to connect to the server API. Clients and nodes are somewhat the same in Chef. Theoretically it is possible that a client manages a number of nodes, but normally every node corresponds to one client. Therefore we create a new client for our workstation. You can also run &lt;code&gt;chef-client&lt;/code&gt; on your node and provide the validator certificate for your organization. If the node does not yet exist on the server it is created. However this means that you have to have the validator certificate (which is the ultimate key to your server) on the node. This might not be a problem for setting up your development machine, but is bad security in general. So the better way is to create the client and node on the server and provide the correct credentials (at least read and update) for the client on the node. One more advantage is that we can now already assign roles to our nodes (via the &#39;Roles&#39; menu) and add the &#39;workstation&#39; role to the newly created node. All these steps can of course also be accomplished with &lt;code&gt;knife&lt;/code&gt;, but I find the web management console easier to start with. When all this is done, download the client&#39;s certificate and also put it in &lt;code&gt;~/.chef&lt;/code&gt;. Theoretically your node is correctly set up already. However Chef makes the assumption that it is run with privileges. Therefore the default data directory is in &lt;code&gt;/etc/chef&lt;/code&gt;. As we want to setup our development machine and not a server, it makes sense to run &lt;code&gt;chef-client&lt;/code&gt; as your normal user. In order to do this, you would now have to make the default directories accessible for your user. But we can also override the paths used in the client config. I also keep my paths in &lt;code&gt;~/.chef&lt;/code&gt; (everything in one place, remember?) so a good adaption of your &lt;code&gt;client.rb&lt;/code&gt; might be:&lt;/p&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb10&#34;&gt;&lt;pre class=&#34;sourceCode ruby&#34;&gt;&lt;code class=&#34;sourceCode ruby&#34;&gt;&lt;span id=&#34;cb10-1&#34;&gt;&lt;a href=&#34;#cb10-1&#34;&gt;&lt;/a&gt;    base_dir = &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;&lt;span class=&#34;dt&#34;&gt;ENV&lt;/span&gt;[&lt;span class=&#34;st&#34;&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;]&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/.chef&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb10-2&#34;&gt;&lt;a href=&#34;#cb10-2&#34;&gt;&lt;/a&gt;    run_path &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;base_dir&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/run&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb10-3&#34;&gt;&lt;a href=&#34;#cb10-3&#34;&gt;&lt;/a&gt;    checksum_path &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;base_dir&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/checksum&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb10-4&#34;&gt;&lt;a href=&#34;#cb10-4&#34;&gt;&lt;/a&gt;    file_cache_path &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;base_dir&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/cache&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb10-5&#34;&gt;&lt;a href=&#34;#cb10-5&#34;&gt;&lt;/a&gt;    file_backup_path &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;base_dir&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/backup&amp;quot;&lt;/span&gt;&lt;/span&gt;&#xA;&lt;span id=&#34;cb10-6&#34;&gt;&lt;a href=&#34;#cb10-6&#34;&gt;&lt;/a&gt;    cache_options({&lt;span class=&#34;st&#34;&gt;:path&lt;/span&gt; =&amp;gt; &lt;span class=&#34;st&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&#34;ot&#34;&gt;#{&lt;/span&gt;base_dir&lt;span class=&#34;ot&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;/cache/checksums&amp;quot;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;:skip_expires&lt;/span&gt; =&amp;gt; &lt;span class=&#34;dv&#34;&gt;true&lt;/span&gt;})&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;This will make sure only subdirectories of &lt;code&gt;~/.chef&lt;/code&gt; will be used for caching, checksums, etc. After these steps there is only one thing to do.&lt;/p&gt;&#xA;&lt;h3 id=&#34;sit-back-and-watch&#34;&gt;Sit back and watch&lt;/h3&gt;&#xA;&lt;div class=&#34;sourceCode&#34; id=&#34;cb11&#34;&gt;&lt;pre class=&#34;sourceCode bash&#34;&gt;&lt;code class=&#34;sourceCode bash&#34;&gt;&lt;span id=&#34;cb11-1&#34;&gt;&lt;a href=&#34;#cb11-1&#34;&gt;&lt;/a&gt;    $ &lt;span class=&#34;ex&#34;&gt;chef-client&lt;/span&gt; -c ~/.chef/client.rb -k ~/.chef/client.pem&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&#xA;&lt;p&gt;The above command will run the Chef client with the specified config and client certificate. It will then fetch the cookbooks from the server, determine which to execute via the nodes run list and run them. If everything went well you now have oh-my-zsh installed and can go on and add additional cookbooks to your repository.&lt;/p&gt;&#xA;&lt;h3 id=&#34;further-reading&#34;&gt;Further reading&lt;/h3&gt;&#xA;&lt;p&gt;You should now be equipped with a basic working setup to create your configuration with Chef. Play around with new cookbooks and try to force yourself to do everything system configuration related in terms of cookbooks and data bags. You&#39;ll only learn it by doing it. If you feel comfortable enough with this basic setup, see the following links for some more sophisticated possibilities.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://jtimberman.posterous.com/managing-my-workstations-with-chef&#34;&gt;Managing workstations with Chef&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://wiki.opscode.com/display/chef/Encrypted+Data+Bags&#34;&gt;Encrypted data bags&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://wiki.opscode.com/display/chef/Lightweight+Resources+and+Providers+(LWRP)&#34;&gt;Light Weight Resource Providers(LWRP)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2011/08/25/setting-up-workstations-with-chef-newbie-edition.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I have wanted to reinstall and cleanly set up my iMac at home for some time now. And since there </summary>
  </entry>
  <entry>
    <title>gtd-couch - GTD as a couchapp</title>
    <updated>2011-01-03T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2011,2011-01-03:/01/03/gtd-couch---gtd-as-a-couchapp.html</id>
    <content type="html">&lt;h3 id=&#34;why-another-gtd-app&#34;&gt;Why another GTD app?&lt;/h3&gt;&#xA;&lt;p&gt;Over the last years I have tried a lot of task management applications. I was always trying to improve the status quo, where I forgot some things I wanted to do and didn&#39;t have a possibility to jot things down when I should have. For the last 2 years &lt;a href=&#34;http://culturedcode.com/&#34;&gt;Things&lt;/a&gt; was my task manager of choice. With the iPhone companion app I could add tasks on the go and sync them to the Things database on my MacBook. The fact that it was only possible in the local network was acceptable, since cloud sync was &lt;a href=&#34;http://culturedcode.com/things/blog/2009/08/this-is-not-a-roadmap.html&#34;&gt;announced with priority&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Over time I added an &lt;a href=&#34;http://unwiredcouch.com/2009/12/24/first-weekend-with-endless-screen-real-estate.html&#34;&gt;iMac&lt;/a&gt; and an &lt;a href=&#34;http://twitter.com/mrtazz/status/24500270704&#34;&gt;iPad&lt;/a&gt; to my setup. This made t(T)hings a bit more complicated. Syncing between the iMac and MacBook is much more complicated. I chose to sync my Things database file via my &lt;a href=&#34;http://db.tt/IizMFIF&#34;&gt;DropBox&lt;/a&gt; account to all my computers. But this means that only one instance of Things can be running at a time. If I forget to close the app on one machine, the data will probably not be up to date or even overwritten. The iPad can sync natively with the Mac application. But then again only via the local network. I also didn&#39;t want to pay half of the price of the desktop application for a solution I&#39;m not satisfied with. And I didn&#39;t want to setup some VPN/Wide Area Bonjour solution just to sync my tasks. And there is still no over-the-air sync solution in sight.&lt;/p&gt;&#xA;&lt;p&gt;The main problem is apparently that this syncing and scaling stuff is &lt;a href=&#34;http://culturedcode.com/things/blog/2010/12/state-of-sync-part-1.html&#34;&gt;really hard&lt;/a&gt;. Which is also the reason why systems like &lt;a href=&#34;http://couchdb.apache.org/&#34;&gt;CouchDB&lt;/a&gt; don&#39;t exist. Don&#39;t get me wrong, I don&#39;t think you can solve this (in a satisfying way for developers and customers) by just throwing a piece of technology at it. But I also don&#39;t think this is we-have-to-think-about-it-for-2-years hard. Needless to say I am a bit disappointed how this turned out. And due to this I also used Things less and less, which didn&#39;t really improve the situation.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-alternatives&#34;&gt;The alternatives&lt;/h3&gt;&#xA;&lt;p&gt;So I started to try out other task management solutions. The obvious choice was &lt;a href=&#34;http://www.omnigroup.com/products/omnifocus/&#34;&gt;OmniFocus&lt;/a&gt;. It has great syncing support and device integration. However I just want a simple solution and OmniFocus can do pretty much everything ever imagined regarding task management. So it is a bit bloated to use. Other notable choices are &lt;a href=&#34;http://www.appigo.com/todo/ipad&#34;&gt;Todo for iPad&lt;/a&gt;/&lt;a href=&#34;http://www.appigo.com/todo&#34;&gt;iPhone&lt;/a&gt; in combination with the &lt;a href=&#34;https://appigotodo.appspot.com/&#34;&gt;online syncing service&lt;/a&gt;. There is no Desktop app however and I have the feeling, that the data is rather closed in.&lt;/p&gt;&#xA;&lt;p&gt;One really good looking alternative is &lt;a href=&#34;http://www.6wunderkinder.com/wunderlist/&#34;&gt;wunderlist&lt;/a&gt; by the Berlin based company &lt;a href=&#34;http://www.6wunderkinder.com/&#34;&gt;6 Wunderkinder&lt;/a&gt;. There is a Desktop and iPhone app and there is also online syncing built in. This is really a promising todo manager with a clean interface. But I also wanted the possibility to have my data in my own personal cloud.&lt;/p&gt;&#xA;&lt;h3 id=&#34;couchdb-to-the-rescue&#34;&gt;CouchDB to the rescue&lt;/h3&gt;&#xA;&lt;p&gt;As I had started to work a lot more with CouchDB lately, I decided to built a GTD manager as a couchapp. This meant I get replication, simple storage and the REST API (almost) for free. Additionally it supports a completely decoupled approach to interface with the data. The first step is of course to write a couchapp to be served directly from CouchDB. This can then be used to access the data from everywhere. And can also be replicated together with the data to any device supporting CouchDB.&lt;/p&gt;&#xA;&lt;p&gt;For the next steps the CouchDB HTTP/JSON API also enables the easy creation of clients for the data in almost any language or technology. Therefore a console, native OSX or iPhone client or even a much better web client can be created rather easily. And all this while your data remains under your control. Just &lt;a href=&#34;http://www.couchone.com/get&#34;&gt;get&lt;/a&gt; a CouchDB and get started.&lt;/p&gt;&#xA;&lt;h3 id=&#34;use-this-now&#34;&gt;Use this now?&lt;/h3&gt;&#xA;&lt;p&gt;That being said, &lt;a href=&#34;https://github.com/mrtazz/gtd-couch&#34;&gt;gtd-couch&lt;/a&gt; - the couchapp mentioned before - has just reached version v0.1.0. It already features basic functionality and is pretty usable. Try it out if you&#39;re interested, I use it as my task manager already. There are also some outstanding issues and new features which will be implemented as time allows.&lt;/p&gt;&#xA;&lt;p&gt;This does not mean that I won&#39;t try out the Things cloud sync solution, when (if) it finally comes out. I still think it has really great design and a simple interface. But for now I&#39;ll enjoy being able to interface with my data as I want to and host it where I want to.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2011/01/03/gtd-couch---gtd-as-a-couchapp.html" rel="alternate"></link>
    <summary type="html">&lt;h3 id=&#34;why-another-gtd-app&#34;&gt;Why another GTD app?&lt;/h3&gt;&#xA;&lt;p&gt;Over the last years I have tried a lot of </summary>
  </entry>
  <entry>
    <title>Testing couchapps with cucumber</title>
    <updated>2010-12-30T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2010,2010-12-30:/12/30/testing-couchapps-with-cucumber.html</id>
    <content type="html">&lt;h3 id=&#34;couchapps-overview&#34;&gt;Couchapps overview&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://couchapp.org&#34;&gt;Couchapps&lt;/a&gt; are a great way to build web apps hosted directly on a CouchDB. This is due to the integrated HTTP server, so if you can fit your application into the constraints of HTML/CSS/JavaScript, you get the storage (almost) for free. The heart of couchapps is &lt;a href=&#34;http://couchapp.org/page/evently&#34;&gt;evently&lt;/a&gt;, a JavaScript framework simplifying the development of event based web applications. The development process is accompanied by the &lt;a href=&#34;https://github.com/couchapp/couchapp&#34;&gt;couchapp python script&lt;/a&gt;, which maps a certain directory structure to the evently application layout. This makes it easy to develop the source code, which is normally stored as attachments in the design document, in your favourite editor. However this difference in how the application is developed and how it is deployed, makes it a bit more difficult to automatically test the application.&lt;/p&gt;&#xA;&lt;h3 id=&#34;enter-cucumber&#34;&gt;Enter cucumber&lt;/h3&gt;&#xA;&lt;p&gt;Fortunately the ruby world has provided us with a great tool for acceptance testing web applications: &lt;a href=&#34;http://cukes.info&#34;&gt;Cucumber&lt;/a&gt;. Cucumber is a testing framework, which encourages &lt;a href=&#34;http://en.wikipedia.org/wiki/Behavior_Driven_Development&#34;&gt;BDD&lt;/a&gt; style development. It features different drivers for (headless) browser testing and supports an easy, natural language like, syntax for creating tests (scenarios as they are called in BDD world). If you don&#39;t use it already, give it a try, it is really great. However to fully embrace an automated testing approach we need some helpers to do additional work, for example create and destroy the testing environments.&lt;/p&gt;&#xA;&lt;h3 id=&#34;we-have-the-technology-we-can-make-him-stronger&#34;&gt;We have the technology, we can make him stronger&lt;/h3&gt;&#xA;&lt;p&gt;The first problem was the CouchDB native authentication db used by couchapps to profit from the already existing user management. Fortunately there is &lt;a href=&#34;http://lenaherrmann.net/2010/04/29/security-in-couchdb-changing-the-authentication-db&#34;&gt;a way&lt;/a&gt; to change the db used for authentication to an arbitrary one. The next nice-to-have is an easy setup for choosing databases for different environments like tests. Fortunately rails already provides a clean setup for this, which we can copy. Now we only have to bundle a &lt;a href=&#34;https://gist.github.com/738128&#34;&gt;simple CouchDB library&lt;/a&gt; and some helper methods and we are ready to go. This is what &lt;a href=&#34;https://github.com/mrtazz/couchapp-cucumber&#34;&gt;couchapp-cucumber&lt;/a&gt; is about. I bundled all these steps as a simple cucumber drop-in. I&#39;m sure it can be improved in a lot of ways.&lt;/p&gt;&#xA;&lt;h3 id=&#34;so-fork-it-hack-away-and-happy-testing&#34;&gt;So fork it. Hack away. And happy testing.&lt;/h3&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2010/12/30/testing-couchapps-with-cucumber.html" rel="alternate"></link>
    <summary type="html">&lt;h3 id=&#34;couchapps-overview&#34;&gt;Couchapps overview&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://couchapp.org&#34;&gt;Couchapps&lt;/a&gt; a</summary>
  </entry>
  <entry>
    <title>Introducing Ramrod Command Center</title>
    <updated>2010-09-19T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2010,2010-09-19:/09/19/introducing-ramrod-command-center.html</id>
    <content type="html">&lt;p&gt;I have &lt;a href=&#34;http://twitter.com/mrtazz/status/24040433982&#34;&gt;finally&lt;/a&gt; registered my Master&#39;s thesis. This means in 6 month my university life is over and the hard and cruel reality begins. I am writing my thesis at the &lt;a href=&#34;http://cone.informatik.uni-freiburg.de&#34;&gt;Chair of Computer Networks&lt;/a&gt; about localization of nodes without external positioning information. I am going to port the existing algorithms to Unix platforms and create a server environment to be able to use the localization also in networks without direct communication.&lt;/p&gt;&#xA;&lt;p&gt;The resulting (localization) software has to run on different platforms such as Windows, Unix and the iPhone. This is why I wanted a build system with continuous integration, where the software is built and tested on these platforms. For continuous integration I normally use &lt;a href=&#34;http://integrityapp.com&#34;&gt;integrity&lt;/a&gt; or &lt;a href=&#34;http://github.com/defunkt/cijoe&#34;&gt;cijoe&lt;/a&gt;, which are simple but therefore don&#39;t support notifying builds for several platforms. &lt;a href=&#34;http://hudson-ci.org&#34;&gt;Hudson&lt;/a&gt; has support for agents, but as far as I found out, they have to be hudson agents. For my Master&#39;s project I wanted to be able to use integrity as well as cijoe as agents and have a simple central command instance, which notifies them.&lt;/p&gt;&#xA;&lt;h3 id=&#34;ramrod&#34;&gt;Ramrod&lt;/h3&gt;&#xA;&lt;p&gt;This is why I built &lt;a href=&#34;http://github.com/mrtazz/ramrod&#34;&gt;ramrod&lt;/a&gt;. It is a small sinatra application, which acts as a sort of CI control center. Ramrod can be notified to build a project via simple HTTP POST. All registered agents are then notified subsequently. The agents have to be configured to notify the result back to ramrod, where all the results are then displayed. This can be easily done with cijoe and integrity. Ramrod itself has a simple structure and can be deployed to any ruby hosting platform.&lt;/p&gt;&#xA;&lt;p&gt;The project is still in a very early stage and there are a lot of things which have to be improved (or even implemented), such as a notification system, authentication and of course a much better design. But I think the initial release v0.1.0 is already quite helpful and usable.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2010/09/19/introducing-ramrod-command-center.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;I have &lt;a href=&#34;http://twitter.com/mrtazz/status/24040433982&#34;&gt;finally&lt;/a&gt; registered my Master&#39;s </summary>
  </entry>
  <entry>
    <title>Chipping in on Textmate to Vim switching</title>
    <updated>2010-08-09T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2010,2010-08-09:/08/09/vim.html</id>
    <content type="html">&lt;p&gt;There was some buzz lately about people considering &lt;a href=&#34;http://www.vim.org&#34;&gt;Vim&lt;/a&gt; as their main editor and especially going from &lt;a href=&#34;http://macromates.com&#34;&gt;Textmate&lt;/a&gt; to Vim. I&#39;ve tried several times to go the other way and leave vim as my editor of choice in favour of Textmate. It never worked.&lt;/p&gt;&#xA;&lt;h3 id=&#34;magic-does-not-come-easy&#34;&gt;Magic does not come easy&lt;/h3&gt;&#xA;&lt;p&gt;I think there is one big mistake a lot of people do when switching. They expect to start vim and instantly have their fingers dance over the keyboard and coworkers being stunned by the awesome magic. But as with everything you learn, this is not the case. It is a long (think years long and not weeks long) way to even come close to this dance. I started fighting with vim in 2004 and think I have mastered the first 10% now. In my opinion Yehuda Katz was right when he &lt;a href=&#34;http://yehudakatz.com/2010/07/29/everyone-who-tried-to-convince-me-to-use-vim-was-wrong/&#34;&gt;said&lt;/a&gt; that you should really start in insert mode. It turns out, that you can really use Vim (especially &lt;a href=&#34;http://code.google.com/p/macvim/&#34;&gt;MacVim&lt;/a&gt;) like any other editor. From there on, if you force yourself to learn and use a new command everyday, you will see significant speed (and magic) improvements quite fast.&lt;/p&gt;&#xA;&lt;h3 id=&#34;bundle-configuration-with-pathogen&#34;&gt;Bundle configuration with pathogen&lt;/h3&gt;&#xA;&lt;p&gt;Another topic which is very important (and powerful) is bundle support. Textmate&#39;s bundles are split into different type in Vim. There are plugins, compiler, syntax and some more folders which can be used for configuration. If you do it the old way, it is really cumbersome. You have to copy new scripts into the according folders in your &lt;code&gt;~/.vim&lt;/code&gt; folder. You have to check that nothing gets overwritten, and after some time you will lose track of what plugins you have installed.&lt;/p&gt;&#xA;&lt;p&gt;Fortunately, Tim Pope wrote the great &lt;a href=&#34;http://github.com/tpope/vim-pathogen&#34;&gt;pathogen plugin&lt;/a&gt;. You only have to put it into a folder called autoload and enter 3 lines into your &lt;code&gt;~/.vimrc&lt;/code&gt; and your done. Now you can create a new folder under &lt;code&gt;~/.vim/bundle&lt;/code&gt; for each plugin you want to install. Pathogen will automatically load the plugin for you. You can even go further and put your configuration into &lt;a href=&#34;http://git-scm.com&#34;&gt;git&lt;/a&gt;. If you add all of your plugins as git submodule, you can easily update them and have your configuration in sync on all your machines. It&#39;s that easy.&lt;/p&gt;&#xA;&lt;h3 id=&#34;you-mentioned-textmate&#34;&gt;You mentioned Textmate?&lt;/h3&gt;&#xA;&lt;p&gt;Right. I mentioned that I tried several times to switch to Textmate, as all the smart OSX users seem to use it. And if all the smart people use it, it must be awesome right?&lt;/p&gt;&#xA;&lt;p&gt;After using Textmate for some time, I suffered the same symptoms all the Vim switchers were talking about. Coding was slow, I had to think how I do this and that much to often, shortcuts are way to complicated and I tried to find a Vim mode for Textmate, that worked for me. I was trying to instantly unleash the magic. And that just doesn&#39;t work. While I think Textmate is (one of) the best pure OSX editors and I hope that there will be a version 2 someday, I am still incredibly more productive with Vim. So Textmate is more of a fun to use tool, which I use when I am in the mood.&lt;/p&gt;&#xA;&lt;p&gt;But there is still this emacs thing out there, I hear. And it also wants to be learned.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2010/08/09/vim.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;There was some buzz lately about people considering &lt;a href=&#34;http://www.vim.org&#34;&gt;Vim&lt;/a&gt; as their</summary>
  </entry>
  <entry>
    <title>Notifo</title>
    <updated>2010-07-11T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2010,2010-07-11:/07/11/notifo.html</id>
    <content type="html">&lt;p&gt;&lt;a href=&#34;http://notifo.com&#34;&gt;Notifo.com&lt;/a&gt; is a web service which enables you to send push notifications to your mobile device (at the moment there is only support for the iPhone). This &lt;a href=&#34;http://paulstamatiou.com/notifo-yc-w2010-gets-a-co-founder-me&#34;&gt;blog post&lt;/a&gt; first called my attention to the service. I have used &lt;a href=&#34;http://prowl.weks.net/&#34;&gt;prowl&lt;/a&gt; (a similar service based on &lt;a href=&#34;http://growl.info/&#34;&gt;growl&lt;/a&gt;) before and I was instantly interested in this somewhat more versatile notifo.&lt;/p&gt;&#xA;&lt;p&gt;On the same evening I decided to build a &lt;a href=&#34;http://github.com/mrtazz/notifo.py&#34;&gt;python library&lt;/a&gt;, to be able to easily notify users from python applications. I also thought it would be cool to get push notifications from your CI server about your builds. So I implemented an &lt;a href=&#34;http://integrityapp.com/&#34;&gt;integrity&lt;/a&gt; notifier which is now available in the main line.&lt;/p&gt;&#xA;&lt;p&gt;At the moment I personally use notifo to get notified about twitter mentions via &lt;a href=&#34;http://push.ly&#34;&gt;push.ly&lt;/a&gt;, website changes via &lt;a href=&#34;http://femtoo.com&#34;&gt;femtoo&lt;/a&gt; and commits to some of my github projects via a &lt;a href=&#34;http://github.com/github/github-services&#34;&gt;service hook&lt;/a&gt;. Once I have found suitable hosting for integrity for my projects, I will also use the integrity notifier. And I am very excited to see what else will be build upon this service.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2010/07/11/notifo.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;a href=&#34;http://notifo.com&#34;&gt;Notifo.com&lt;/a&gt; is a web service which enables you to send push notifi</summary>
  </entry>
  <entry>
    <title>Thunk.us Python wrapper</title>
    <updated>2010-06-04T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2010,2010-06-04:/06/04/thunk-us.html</id>
    <content type="html">&lt;p&gt;Lately I have become more and more interested in APIs (especially on the web). As a first manifestation of this interest I converted the simple python script to add articles to &lt;a href=&#34;http://instapaper.com&#34;&gt;instapaper&lt;/a&gt; I wrote some time ago into a usable &lt;a href=&#34;http://pypi.python.org/pypi/instapaperlib&#34;&gt;python library&lt;/a&gt; utilizing the full API.&lt;/p&gt;&#xA;&lt;p&gt;Then, while reading some blog posts about continuous integration and build notification, I stumbled upon &lt;a href=&#34;http://thunk.us&#34;&gt;thunk.us&lt;/a&gt;. It is a simple status management service. You register your thunk there, poke it to set the status and everyone who needs to (i.e. knows the ID) can check it. It can easily be used to notify about succeeded/failed builds, status of queues or coffee supply or anything else for that matter. Allthough I had no immediate usage for such a system, I read the API definitions and found them to be interesting enough to build something upon it.&lt;/p&gt;&#xA;&lt;p&gt;Enter &lt;a href=&#34;http://github.com/mrtazz/thunkapi.py&#34;&gt;thunkapi.py&lt;/a&gt;. A python library with command line client to interact with the thunk.us service. I built the library with ease of use in mind (and I think I somewhat succeeded). One can easily provide states, payload and a UID (or list of UIDs where applicable) to the exposed methods and get a clean python dict object in return.&lt;/p&gt;&#xA;&lt;p&gt;I will still have to see if I have a productive use for the thunk.us service. But the fun of building the library was motivation enough. So have fun with it, use it if you like it and if you dislike something about it: &lt;a href=&#34;http://github.com/mrtazz/thunkapi.py&#34;&gt;Fork me!&lt;/a&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2010/06/04/thunk-us.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lately I have become more and more interested in APIs (especially on the web). As a first manifes</summary>
  </entry>
  <entry>
    <title>Where&#39;s ma ketchup?</title>
    <updated>2010-05-31T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2010,2010-05-31:/05/31/ketchupstatus.html</id>
    <content type="html">&lt;p&gt;At our office mondays are special. This is the one day Bobby drives his good old trailer to the parking lot of the supermarket next to the office and sells chicken and fries. As an alternative it is also possible to only get fries and get burgers for the microwave from the supermarket. But there is still one more important thing: Ketchup. There are even weekly fights, about which brand is the best (no doubt, Heinz is where my heart is). Ketchup is a shared resource with us. One person usually buys a bottle for everybody and when it is empty, the next one is bought by someone else.&lt;/p&gt;&#xA;&lt;p&gt;The problem is once we are in the supermarket, usually nobody has checked if we still have ketchup or not. And so the guessing starts. This is why I decided to build an easy web application where we can set and check the current status of our ketchup supply. So last weekend I sat down and since I wanted to get into ruby anyway, I built a sinatra app. It is quite simple and works with a token based API, but it does the job. It is hosted on &lt;a href=&#34;http://ketchupstatus.heroku.com&#34;&gt;heroku&lt;/a&gt; if you want to check it out. But you can also fork it on &lt;a href=&#34;http://github.com/mrtazz/ketchupstatus&#34;&gt;the githubs&lt;/a&gt;, if you want to improve it or adapt it to something else.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2010/05/31/ketchupstatus.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;At our office mondays are special. This is the one day Bobby drives his good old trailer to the p</summary>
  </entry>
  <entry>
    <title>instapaperlib</title>
    <updated>2010-05-20T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2010,2010-05-20:/05/20/instapaperlib.html</id>
    <content type="html">&lt;p&gt;For some time now &lt;a href=&#34;http://instapaper.com&#34;&gt;instapaper.com&lt;/a&gt; is one of the web services I use most. Together with the iPhone application it is the perfect storage place for articles and blog posts you get via RSS, twitter or from anywhere else. Whenever I don&#39;t have time to read a link right now, I hit my &#34;Read later&#34; bookmark and the article is saved in pure text form to my instapaper.com account. The same goes for twitter links, Tweetie (now Twitter for iPhone) has perfectly integrated instapaper so that it could not be easier to post links for reading later.&lt;/p&gt;&#xA;&lt;p&gt;However I also wanted to be able to add links quickly which come from other sources. That is why I wrote a library for instapaper in python and a command line client using this library. For source code and examples see the &lt;a href=&#34;http://github.com/mrtazz/InstapaperLibrary&#34;&gt;github&lt;/a&gt; page and to install use &lt;a href=&#34;http://pypi.python.org/pypi/instapaperlib/0.2.0&#34;&gt;PyPi&lt;/a&gt;.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2010/05/20/instapaperlib.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;For some time now &lt;a href=&#34;http://instapaper.com&#34;&gt;instapaper.com&lt;/a&gt; is one of the web services I</summary>
  </entry>
  <entry>
    <title>plustache</title>
    <updated>2010-04-21T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2010,2010-04-21:/04/21/plustache.html</id>
    <content type="html">&lt;p&gt;Some time ago I discovered &lt;a href=&#34;http://twitter.com/defunkt&#34;&gt;@defunkt&#39;s&lt;/a&gt; logic less ruby templating system &lt;a href=&#34;http://mustache.github.com&#34;&gt;mustache&lt;/a&gt;. I instantly liked it because of its simplicity, independence from any frameworks and admittingly also because of the name. After having seen many implementations in &lt;a href=&#34;http://github.com/defunkt/pystache&#34;&gt;python&lt;/a&gt;, &lt;a href=&#34;http://github.com/janl/mustache.js&#34;&gt;JavaScript&lt;/a&gt; and even &lt;a href=&#34;http://github.com/mojombo/mustache.erl&#34;&gt;Erlang&lt;/a&gt; and &lt;a href=&#34;http://github.com/raycmorgan/Mu&#34;&gt;node.js&lt;/a&gt; I decided to also port it to a new language. Since I am doing some C++ at work at the moment and I wanted to deepen my knowledge in some non-work related projects anyway, the decision was practically made. So I fired up my trusty &lt;a href=&#34;http://code.google.com/p/macvim/&#34;&gt;text editor&lt;/a&gt; and hacked away. After some weeks of creating the build system, deciding how to do regular expressions and unit tests, basic mustache tags, true/false and inverted sections are working, as well as basic HTML esacping.&lt;/p&gt;&#xA;&lt;p&gt;The results can be seen on &lt;a href=&#34;http://github.com/mrtazz/plustache&#34;&gt;github&lt;/a&gt; and at the moment I am working on getting to a point where I am satisfied enough with the code to tag it v0.1.0. I am excited to port mustache to a more static language and challenge the difficulties of still keeping it simple. And I am even more excited about how this mustache thing will evolve.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2010/04/21/plustache.html" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Some time ago I discovered &lt;a href=&#34;http://twitter.com/defunkt&#34;&gt;@defunkt&#39;s&lt;/a&gt; logic less ruby te</summary>
  </entry>
  <entry>
    <title>Almost Endless Screen Real Estate</title>
    <updated>2009-12-24T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2009,2009-12-24:/12/24/first-weekend-with-endless-screen-real-estate.html</id>
    <content type="html">&lt;h3 id=&#34;ye-olde-setup&#34;&gt;Ye olde setup&lt;/h3&gt;&#xA;&lt;p&gt;Some months ago I realized that my Mac mini, used as a media server in my livingroom, has been getting a bit long in the tooth. The 1,8 GHz Core (no 2) Duo with 1GB RAM and 80GB hard disk was top notch when I bought it around 3 years ago. But in the meantime I have aquired around 300GB of music, TV shows and movies (thank you iTunes store and handbrake) and the startup time of iTunes seemed to increase every week. It was also getting more and more time consuming to play flash videos, not to speak of HD TV shows.&lt;/p&gt;&#xA;&lt;p&gt;Another thing that always somehow bugged me, was the fact that I had a whole machine only for serving media content, which just seems a bit too much. Since I don&#39;t watch TV shows all day and also don&#39;t listen to music all the time, the Mac mini was idle around 75% of the day. Sure it doesn&#39;t consume that much power when idling, but nevertheless it always felt like a waste. Additionally there are some Firewire hard disks connected to the Mac mini, since I ran out of internal storage a long time ago (and didn&#39;t feel like replacing the hard disk). Just more negative contribution to my carbon footprint.&lt;/p&gt;&#xA;&lt;p&gt;My main machine for work and university is a black MacBook from late 2007/early 2008. For coding and longer studying, I hooked it up to an external 22-inch Full HD display and Apple wireless keyboard/mouse. Since I got tired of cabling/uncabling the MacBook, it happened all too often, that I worked on the small screen too long to be comfortable or had the MacBook connected to the display all weekend and missed its mobility. I also more and more often had the feeling, that the external display was a bit too small and that the combination of 22-inch and 1920x1080 resolution wasn&#39;t right for me.&lt;/p&gt;&#xA;&lt;p&gt;So around September this year I started thinking about how to improve my situation.&lt;/p&gt;&#xA;&lt;h3 id=&#34;choosing-new-hardware&#34;&gt;Choosing new hardware&lt;/h3&gt;&#xA;&lt;p&gt;The first solution I thought about, was the new Mac mini, which has two display outputs. I could hook it up to the display and the TV and have a machine for working and a multimedia machine at the same time. However, I am not satisfied with the hard disk size of the Mac mini. It is only a matter of time until my media data exceeds 500GB and I am not ready to give up the optical drive for more storage and the Mac mini server.&lt;/p&gt;&#xA;&lt;p&gt;Then the new 27-inch iMac came out and I was instantly stunned by the display. Also the low-end 27-inch has a 1TB hard disk, which should be enough for some time, a rather strong CPU and a fairly large amount of RAM (did I mention the display?). So it was almost decided that the new setup would include a 27-inch iMac. The following weeks consisted of discussing the solution (thanks &lt;a href=&#34;http://twitter.com/0ktan&#34;&gt;@0ktan&lt;/a&gt; for pointing out the size of the display several times a day), calculating how to finance it, and making lists to justify not going with the Mac mini variant. After this (for me fairly normal) decision process, I was ready to order and when I was somewhat surprised by a christmas bonus, I knew it was time for a christmas present for myself. So I ordered the low end 27-inch iMac with Apple Care and the new Apple Remote. Only to get notified that it will be delivered 24th to 31st of December (not in time for christmas). The following days I read about broken displays, supply shortage, graphics card failures, but I was convinced that this couldn&#39;t happen to me and kept thinking about a name for it (really the hardest part of all). On the following Saturday I received a shipping confirmation with the 21st of December as the estimated delivery date. It goes without saying, that I was totally excited that the new machine would arrive before christmas, allthough the Apple status site still said 23rd to 29th. And then on the 18th the UPS truck finally arrived.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-screen-real-estate-paradise&#34;&gt;The screen real estate paradise&lt;/h3&gt;&#xA;&lt;p&gt;After the exciting unboxing, the setup was straight forward as usual. Entering my MobileMe credentials synchronized contacts, calendars, iDisk, and such to the new iMac. I copied my data and applications from my MacBook and the media files from the mac mini and have used the iMac since then almost exclusively (except for some trips to the couch with the MacBook).&lt;/p&gt;&#xA;&lt;p&gt;Working with the iMac is just awesome. I can now have a browser window, IDE and a terminal conveniently beneath each other without overlapping. iTunes with my whole media library loads in seconds, even when I have a virtual machine running and the whole setup isn&#39;t even that big. Since I have a rather small desktop, I was worried a bit that the iMac would look too big on it and that there wasn&#39;t enough space for books and other stuff. But despite its large screen it consumes hardly more space than the 22-inch display with the VESA mount.&lt;/p&gt;&#xA;&lt;p&gt;The mini Displayport to HDMI adapter still has to be delivered, so I don&#39;t know yet if it is irritating, if the TV is permanently connected as a secondary display. If this is the case, I will have to manually disconnect the TV when I am working on the iMac. Also because my desktop isn&#39;t that big I have to turn my head a little bit to see the edges of the screen, which can be a bit uncomfortable.&lt;/p&gt;&#xA;&lt;p&gt;Since these two things can be easily filed under first world problems, I have to say that I am totally happy with my decision and that it is (again) the best Mac I have worked on so far.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2009/12/24/first-weekend-with-endless-screen-real-estate.html" rel="alternate"></link>
    <summary type="html">&lt;h3 id=&#34;ye-olde-setup&#34;&gt;Ye olde setup&lt;/h3&gt;&#xA;&lt;p&gt;Some months ago I realized that my Mac mini, used as a </summary>
  </entry>
  <entry>
    <title>Google Reader to Instapaper bridge</title>
    <updated>2009-09-19T00:00:00Z</updated>
    <id>tag:unwiredcouch.com2009,2009-09-19:/09/19/google-reader-instapaper.html</id>
    <content type="html">&lt;h3 id=&#34;the-dilemma&#34;&gt;The dilemma&lt;/h3&gt;&#xA;&lt;p&gt;For some years now I am using &lt;a href=&#34;http://google.com/reader&#34;&gt;Google Reader&lt;/a&gt; as my reader of choice for news feeds. I still think it&#39;s the best way to get daily news (for me), although I do recognize that I don&#39;t read every feed as thoroughly as I used to anymore. I always use the starred items section as a sort of &#34;save for later&#34; storage, so I can open all the unread stories in my browser tabs and read them when I have time. This worked out ok, but in the last months I got more and more used to the &lt;a href=&#34;http://www.instapaper.com&#34;&gt;instapaper&lt;/a&gt; service, which provides a simple web frontend to save websites for later and a great &lt;a href=&#34;http://itunes.apple.com/WebObjects/MZStore.woa/wa/viewSoftware?id=284942713&amp;amp;mt=8&#34;&gt;iPhone app&lt;/a&gt;. This led to the situation, that I still starred items in Google Reader, but then had to open the pages and manually save them to instapaper.com and unstar them in Google Reader. An alternative is the builtin Google Reader option to share to instapaper, which also needs some manual actions and you still have to unstar the item afterwards.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-solution&#34;&gt;The solution&lt;/h3&gt;&#xA;&lt;p&gt;So I decided to build a script, which would run nightly on a server and pull all starred items out of Google reader and into instapaper. Since I am trying to improve my python knowledge whenever I can, I decided to build a python implementation. Since I also wanted to dig into the (unofficial) Google Reader API, I decided not to use the very good existing &lt;a href=&#34;http://code.google.com/p/pyrfeed&#34;&gt;python framework&lt;/a&gt;, but to utilize the API myself. I had already written a small &lt;a href=&#34;http://github.com/mrtazz/InstapaperLibrary&#34;&gt;instapaper library&lt;/a&gt; before, which I mainly used to save articles for later on the command line.&lt;/p&gt;&#xA;&lt;p&gt;So I sat down and started to write &lt;a href=&#34;http://github.com/mrtazz/instareader.py&#34;&gt;the bridge&lt;/a&gt;. All in all it took me a bit more than a month (due to university life, work and exams) to finally get a basic version working, which is able to retrieve starred items, save them to instapaper and then remove the star from instapaper. The script is now run every hour on a server, which is enough for my needs of instapaper being up-to-date. Also I have more choices on iPhone RSS readers with Google Reader syncing now, since Instapaper support is not a requirement for the app anymore. There are still (as always) some things to do, but at least the manual open,save,unstar actions are no more now.&lt;/p&gt;&#xA;</content>
    <link href="https://unwiredcouch.com2009/09/19/google-reader-instapaper.html" rel="alternate"></link>
    <summary type="html">&lt;h3 id=&#34;the-dilemma&#34;&gt;The dilemma&lt;/h3&gt;&#xA;&lt;p&gt;For some years now I am using &lt;a href=&#34;http://google.com/re</summary>
  </entry>
</feed>