<?xml version="1.0" encoding="utf-8"?> 
    <feed xmlns="http://www.w3.org/2005/Atom"> 
    
    <title>unwiredcouch.com</title> 
    <subtitle>unwiredcouch.com</subtitle> 
    <link href="https://unwiredcouch.com/atom.xml" rel="self" /> 
    <link href="https://unwiredcouch.com/" /> 
    <id>https://unwiredcouch.com/</id> 
    <updated>2019-10-14T17:01:39+02:00</updated> 
    <author> 
      <name>Daniel</name> 
      <email>d@unwiredcouch.com</email> 
    </author><entry> 
          <title>Pen and Paper</title> 
          <link href="https://unwiredcouch.com/2019/07/05/pen-and-paper.html" /> 
              <id>https://unwiredcouch.com/2019/07/05/pen-and-paper.html</id> 
          <updated>2019-07-05T00:00:00+02:00</updated> 
          <content type="html">&lt;p&gt;A couple of years ago I went from working in an office to working remote mostly from home. A couple of months in I realized how my productivity had dropped significantly. For years everything I had to do and most of the planning around it has lived in &lt;a href=&quot;https://www.omnigroup.com/omnifocus&quot; title=&quot;Omnifocus&quot;&gt;Omnifocus&lt;/a&gt;. I have even written &lt;a href=&quot;https://unwiredcouch.com/2014/05/13/omnifocus.html&quot; title=&quot;Omnifocus post&quot;&gt;about it before&lt;/a&gt;. For the rest of planning and notes I kept a handful of markdown files in a git repo, held together by Makefiles and &lt;a href=&quot;https://github.com/mrtazz/vim-plan&quot; title=&quot;vim-plan plugin&quot;&gt;a vim plugin&lt;/a&gt;. But now it didn’t work for me anymore. I kept opening OmniFocus just to find myself aimlessly clicking and sorting things around. I redid the layout of my perspectives again. Restructured all the GTD contexts and areas of focus. But nothing actually changed. Looking at the app it just blurred with all the other open windows. All the other apps. It became kind of meaningless. I realized with 100% of work and interactions happening on my screen now, everything felt the same to me. I was unable to focus on what I wanted to do. Planning was an app switch away from coding was an app switch away from meetings was an app switch away from my todos. There were many times where I caught myself cycling from one thing to the other a couple of times within minutes. My attention was completely shot. Additionally I had so many Omnifocus integrations set up that were pulling in my JIRA tickets, my assigned code reviews, and even emails I needed to reply to at some point. The longer I wasn’t using Omnifocus the more it got cluttered with things that needed filing. Instead of helping me get organized it did the opposite. I had over engineered Omnifocus having succumbed to the idea that I&#39;d be more productive the more I automate and fine tune it.&lt;/p&gt;
&lt;h2 id=&quot;trying-something-new-ish&quot;&gt;Trying something new(-ish)&lt;/h2&gt;
&lt;p&gt;I needed to change things up. And the solution for this couldn&#39;t be another app. It needed to be different. And it turns out this is a pretty normal thing for humans. We link memories (which things to remember to do basically are) to locations via the hippocampus.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is the reason it&#39;s important to have a designated place for each of our belongings - the hippocampus does the remembering for us if we associate an object with a particular spatial location.&lt;/p&gt;
&lt;p class=&quot;cite&quot;&gt;
&amp;mdash; &lt;cite&gt;Daniel Levitin, The Organized Mind (p. 91)&lt;/cite&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I’ve been carrying a Moleskine notebook with me since early 2008. Early on I had already used it as a todo organizer before switching to Things and eventually Omnifocus. I’ve used it on and off for random things (rarely enough for it to last 10 years). And it’s been the testing ground every time I wanted to get back to taking more analog notes. I’ve also backed the &lt;a href=&quot;https://unwiredcouch.com/2015/03/18/spark-notebook-omnifocus.html%20%22Spark%20Notebook%20post%22&quot;&gt;Spark Notebook&lt;/a&gt; on Kickstarter and used that with a lot of success for a while. So when I was looking to change things up from my digital routine I remembered having read about the &lt;a href=&quot;https://bulletjournal.com/&quot; title=&quot;Bullet Journal method&quot;&gt;Bullet Journal method&lt;/a&gt; and decided to give it a try.&lt;/p&gt;
&lt;h2 id=&quot;getting-started-with-a-bullet-journal&quot;&gt;Getting started with a Bullet Journal&lt;/h2&gt;
&lt;p&gt;For getting set up I started reading the website first and watched the canonical intro video linked from there. But being used to this elaborate GTD setup I wasn’t convinced that a minimalist way worked for me. I read a lot of fairly popular posts on getting started with bullet journaling from websites like &lt;a href=&quot;https://littlecoffeefox.com/&quot; title=&quot;Little Coffee Fox&quot;&gt;this&lt;/a&gt; and &lt;a href=&quot;https://www.tinyrayofsunshine.com&quot; title=&quot;Tiny Ray of Sunshines&quot;&gt;this one&lt;/a&gt; and a ton of other blog posts to understand how this is being used by different people. And then I bought a new notebook and some pens and started with my own.&lt;/p&gt;
&lt;p&gt;And I absolutely overdid it. I used a ton of color and differently sized pens to denote headlines, priorities, etc. I had 2 different systems (dot stickers and sticky labels) do denote important pages. And I added a ton of modules and collections like trackers for workout, meditation, water intake, and reading time. I had very elaborate monthly and weekly spreads, trying to recreate the organizational cockpit that I always wanted Omnifocus to be. I put way too many things to do in, areas of focus with color coded headings, and complicated time blocking details. My daily spread had a &lt;a href=&quot;https://medium.com/rohdesign/the-daily-plan-bar-357972361096&quot; title=&quot;Rohdesign Daily Plan bar&quot;&gt;daily plan bar&lt;/a&gt; that included all my meetings and time blocks for the day. My weekly spreads were as complicated and stuffed, at some point even including which days to take out the trash. Bringing me to up to an hour of just setting up my page to get started for the day. All to combat the feeling of not getting things done and falling of the wagon again.&lt;/p&gt;
&lt;p&gt;Of course once the initial excitement had worn off I fell back into seeing maintaining this complicated thing as a chore and neglected it. And I ran into the same problem I had with Omnifocus of having a layout that was very tuned to my workdays. On the weekend or when I was taking vacation, it wasn’t useful. And I hardly interacted with the journal. Leaving me again with the guilt of “having fallen off”. One important difference though was that on those weekend days and during time off where I couldn’t bother to get into my complicated setups, when I did use the journal it resembled a lot more the original idea of the Bullet Journal. And instead of giving up and changing back to Omnifocus, I stuck with it.&lt;/p&gt;
&lt;h2 id=&quot;what-my-bullet-journal-actually-looks-like-now&quot;&gt;What my Bullet Journal actually looks like now&lt;/h2&gt;
&lt;p&gt;One of those vacations was at the end of last year. During that time I reduced my usage of the journal to basically only a weekly spread. Mostly because there wasn&#39;t much to keep track of. And I realized it still worked for me. I still put all my todos and appointments in there. And it adapted to the difference in usage wonderfully. I was also about to start my third Bullet Journal, having journaled more than twice as much as the previous 10 years combined. I bought the official &lt;a href=&quot;https://bulletjournal.com/pages/book&quot; title=&quot;Bullet Journal Book&quot;&gt;Bullet Journal book&lt;/a&gt; to learn more about the ideas and philosophies behind the original approach given I had more belief it could work for me. And aside from all the other interesting things in the book, the thing that really changed the way I thought about it was that it&#39;s still supposed to be more like a journal than a GTD system.&lt;/p&gt;
&lt;p&gt;After finishing the book I slimmed down my Bullet Journal to the useful bare essentials. I kept the original monthly layout I had already been using but stripped down the monthly task list to a literal list instead of different areas with colored headlines. The 2 page weekly spread turned into a single page of tasks I want to get done over the course of the week. And the daily spread is no longer a plan bar for a meticulously planned out day. It now just starts with the date headline and serves 90% as a journal for recording the day rather than a pre-planned skeleton of how I think the day will go. Because one of the big reasons why I was often abandoning the journal was because they day almost never turned out as planned. Making me feel like the journal was less useful.&lt;/p&gt;
&lt;p&gt;I kept marking the future log (which for me is the combined &lt;a href=&quot;https://bulletjournal.com/blogs/bulletjournalist/future-log-inspiration%20%22Calendex%20Alistair%20Hybrid%20Future%20Log%22&quot;&gt;calendex/alistair&lt;/a&gt; method), monthly and weekly spreads, as well as important collections with dot stickers. That way I can quickly find e.g. the page with the last monthly spread if I want to look something up.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/pen-and-paper/dot-stickers.jpeg&quot; title=&quot;Dot Stickers&quot; alt=&quot;dot stickers for bookmarks&quot; /&gt;&lt;/p&gt;
&lt;p&gt;And another big insight from the book was that I’m now leaning on &lt;a href=&quot;https://bulletjournal.com/blogs/bulletjournalist/migration&quot; title=&quot;Bullet Journal Migrations&quot;&gt;migrations&lt;/a&gt; a lot more than I used to even though I don’t do daily migrations anymore. I scan the last pages for the current week in the morning for things that still need to get done and if they are a priority I move them to the current day. However that rarely happens and it mostly a measure for me to not forget about priorities. I do weekly and monthly migrations where I thoroughly go through the pages and migrate items, add additional context, put things into the future log (or the topic specific collections for things like personal, work, apartment, etc that serve as a sort of backlog). But otherwise I really just start a new headline every morning and start journaling.&lt;/p&gt;
&lt;h2 id=&quot;in-closing&quot;&gt;In Closing&lt;/h2&gt;
&lt;p&gt;Switching to paper for organizing my todos, thoughts, events, and planning things has been absolutely wonderful for my stress levels and mental health. Especially after trimming the process down to the minimum. I’m no longer stressing about the perfect setup, but use the journal in the way that makes the most sense for me in the moment. I still use a reminders list on my phone for things on the go or when I don’t have the journal with me to migrate over later. I’m much more focused and calm about organizing things when I’m able to close my laptop and just open the journal, it feels much less noisy. Using pen and paper so much every day also lead me to occasionally doodle on pages and discover my interest in drawing and art which has been another huge source of joy for me.&lt;/p&gt;
</content>
</entry>
<entry> 
          <title>Factors of Confidence</title> 
          <link href="https://unwiredcouch.com/2019/04/02/factors-of-confidence.html" /> 
              <id>https://unwiredcouch.com/2019/04/02/factors-of-confidence.html</id> 
          <updated>2019-04-02T00:00:00+02:00</updated> 
          <content type="html">&lt;p&gt;I&#39;ve been having a lot of discussions about delivery of software lately and especially about the deployment part of it. This made me think about the last couple of years of working on deployment and development tooling and the approach I take there.&lt;/p&gt;
&lt;p&gt;I&#39;ve come to view this from a perspective of formulating a hypothesis and establishing factors of confidence to confirm or refute this hypothesis. This sounds very abstract and theoretical at first. But bear with me for a moment here. The basis for all delivery is a change (or patch, diff, commit, change set, whatever you wanna call it). This change is meant to improve something. Add a feature (or establish the base for one), fix a bug, improve performance, increase visibility, or just clean up some technical debt. This means you&#39;re going to production to make the world better. However given the complex nature of the systems we deploy software to, you won&#39;t actually know if your change is a net positive until it&#39;s running in production. And even then you often only know a couple of hours or even days later. So all you have when you&#39;re in front of your editor writing some code is an idea about what will make the word better. A hypothesis.&lt;/p&gt;
&lt;p&gt;The job of a delivery pipeline now is to help you get confidence. Confidence that your hypothesis holds. Or confidence when you have to refute it. However all of the complex interactions of systems means you don’t get to have that single unified proof that your code is what you want it to be. Your ability to make a decision about your change is based on many small factors of confidence. And the delivery pipeline should give you tools along the way to acquire those factors of confidence in reasonable time and effort. It usually starts with a very quick feedback loop and something akin to a unit test. You can write them quickly and they can be verified quickly (individually that is. Running large numbers of unit tests on CI is still a not so easy problem). You then usually move on to test that are more expensive with a longer feedback loop. Like an integration test. Maybe a QA environment. A staging environment. Smoker tests in production. Canary deploys. And so on. All of those things (and this is hardly an exhaustive list) are intended to give you confidence in something. That your logic is correct, that your code works well with other API endpoints, that it interacts with other code on the site in a way that doesn’t break the whole thing, that it doesn’t put too much load on downstream systems, etc, etc. And ideally all these things in place will give you a nice set of guardrails that make deploying to production an enjoyable experience.&lt;/p&gt;
&lt;p&gt;However given these tools are merely a snapshot of your understanding of the system at the time and what confidence is needed to make a change to it, the delivery pipeline needs to be constantly maintained and re-evaluated. Maybe system growth now means that the trade off of running a large array of unit tests and the time it takes, doesn’t pay off in the confidence it provides. Or maybe it does and this means you need to think of something to make running unit tests faster. Maybe a new additional service means you now need to add a set of smoker tests. Whatever it is, the most important thing is that you know &lt;em&gt;why&lt;/em&gt; any of these tools to assert confidence are in place. &lt;em&gt;Who&lt;/em&gt; are they for and &lt;em&gt;what&lt;/em&gt; are they telling you? The last couple of years have seen the rise of a huge number of fantastic delivery systems. Often highly opinionated or infinitely configurable. Sometimes both. It’s easy to just take one of them and cargo cult what they bring with it. And if you don’t already have an established system, this is a fine approach that will certainly make you end up with a better setup than you had before. However I encourage you to look closely what your delivery pipeline is made up of. And what kind of things it gives you confidence in. Do you often see failures after deploys because of surprises in your logic? Maybe you’re missing some unit tests. Are you spending tons of time on unit tests that essentially only re-test the framework code of the tool you’re using? Maybe you don’t need those tests and can free up a lot of engineering time. Whatever it is, your delivery pipeline needs to give you confidence in changes in &lt;em&gt;your&lt;/em&gt; stack. You know best what kind of things need to go in there. And spending some time to think about that will give you a lot of insight and pay off when it comes to improving your delivery pipeline. And it’s also tons of fun!&lt;/p&gt;
&lt;p&gt;PS: I’ve had many discussions about those things with many people over the years. And they all helped me figure out how I think about delivery and make sense of my rambling thoughts. So if you&#39;ve ever chatted with me about deployment and/or delivery, I&#39;m extremely grateful you took the time and I really enjoyed our chat.&lt;/p&gt;
</content>
</entry>
<entry> 
          <title>Capacity planning for Etsy’s web and API clusters</title> 
          <link href="https://unwiredcouch.com/2018/10/23/capacity-planning-etsy.html" /> 
              <id>https://unwiredcouch.com/2018/10/23/capacity-planning-etsy.html</id> 
          <updated>2018-10-23T00:00:00+02:00</updated> 
          <content type="html">&lt;p&gt;I wrote about how we do capacity planning for our web and API clusters on Etsy&#39;s &lt;a href=&quot;https://codeascraft.com&quot;&gt;engineering blog&lt;/a&gt;. You can find the post &lt;a href=&quot;https://codeascraft.com/2018/10/23/capacity-planning-for-etsys-web-and-api-tiers/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</content>
</entry>
<entry> 
          <title>Learning to have an engineering vision</title> 
          <link href="https://unwiredcouch.com/2018/01/03/engineering-vision.html" /> 
              <id>https://unwiredcouch.com/2018/01/03/engineering-vision.html</id> 
          <updated>2018-01-03T00:00:00+01:00</updated> 
          <content type="html">&lt;p&gt;Saying that the last 18 months or so were stressful and full of changes would be a colossal understatement. Work wise I switched to a new team after over 4 years on the same team, which was then dismantled as part of a big structural reorg that was actually part 1 of 2. Part 2 consisted of a larger restructuring that meant my new team also ceased to exist in its then current form after only 10 months. These changes were incredibly important and long overdue. However after a couple of pretty stable years this also meant I had to get out of my comfort zone in a lot of new ways. On both newly created teams I was one of the more senior engineers which meant for me thinking long and hard about how I want to contribute to building up a new team and what my place should and can be there. This meant building up and getting used to new routines, schedules, way of communication and urgencies in work. All muscles I had not really needed to exercise in a while and to a large degree not ever. And besides the build up of technical knowledge about the services we were now providing as a team, the non-technical side of things was where I really grew as an engineer. Specifically the most positive impact on how I view work has been to finally get a better grasp and think hard about what vision means for an infrastructure/systems engineering team.&lt;/p&gt;
&lt;p&gt;I&#39;ve gone through the process of thinking about vision for a team before. At Etsy we use a structure called &quot;VMSO - Vision, Mission, Strategy, Objectives&quot;, to organize and structure teams and departments in what their purpose is within the company and what they contribute to the business. It draws a lot of inspiration from the ideas in this blog post by LinkedIn CEO Jeff Weiner called &lt;a href=&quot;https://www.linkedin.com/pulse/20121029044359-22330283-to-manage-hyper-growth-get-your-launch-trajectory-right&quot;&gt;&quot;From Vision to Values: The Importance of Defining Your Core&quot;&lt;/a&gt;. The rough overview is that vision is the 30 000 foot view, the high level idea on the horizon that (almost) never changes. The world we want to see exist. The mission is derived from it and describes what the team does to get towards the vision. And then it gets more concrete with strategies how to get there and concrete objectives we want to fulfill. It&#39;s not an easy process and definitely takes a whole of brainstorming, suggestions, throwing away suggestions, refining and merging ideas, and consensus building to get there.&lt;/p&gt;
&lt;p&gt;Before this season of change, on my old team, when we were tasked with creating a VMSO for ourselves we always got hung up on the vision. It was always that high level thing that never quite matched the work we were doing. We would meet once or twice and always seemed to end at the same dead ends: &quot;Our work is too multifaceted to be captured by a single statement&quot;, &quot;It&#39;s hard to explain what we do&quot;, &quot;We do anything that needs doing&quot;, &quot;We keep things running&quot;. If you&#39;re working on a general purpose infrastructure team, this might sound familiar to you. It seemed like it was just impossible to come up with a single vision for the team, so we always left it at a half baked, cheesy feeling idea. And of course at that point we didn&#39;t manage to derive a good mission from the vision either. Not to speak of strategy or objectives. I didn&#39;t feel too bad about that at the time. As we had a fairly broad vision statement, it let us basically take on anything we wanted. And to be honest, I &lt;em&gt;loved&lt;/em&gt; working on that team. Although we were always working on separate things, we were a bunch of engineers with the same mindset and approach to work. We had a great team dynamic and our team meetings were a ton of fun. I couldn&#39;t imagine working on a different team.&lt;/p&gt;
&lt;p&gt;And in the middle of this work the first part of the reorg happened and our team got dissolved. I was really upset. While I was fully onboard with the reasoning and goals of the reorg, I couldn&#39;t understand why our team got ended and most of our roadmap dropped. It felt like our work had gone completely unvalued. But then I had a long 1-on-1 with my then &lt;a href=&quot;http://twitter.com/attackgecko&quot;&gt;Engineering Director Jason Wong&lt;/a&gt;. We talked about all of it, he gave me a ton more context. And he made me understand how a team that does &quot;a little bit of everything&quot; is really hard to fit in organizationally. He asked me flat out what the purpose and vision of the team was in the org. Where was the team going? What would it look like in 2 years? And I couldn&#39;t give him a straight, simple answer. I was a very senior engineer on the team and I had no answer. This was the moment where I managed to connect (some of) the dots. And tie together our lack of a comprehensive vision to the downsides of our operating model. We ended up supporting way more things than we could, leading to long periods of maintenance work and almost none of the iterative improvements we planned for at the beginning of the year. We had no way of saying no to work because we didn&#39;t have a good reason to reject the work. We had weeks where our work summary would basically just be &quot;clean up&quot;. Which I love doing and is valuable work, but not if it takes up 90% of someone&#39;s time. We agreed on a vision that was defined by the work we were already doing and not by what we wanted the work to be.&lt;/p&gt;
&lt;p&gt;And at the time I failed to see the big downside of this: it let us take on anything we wanted. While this sounds like fun at first, it makes a lot of things really hard. We continuously worked on 6 different projects as a team of 7 engineers. There was hardly any collaboration possible and we ended up with single points of failure because single engineers would end up being the only ones knowing about a particular system. Once we had hit the limit of reports for a manager (7 at the time), we needed to hire another manager but had a really hard time figuring out how to split the team because there was no clear structure. And boy was it hard to give the elevator pitch for the team in those interviews. We were a team that was ever expanding its work areas to catch things and never managed to retract back and focus on our core. We were aware of those problems and we always thought we will figure them out with time. For the time being it felt better to keep fixing things and worry about the rest later. Succumbing to the always existing, intriguing feeling that something that you can fix needs to be fixed right now.&lt;/p&gt;
&lt;p&gt;And in the middle of 2016, all of this was suddenly gone. And after that very intense and honest 1-on-1 with Jason I felt I knew what I had to do. I joined a new team. I kept thinking about team focus and organizational structure. And when we set up to create a VMSO I went full in and went with the process. I talked a lot to &lt;a href=&quot;http://twitter.com/dbness&quot;&gt;Vanessa Hurst&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/lara_hogan&quot;&gt;Lara Hogan&lt;/a&gt;, both also Engineering Directors at the time, about VMSOs, team structure and direction. Both of them know incredibly well how to build engineering organizations and gave me so much insight and food for thought how to approach this task. I thought hard and good about what &lt;em&gt;I&lt;/em&gt; as an engineer on the team wanted the team to be. And what I don&#39;t want it to be. What were the things that I wanted this team to contribute to the business? What did I not want to bring around anymore and let stay in the past? I wanted to have a vision that I can align goals and work to that would provide focus and effectiveness for the team. And after a week or two with many, many VMSO meetings we ended up with a result that I was really happy with. It was also the first thing we delivered as a newly created team which helped immensely with team identity building. And in the following months to come I found myself often referring to the vision when the question came up of whether our team should be doing a particular bit of work or take over a certain ticket.&lt;/p&gt;
&lt;p&gt;Since then I&#39;ve also worked on the VMSO for our whole organization of Systems Engineering. And it was an even harder challenge to find something that matches the purpose of a dozen teams and gives them something to align their work to. But it was again a valuable lesson and a time spent building the structure for something I really want to be part of and make contribution to the business.&lt;/p&gt;
&lt;p&gt;These past 18 months have been an incredibly intense learning period for me. Most of the things we did on my old team were the right things to do at the time. We worked on a lot of exciting and important projects that enabled others to build on top. And we were incredibly successful. But we also missed the point where the team needed to change to a different operating model to grow with the business. To align it to where the infrastructure needed to go. I learned to not think about work on an infrastructure team as just &quot;keeping the lights on&quot;, &quot;fixing broken things&quot; or &quot;administering the machines everything else runs on&quot;. But actually take the time to think about what to really contribute to engineering. What the state is I can see on the horizon and not just the work I know needs to get done right now. The two or three things that will make a difference over a laundry list of things that would be nice to do.&lt;/p&gt;
</content>
</entry>
<entry> 
          <title>Make and Go for Fun and Profit</title> 
          <link href="https://unwiredcouch.com/2016/05/31/go-make.html" /> 
              <id>https://unwiredcouch.com/2016/05/31/go-make.html</id> 
          <updated>2016-05-31T00:00:00+02:00</updated> 
          <content type="html">&lt;p&gt;I&#39;ve been somewhat interested in Go for quite a while now. It&#39;s gotten to the point where it has replaced Ruby for me in those places where I write command line utilities which are too involved for them to make sense to be a shell script. I don&#39;t have too many opinions about the language itself, but I like the static type system and that it&#39;s a compiled language. And to be honest, the build system and how to utilize it have been the most interesting bits for me so far. One thing I especially like is the fact that go provides a bunch of tooling to do different things but how you tie them together is up to you. So this gives rise to some fun use cases for a nice Makefile.&lt;/p&gt;
&lt;h3 id=&quot;the-basics&quot;&gt;The Basics&lt;/h3&gt;
&lt;p&gt;Every project I start gets this Makefile with some basic setups and variable definitions that I always want.&lt;/p&gt;
&lt;pre class=&quot;make&quot;&gt;&lt;code&gt;export GO15VENDOREXPERIMENT = 1

# variable definitions
NAME := coolthings
DESC := a nice toolkit of helpful things
PREFIX ?= usr/local
VERSION := $(shell git describe --tags --always --dirty)
GOVERSION := $(shell go version)
BUILDTIME := $(shell date -u +&amp;quot;%Y-%m-%dT%H:%M:%SZ&amp;quot;)
BUILDDATE := $(shell date -u +&amp;quot;%B %d, %Y&amp;quot;)
BUILDER := $(shell echo &amp;quot;`git config user.name` &amp;lt;`git config user.email`&amp;gt;&amp;quot;)
PKG_RELEASE ?= 1
PROJECT_URL := &amp;quot;https://github.com/mrtazz/$(NAME)&amp;quot;
LDFLAGS := -X &amp;#39;main.version=$(VERSION)&amp;#39; \
           -X &amp;#39;main.buildTime=$(BUILDTIME)&amp;#39; \
           -X &amp;#39;main.builder=$(BUILDER)&amp;#39; \
           -X &amp;#39;main.goversion=$(GOVERSION)&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the most part this just defines a whole bunch of meta data that gets compiled into the binaries via linker flags. This is a pattern I have seen in a lot of Go projects and I really like that this is somewhat of a standard thing to do. Especially with the static nature of Go binaries, the more helpful information you can compile into the binary the better it is when you have to figure out where a binary comes from.&lt;/p&gt;
&lt;p&gt;I also always have a handful of tasks defined that are helpful for running tests and such, especially to have a uniform and documented way how they are run locally and on CI.&lt;/p&gt;
&lt;pre class=&quot;make&quot;&gt;&lt;code&gt;# development tasks
test:
    go test $$(go list ./... | grep -v /vendor/ | grep -v /cmd/)

PACKAGES := $(shell find ./* -type d | grep -v vendor)

coverage:
    @echo &amp;quot;mode: set&amp;quot; &amp;gt; cover.out
    @for package in $(PACKAGES); do \
        if ls $${package}/*.go &amp;amp;&amp;gt; /dev/null; then  \
        go test -coverprofile=$${package}/profile.out $${package}; fi; \
        if test -f $${package}/profile.out; then \
        cat $${package}/profile.out | grep -v &amp;quot;mode: set&amp;quot; &amp;gt;&amp;gt; cover.out; fi; \
    done
    @-go tool cover -html=cover.out -o cover.html

benchmark:
    @echo &amp;quot;Running tests...&amp;quot;
    @go test -bench=. $$(go list ./... | grep -v /vendor/ | grep -v /cmd/)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These make heavy use of &lt;code&gt;go list&lt;/code&gt; to determine existing packages to run tests for. The rules also exclude the vendor folder as I don&#39;t want to run those tests and the cmd folder which I will describe more in the next section.&lt;/p&gt;
&lt;h3 id=&quot;structure-for-multiple-binaries&quot;&gt;Structure for multiple binaries&lt;/h3&gt;
&lt;p&gt;Go has this defacto standard of how to structure code if your build produces multiple executables. Since your main entry point in the app is always the main package and there can only be one per directory (which is also true for any other package btw) you need to separate different executables by directory. The pattern here is basically to have a &lt;code&gt;cmd&lt;/code&gt; folder that contains subfolders for each executable which in turn just contain a &lt;code&gt;main.go&lt;/code&gt; file. This is a pretty nice pattern, once you get used to it and is a convention that lets you easily create make rules for building those executables via the make wildcarding support.&lt;/p&gt;
&lt;pre class=&quot;make&quot;&gt;&lt;code&gt;CMD_SOURCES := $(shell find cmd -name main.go)
TARGETS := $(patsubst cmd/%/main.go,%,$(CMD_SOURCES))

%: cmd/%/main.go
    go build -ldflags &amp;quot;$(LDFLAGS)&amp;quot; -o $@ $&amp;lt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This piece just finds all &lt;code&gt;main.go&lt;/code&gt; files under the cmd folder and creates targets from them located at the top level of the repo. Then there is a rule to build those targets via a rule that ties them back to the source file via wildcarding again and runs &lt;code&gt;go build&lt;/code&gt; with the linker flags from before.&lt;/p&gt;
&lt;p&gt;Of course it&#39;s good habit to provide man pages for your tools. So we can rig up a similar set of rules for building man pages for each executable:&lt;/p&gt;
&lt;pre class=&quot;make&quot;&gt;&lt;code&gt;MAN_SOURCES := $(shell find man -name &amp;quot;*.md&amp;quot;)
MAN_TARGETS := $(patsubst man/man1/%.md,%,$(MAN_SOURCES))

%.1: man/man1/%.1.md
    sed &amp;quot;s/REPLACE_DATE/$(BUILDDATE)/&amp;quot; $&amp;lt; | pandoc -s -t man -o $@

all: $(TARGETS) $(MAN_TARGETS)
.DEFAULT_GOAL:=all
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This lets us write man pages in markdown under the &lt;code&gt;man/man1/&lt;/code&gt;folder named as &lt;code&gt;${cmd}.1.md&lt;/code&gt; and again uses wildcards in make to generate them top level via an implicit rule. I also added an &lt;code&gt;all&lt;/code&gt; target there which is the default and builds all binaries and man pages.&lt;/p&gt;
&lt;p&gt;Over time I&#39;ve come to the conclusion that it&#39;s really a good practice to have your &lt;code&gt;main.go&lt;/code&gt; files be as slim as possible. Ideally all they should be concerned with is flag parsing, calling a method from your library packages, and formatting and printing the output to the terminal. Any actual logic should live in library modules somewhere else in your repo. This maintains a good code layout to extend, makes sure code is reusable, and provides good conventions for testing.&lt;/p&gt;
&lt;h3 id=&quot;installation&quot;&gt;Installation&lt;/h3&gt;
&lt;p&gt;So now that we have rules to build the binaries, we also want to be able to install them to the &lt;code&gt;PREFIX&lt;/code&gt; we have defined at the top. Go comes with an install command already (&lt;code&gt;go install&lt;/code&gt;) which will put binaries in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; but there is no need to have to rely on that. Plus on a multi user system you want to provide tools for everyone anyways. Also let&#39;s be real, &lt;code&gt;go install&lt;/code&gt; is not a replacement for a real package manager. Just because go builds are fast and produce a static binary doesn&#39;t mean it&#39;s not a good idea to be able to build packages. Plus you want your man pages to be installed with your software as well of course. So let&#39;s write some generic install commands:&lt;/p&gt;
&lt;pre class=&quot;make&quot;&gt;&lt;code&gt;INSTALLED_TARGETS = $(addprefix $(PREFIX)/bin/, $(TARGETS))
INSTALLED_MAN_TARGETS = $(addprefix $(PREFIX)/share/man/man1/, $(MAN_TARGETS))

# install tasks
$(PREFIX)/bin/%: %
    install -d $$(dirname $@)
    install -m 755 $&amp;lt; $@

$(PREFIX)/share/man/man1/%: %
    install -d $$(dirname $@)
    install -m 644 $&amp;lt; $@

install: $(INSTALLED_TARGETS) $(INSTALLED_MAN_TARGETS)

local-install:
    $(MAKE) install PREFIX=usr/local
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We&#39;re adding the &lt;code&gt;PREFIX&lt;/code&gt; to all targets and man targets here to generate the paths to install. Then we write another implicit wildcarding rule that has the original targets as dependencies and performs install commands to put them into the prefix. This is a quick and easy way to have a generic &lt;code&gt;make install&lt;/code&gt; target and also lets us easily add a local install target that we can use as a dependency for building packages later on.&lt;/p&gt;
&lt;h3 id=&quot;dependencies-oh-my&quot;&gt;Dependencies, Oh My!&lt;/h3&gt;
&lt;p&gt;If you&#39;ve spent time with Go and make before, you will maybe have noticed a flaw in the building step of the Makefile so far. To revisit, we are building binaries from the source in the cmd folder with this implicit rule.&lt;/p&gt;
&lt;pre class=&quot;make&quot;&gt;&lt;code&gt;%: cmd/%/main.go
    go build -ldflags &amp;quot;$(LDFLAGS)&amp;quot; -o $@ $&amp;lt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However this only tells make about the first level of direct dependencies for the binary to the cmd source. Chances are you are using library and vendored code in those. This means while &lt;code&gt;go build&lt;/code&gt; technically knows about all dependencies, make doesn&#39;t. And it will refuse to rebuild the binaries if something other than the cmd source changes. This is annoying but fortunately also fixable. A simple fix would be to just not have dependencies in make for the executables and mark them as &lt;code&gt;.PHONY&lt;/code&gt; so that they are always regarded out of date. This pushes all dependency resolution back to the go tool chain which is nice, but kinda defeats half of the purpose of a Makefile as it will just run all the commands all the time. To be clear, in practice this is a fine solution and the downsides are mostly academic with the speed of a usual go build.&lt;/p&gt;
&lt;p&gt;However it&#39;s fun to figure out how to make things work and while we&#39;re here already, lets utilize make to its full extent and make it aware of all dependencies. The details for the make side of things I got from &lt;a href=&quot;http://make.mad-scientist.net/papers/advanced-auto-dependency-generation/&quot;&gt;this awesome blogpost&lt;/a&gt; which gives a great overview over automatic dependency management in makefiles. So now all we need is a way to get a list of all dependencies for a go source file. And of course, &lt;code&gt;go files&lt;/code&gt; to the rescue again! As it not only lets us print packages for passing to the test runner, but also can print out all dependencies of a file. And with its &lt;code&gt;-f&lt;/code&gt; parameter it also supports basic templating for printing out the results. Utilizing that we only need to do a small amount of post processing to print it in make dependency format and we are good to go.&lt;/p&gt;
&lt;pre class=&quot;make&quot;&gt;&lt;code&gt;# source, dependency and build definitions
DEPDIR = .d
$(shell install -d $(DEPDIR))
MAKEDEPEND = echo &amp;quot;$@: $$(go list -f &amp;#39;{{ join .Deps &amp;quot;\n&amp;quot; }}&amp;#39; $&amp;lt; | awk &amp;#39;/github/ { gsub(/^github.com\/[a-z]*\/[a-z]*\//, &amp;quot;&amp;quot;); printf $$0&amp;quot;/*.go &amp;quot; }&amp;#39;)&amp;quot; &amp;gt; $(DEPDIR)/$@.d

$(DEPDIR)/%.d: ;
.PRECIOUS: $(DEPDIR)/%.d

-include $(patsubst %,$(DEPDIR)/%.d,$(TARGETS))

%: cmd/%/main.go $(DEPDIR)/%.d
    $(MAKEDEPEND)
    go build -ldflags &amp;quot;$(LDFLAGS)&amp;quot; -o $@ $&amp;lt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The makedepend command here grabs all dependencies that come from github (which was a good enough approximation for me to filter out the std lib), cuts off the project prefix and appends &lt;code&gt;/*.go&lt;/code&gt; to each dependency. With the go rules of having a package per folder, this also is pretty accurate most of the time and only occasionally serves false positives to result in a rebuild. We then adapt the implicit build rule to require the dependency file as well but also rebuild it on each build. And BOOM our Makefile knows almost perfectly a out all source dependencies.&lt;/p&gt;
&lt;h3 id=&quot;packaging-and-documentation&quot;&gt;Packaging and Documentation&lt;/h3&gt;
&lt;p&gt;I always aim for providing packages and good documentation for my Go projects. But I&#39;ve already written about those things more generally &lt;a href=&quot;https://unwiredcouch.com/2016/01/12/coding-pride.html&quot;&gt;here&lt;/a&gt;, so if you&#39;re interested in the details of it, give that blog post a read. The important part is that the Makefile also holds the logic for building docs and packages, so they can be easily triggered from CI.&lt;/p&gt;
&lt;h3 id=&quot;cleanup&quot;&gt;Cleanup&lt;/h3&gt;
&lt;p&gt;Since it&#39;s also always good to make it easy to clean up artifacts and generated intermediate and output files, all makefiles also get some clean up tasks.&lt;/p&gt;
&lt;pre class=&quot;make&quot;&gt;&lt;code&gt;# clean up tasks
clean-docs:
    rm -rf ./docs

clean-deps:
    rm -rf $(DEPDIR)

clean: clean-docs clean-deps
    rm -rf ./usr
    rm $(TARGETS)
    rm $(MAN_TARGETS)

.PHONY: all test rpm deb install local-install packages govendor coverage docs jekyll deploy-docs clean-docs clean-deps clean&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Equipped with those Make tricks I&#39;ve been having tons of fun building Go code. Some of that is surely more involved than it has to be and especially the dependency resolution stuff is very bonus round. But it&#39;s been super interesting to rig it up and I learned a lot of things about Make. And in the end that&#39;s what it&#39;s all about for me. (Besides having projects with a super nice to use structure :)&lt;/p&gt;
</content>
</entry>
<entry> 
          <title>Optimize for Mutability and the Present</title> 
          <link href="https://unwiredcouch.com/2016/05/02/mutability-present.html" /> 
              <id>https://unwiredcouch.com/2016/05/02/mutability-present.html</id> 
          <updated>2016-05-02T00:00:00+02:00</updated> 
          <content type="html">&lt;p&gt;I recently read &lt;a href=&quot;https://twitter.com/lusis&quot;&gt;John Vincent&#39;s&lt;/a&gt; very interesting and honest blog post about &lt;a href=&quot;http://blog.lusis.org/blog/2016/04/28/the-flaw-in-all-things/&quot;&gt;being paralyzed because of seeing all the flaws in systems&lt;/a&gt;. At first I decided to just put it away as it&#39;s not a problem I encounter a lot. But in the last paragraph he asked how others deal with this. And that was the point in which I started thinking about why this doesn&#39;t bother me as much. And it occupied my brain in those precious shower and dish washing moments thinking about why this - although I know the feeling well - is the case. I more or less thought about it all weekend and this is my attempt to give my perspective on it in a somewhat coherent form. I hope it&#39;s in any way helpful and you should absolutely read John&#39;s post first to understand the context of this post.&lt;/p&gt;
&lt;p&gt;The short answer is that I optimize for the present and for mutability, which in itself is probably a completely useless answer. So let me try to elaborate what I mean by this. My day job is working in infrastructure engineering, specifically on a team that works on making writing code and deploying it as much fun as possible. This means while I&#39;m technically a software engineer, the lines between software engineering and operations are blurry at best in my day to day work (which is a good thing and I very much enjoy it). I have worked on a bunch of systems, designed some of them, see almost all of them break in various ways and participate in as many architecture reviews as possible to give input on other people&#39;s system designs. The main goal of my work however is to contribute to engineering happiness. This means I&#39;m very aware of the intersection of technology and humans using it. In addition to that, working mostly on internal things means when the things I work on break, a lot of my coworkers are blocked from getting their stuff done. This can be petrifying. When I set out to write a new thing or fix up an existing one, I can test it out for my workflow but can also inevitably see how it could and will break for someone with a different workflow, editor, or set of dotfiles. And what makes it worse is that I won&#39;t notice immediately and when it breaks for someone I might be in a meeting, unable to help right away. And I really &lt;a href=&quot;https://unwiredcouch.com/2016/03/18/breaking-things.html&quot;&gt;hate breaking things&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So there I have 2 choices. Ship a thing that&#39;s gonna break in some way. Or don&#39;t ship anything. And the way I make myself be ok with shipping something that is flawed is by of course making sure I do a reasonably extensive attempt of testing it. But also make it as easy as possible to change or adapt later, to decide whether my original trade offs are still the right way to go and to rip things out if not. But not necessarily by trying to cater for all possible future use cases (the famous &quot;premature optimization&quot;) and sure as hell not by writing throw away code. Because everybody can tell you the only thing harder than building something is decommissioning it, and that goes doubly so for throw away code. How I try to achieve this is by dropping all of my context into &lt;a href=&quot;https://twitter.com/mrtazz/status/724734135831547905&quot;&gt;documentation and automation&lt;/a&gt; in some form. This means code comments. Documenting my thought process on the JIRA ticket that relates to it. Writing thorough &lt;a href=&quot;https://twitter.com/mrtazz/statuses/661618547295129600&quot;&gt;detailed commit message&lt;/a&gt; about my change. Writing unit tests that are being run on CI. A proper README. A thought through Chef recipe. A Makefile with all important tasks. A runbook. Those kinds of things. So that when someone else has to go and fix something (that could be future me or a coworker), they don&#39;t have to spend minutes to hours to get up to speed on the context, decisions, and trade-offs I had and made to understand why I opted for this solution to the problem. So I&#39;m very happy to write a 20 line commit message that links to the ticket and the CI/try run and mentions the people I consulted while working on this - even for a single line of change. I&#39;m excited to add unit tests even when I&#39;m &quot;only&quot; writing a vim plugin or a shell script. And I&#39;m excited when I get to write man pages.&lt;/p&gt;
&lt;p&gt;Because if I&#39;m honest, yes I can see how things are flawed and can break in the future. But I don&#39;t think I can accurately judge the impact of that flaw down the line. How severe will it be to reboot a bunch of things for a security update? How annoyed is the developer really gonna be about this tooling change? How pissed is my coworker gonna be to get paged for the thing I built? But also, what is someone gonna be able to build on top of or inspired by this? What am I free to do until the flaw really becomes a problem? And is my coworker gonna be ok with with all of this as they have learned something from it and had all the context available to fix it and make it better? Because the one thing I do know about current me is that there are gonna flaws in any solution. And I know one thing for sure about future me or my coworker encountering the flaw in the system: If they have the same context as I had when I deployed it, they are gonna be a lot happier, more empathetic as to why I made those choices, and be able to more quickly build on the existing solution. And if documentation, automation, and tests are in place it looks a lot less like some thrown together piece of code but more like the thought through project and honest attempt to fix a problem that had to make trade offs that it is. And up until now they trade offs were good ones and enabled a lot of other things that were impossible to tell before the fact.&lt;/p&gt;
&lt;p&gt;So I guess the way I work through those feelings of overwhelming and paralysis is by making sure I can be damn &lt;a href=&quot;https://unwiredcouch.com/2016/01/12/coding-pride.html&quot;&gt;proud&lt;/a&gt; of the work I&#39;m doing in the present. And make sure it&#39;s as easily adaptable as possible when the future comes around.&lt;/p&gt;
&lt;p&gt;Of course this is just my personal way of dealing with it. And it is highly influenced by my character and the team I get to work with. And I hope I didn&#39;t deviate too much from John&#39;s original point in the blog post and that this post makes sense in some way. None of this actually makes the reality of flaws and dread of having to deal with them go away. But it gives me an anchor in the present and something to focus on to get things done. And a way to feel more prepared when the flaws &lt;em&gt;do&lt;/em&gt; surface. Because I&#39;d like to think of change as inevitable but also a good thing. Change you&#39;re not prepared for however is when it feels most like a flaw.&lt;/p&gt;
</content>
</entry>
<entry> 
          <title>Bash Unit Testing from First Principles</title> 
          <link href="https://unwiredcouch.com/2016/04/13/bash-unit-testing-101.html" /> 
              <id>https://unwiredcouch.com/2016/04/13/bash-unit-testing-101.html</id> 
          <updated>2016-04-13T00:00:00+02:00</updated> 
          <content type="html">&lt;p&gt;In the last couple of months I&#39;ve done a foray into unit testing the shell scripts I write. This is mostly a conglomerate of things I&#39;ve learned and a talk I&#39;ve given to our ops team about unit testing 101 for infrastructure tools last year.&lt;/p&gt;
&lt;p&gt;In August last year I decided to finally scratch an itch I had for quite a while. The details aren&#39;t super important here, just that it&#39;s a shell script and that there was no sort of of pressure around it which made me take the time to write unit tests for it. That meant for me researching what existed in terms of frameworks and how people are generally approaching this. And unsurprisingly I found a number of ready to use unit testing frameworks, most of them modeled after the familiar patterns you can find in test frameworks for other languages. However I was also curious what a minimal testing framework for bash would look like. After all, all my script would be doing is create some files and directories on disk with some specific content. So I could verify it all with &lt;code&gt;grep&lt;/code&gt; and &lt;code&gt;test&lt;/code&gt;. So I decided to also use this side project to try and write my own minimal bash unit test setup. And while I mostly ended up doing integration testing for the script, it still made me think quite a bit about the basics of unit testing.&lt;/p&gt;
&lt;h3 id=&quot;unit-testing-101&quot;&gt;Unit Testing 101&lt;/h3&gt;
&lt;p&gt;One of the first questions I always get when someone hasn&#39;t really come across a lot of &lt;a href=&quot;https://en.wikipedia.org/wiki/Unit_testing&quot;&gt;unit testing&lt;/a&gt; is &quot;what is a unit?&quot;. And while technically you can probably argue for a unit being a lot of things, the most helpful one I&#39;ve always found to be:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a unit is a function&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This simultaneously gives a very concrete answer and also a starting point of what to do. When writing unit tests, start testing functions. This of course occasionally leads to the next question &quot;what is a function?&quot; and more often to the debate of how to make a function testable. For the first question I&#39;ve again found this very reductionist answer to be the most helpful:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a function is a reusable piece of code that turns defined input into defined output&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is somewhat close to what you learn in school about functions in math and has helped me a lot with how I think about writing code.&lt;/p&gt;
&lt;h3 id=&quot;writing-our-first-tested-bash-code&quot;&gt;Writing our first tested Bash code&lt;/h3&gt;
&lt;p&gt;Now with those definitions out of the way, there&#39;s a plan on how to make a shell script unit testable:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Refactor your code into functions&lt;/li&gt;
&lt;li&gt;Write tests for those functions&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There&#39;s a bit of a lesson to learn about &lt;a href=&quot;https://en.wikipedia.org/wiki/Side_effect_(computer_science)&quot;&gt;side effect free functions&lt;/a&gt; but we can short circuit that by saying the only things your functions should rely on are variables passed into it. And it should always echo its results to STDOUT. This heavily reduces the possibility for side effects in bash functions but also limits the functions that absolutely have to do something other than just taking input and printing results to an absolute minimum. Your logic can live in the other functions most of the time. And those are the ones you can unit test. So now let&#39;s write some functions and tests for them.&lt;/p&gt;
&lt;p&gt;Let&#39;s say we want a function to output the number of characters in a string. It could look something like this:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb1&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-1&quot; title=&quot;1&quot;&gt;&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt; num_chars&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;{&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-2&quot; title=&quot;2&quot;&gt;  &lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${1}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;wc&lt;/span&gt; -c&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-3&quot; title=&quot;3&quot;&gt;&lt;span class=&quot;kw&quot;&gt;}&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It&#39;s a very contrived example and you&#39;re basically testing that &lt;code&gt;wc&lt;/code&gt; works correctly. But it&#39;s a useful example here to show some things. Notice how the function only acts on variables passed into it and prints the result to STDOUT.&lt;/p&gt;
&lt;p&gt;Now let&#39;s write a unit test for it.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb2&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-1&quot; title=&quot;1&quot;&gt;&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt; test_num_chars&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;{&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-2&quot; title=&quot;2&quot;&gt;  &lt;span class=&quot;bu&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;res=$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;num_chars&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-3&quot; title=&quot;3&quot;&gt;  &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;bu&quot;&gt; [&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;${res}&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-ne&lt;/span&gt; 3&lt;span class=&quot;bu&quot;&gt; ]&lt;/span&gt;; &lt;span class=&quot;kw&quot;&gt;then&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-4&quot; title=&quot;4&quot;&gt;    &lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;failed to assert that &lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${res}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt; is 3&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-5&quot; title=&quot;5&quot;&gt;  &lt;span class=&quot;kw&quot;&gt;fi&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-6&quot; title=&quot;6&quot;&gt;&lt;span class=&quot;kw&quot;&gt;}&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And that&#39;s it. That&#39;s all you really need to do to write a simple unit test in bash.&lt;/p&gt;
&lt;p&gt;Of course adding more tests now generates a lot of repetitive work. So we can write a helper function to do the assertion part of the test.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb3&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;a class=&quot;sourceLine&quot; id=&quot;cb3-1&quot; title=&quot;1&quot;&gt;&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt; assert&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;{&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb3-2&quot; title=&quot;2&quot;&gt; &lt;span class=&quot;bu&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${1}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb3-3&quot; title=&quot;3&quot;&gt; &lt;span class=&quot;kw&quot;&gt;if [[&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;$?&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-ne&lt;/span&gt; 0&lt;span class=&quot;kw&quot;&gt; ]]&lt;/span&gt;; &lt;span class=&quot;kw&quot;&gt;then&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb3-4&quot; title=&quot;4&quot;&gt;   &lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${FUNCNAME[1]}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;: failed&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb3-5&quot; title=&quot;5&quot;&gt; &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb3-6&quot; title=&quot;6&quot;&gt;   &lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${FUNCNAME[1]}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;: passed&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb3-7&quot; title=&quot;7&quot;&gt; &lt;span class=&quot;kw&quot;&gt;fi&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb3-8&quot; title=&quot;8&quot;&gt;&lt;span class=&quot;kw&quot;&gt;}&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This helper function takes an argument which is a statement to evaluate. And depending on whether the eval exits with 0 or not, the test is regarded as passing or failing. It then prints out the result accordingly. &lt;code&gt;FUNCNAME&lt;/code&gt; in bash is an array that holds the current execution call stack. And thus the first entry in it is the current function and the next one is the calling function. This gives us a nice way to determine which test is being executed and make it part of the output message.&lt;/p&gt;
&lt;p&gt;And with this helper function in place, our test now looks like this.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb4&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;a class=&quot;sourceLine&quot; id=&quot;cb4-1&quot; title=&quot;1&quot;&gt;&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt; test_num_chars&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;{&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb4-2&quot; title=&quot;2&quot;&gt;  &lt;span class=&quot;bu&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;res=$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;num_chars&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb4-3&quot; title=&quot;3&quot;&gt;  &lt;span class=&quot;ex&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;[ &lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${res}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt; -ne 3 ]&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb4-4&quot; title=&quot;4&quot;&gt;&lt;span class=&quot;kw&quot;&gt;}&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we can already define a couple of tests and run them by calling the functions we defined. However that also gets very repetitive fast and you always have to remember to actually call the function when you define a new test. So let&#39;s also write a helper function to do this for us.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb5&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;a class=&quot;sourceLine&quot; id=&quot;cb5-1&quot; title=&quot;1&quot;&gt;&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt; run_test_suite&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;{&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb5-2&quot; title=&quot;2&quot;&gt;  &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;ex&quot;&gt;testcase&lt;/span&gt; in &lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;bu&quot;&gt;declare&lt;/span&gt; -f &lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;grep&lt;/span&gt; -o &lt;span class=&quot;st&quot;&gt;&amp;quot;^test[a-zA-Z_]*&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;do&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb5-3&quot; title=&quot;3&quot;&gt;    &lt;span class=&quot;va&quot;&gt;${testcase}&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb5-4&quot; title=&quot;4&quot;&gt;  &lt;span class=&quot;kw&quot;&gt;done&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb5-5&quot; title=&quot;5&quot;&gt;&lt;span class=&quot;kw&quot;&gt;}&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This helper gets all the currently declared functions (via &lt;code&gt;declare -f&lt;/code&gt;), looks for the ones starting with &quot;test&quot;, and then simply executes them.&lt;/p&gt;
&lt;p&gt;Now all you have to do is call &lt;code&gt;run_test_suite&lt;/code&gt; at the end of your file and all new test functions are automatically picked up as long as they start with &quot;test&quot;.&lt;/p&gt;
&lt;h3 id=&quot;fixtures-for-tests&quot;&gt;Fixtures for Tests&lt;/h3&gt;
&lt;p&gt;Now a lot of times in shell scripts you actually want to interact with files on the file system. And it&#39;s not really feasible to always have everything just be variables to be passed in. In this case you can adapt your script by setting the base of where the files are you want to interact with. Something like this:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb6&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;a class=&quot;sourceLine&quot; id=&quot;cb6-1&quot; title=&quot;1&quot;&gt;&lt;span class=&quot;va&quot;&gt;FILEBASE=${FILEBASE:-&lt;/span&gt;/usr/local/foo&lt;span class=&quot;va&quot;&gt;}&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb6-2&quot; title=&quot;2&quot;&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb6-3&quot; title=&quot;3&quot;&gt;&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt; list_files_with_a&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;{&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb6-4&quot; title=&quot;4&quot;&gt;  &lt;span class=&quot;fu&quot;&gt;ls&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${FILEBASE}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;/a*&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb6-5&quot; title=&quot;5&quot;&gt;&lt;span class=&quot;kw&quot;&gt;}&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you can set the variable in your test suite before you source your shell script with the functions to test. That way &lt;code&gt;FILEBASE&lt;/code&gt; will already be set and the functions use it as their base. If you know create a directory for those fixtures in your tests directory, you can easily mock out file system details in a controlled way and test for them.&lt;/p&gt;
&lt;h3 id=&quot;dependency-injection-in-bash&quot;&gt;Dependency Injection in Bash&lt;/h3&gt;
&lt;p&gt;One of the most important things for me to get better at unit testing in general was understanding &lt;a href=&quot;https://en.wikipedia.org/wiki/Dependency_injection&quot;&gt;dependency injection&lt;/a&gt;. Writing code in a at that would let me completely drive function behavior based solely on what I&#39;m passing in. And if I have to call an external resource make it so I can pass in the expected return value and only if it&#39;s not set, call the external resource. A simple example could look like this:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb7&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;a class=&quot;sourceLine&quot; id=&quot;cb7-1&quot; title=&quot;1&quot;&gt;&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt; get_url&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;{&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb7-2&quot; title=&quot;2&quot;&gt;  &lt;span class=&quot;bu&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;url=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${1}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb7-3&quot; title=&quot;3&quot;&gt;  &lt;span class=&quot;bu&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;res=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${2}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb7-4&quot; title=&quot;4&quot;&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb7-5&quot; title=&quot;5&quot;&gt;  &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;bu&quot;&gt; [&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-z&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${res}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;]; then&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb7-6&quot; title=&quot;6&quot;&gt;    res=&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;curl&lt;/span&gt; -s &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${url}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb7-7&quot; title=&quot;7&quot;&gt;  fi&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb7-8&quot; title=&quot;8&quot;&gt;}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you can use this function as you would normally do with &lt;code&gt;&#39;get_url &quot;https://unwiredcouch.com&quot;&lt;/code&gt;. However in tests you can also pass in a second argument which will be used as a locked out response instead of actually curl-ing the URL.&lt;/p&gt;
&lt;h3 id=&quot;wrapping-up&quot;&gt;Wrapping up&lt;/h3&gt;
&lt;p&gt;In this short set of examples I hope it got somewhat clear that it can be straightforward to write a quick unit testing setup for shell scripts from built in functionality and start writing tests. I&#39;ve also shown some techniques to write more testable bash to begin with. If you&#39;re interested in reusing the code if pushed the (slightly more improved) version of this I use to &lt;a href=&quot;https://github.com/mrtazz/minibashtest&quot;&gt;GitHub&lt;/a&gt;. It provides nicer output, more details and properly returns a non-zero exit code if something failed, so you can run it on CI. If you want more functionality or more advanced testing support, I&#39;ve listed some alternatives in the &lt;a href=&quot;https://github.com/mrtazz/minibashtest#advanced-testing&quot;&gt;README&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And on a slightly related note, you should start using &lt;a href=&quot;http://www.shellcheck.net/&quot;&gt;shellcheck&lt;/a&gt; when writing bash. It&#39;s such an awesome way to get feedback about how to write better shell scripts and I&#39;ve learned tons already just from the errors, warnings, and suggestions popping up in my VIM quickfix list.&lt;/p&gt;
&lt;p&gt;But the most important part is that testing isn&#39;t magic and doesn&#39;t have to be complicated. You can get started immediately with just the basics of any language. And especially starting to write tests for shell scripts is lots of fun.&lt;/p&gt;
</content>
</entry>
<entry> 
          <title>I don't like Breaking Things</title> 
          <link href="https://unwiredcouch.com/2016/03/18/breaking-things.html" /> 
              <id>https://unwiredcouch.com/2016/03/18/breaking-things.html</id> 
          <updated>2016-03-18T00:00:00+01:00</updated> 
          <content type="html">&lt;p&gt;I don&#39;t like breaking things. I never have. I hate it. When I was a kid and we got our first computer I was completely &lt;a href=&quot;https://twitter.com/mrtazz/statuses/611190610964430848&quot;&gt;afraid of breaking it&lt;/a&gt;. It was a super expensive item at the time and I had no idea how it worked. And I didn&#39;t know if I would completely break it and we didn&#39;t really have the money to get a new one if I did. Sure I was curious and I was fascinated by it. I wanted to do cool things on this computer. But I didn&#39;t want to break it. My sister was also using it and playing games on there and I didn&#39;t have the hubris that I definitely would be able to put it back together if I broke it. Looking at the trade-off between probably learning something but also ruining my sister&#39;s day it just wasn&#39;t worth it. It wasn&#39;t that I didn&#39;t want to know how it worked, it was &lt;a href=&quot;https://twitter.com/mrtazz/statuses/611190760734650368&quot;&gt;about respect&lt;/a&gt;. And it&#39;s not like I never broke the computer or anything on it. But I never approached it lightly and was very uncomfortable when it happened. And I sure wasn&#39;t proud of it.&lt;/p&gt;
&lt;p&gt;Fast forward 25 years or so I have gone to a bunch of LAN parties as a kid, went to university to study computers and eventually got a master&#39;s degree in computer science. I&#39;m running &lt;a href=&quot;https://unwiredcouch.com/2013/10/30/uncloud-your-life.html&quot;&gt;most of my own infrastructure&lt;/a&gt;, have built my own home router, had DNS servers from a Dutch ISP take zone transfers from a &lt;a href=&quot;https://www.flickr.com/photos/mrtazz/214028839/in/album-72157594235164764/&quot;&gt;computer running in a camper van toilet&lt;/a&gt;, and upgraded PHP on a big e-commerce website without downtime. It&#39;s fair to say I&#39;ve learned a couple of things and know my way around computers most of the time. And yet I am still deeply uncomfortable breaking things.&lt;/p&gt;
&lt;h3 id=&quot;whats-wrong-with-breaking-things&quot;&gt;What&#39;s wrong with breaking things?&lt;/h3&gt;
&lt;p&gt;Ironically I now work in an industry that basically worships breaking things. From famous company mottos like &quot;move fast and break things&quot; to phrases that get quoted out of context like &quot;ask for forgiveness, not permission&quot; everybody seems to love being able to break stuff. What it doesn&#39;t take into account is that breaking things doesn&#39;t happen in a vacuum. Your actions always impact others. Even if you&#39;re on-call, the nature of our complex systems means that nobody has a perfect overview over all interactions. And nobody can be sure they will be the only one to get paged and not someone else downstream who is just sitting down to eat with their family. And claiming you can is in my opinion more an unhealthy sign of hubris than healthy engineering. More likely than not it&#39;s gonna ruin someone else&#39;s day.&lt;/p&gt;
&lt;p&gt;In addition the romantic picture of the engineer who is not afraid of breaking things and thus disrupting whole industries on the way is not an evenly distributed one. As &lt;a href=&quot;https://twitter.com/katelosse&quot;&gt;Kate Losse&lt;/a&gt; already wrote in &lt;a href=&quot;https://medium.com/@katelosse/the-unbearable-whiteness-of-breaking-things-521cb394fda2#.pujsyenre&quot;&gt;&quot;the unbearable whiteness of breaking things&quot;&lt;/a&gt; it&#39;s usually just the white men again who are able to get away with it. For everyone else this is likely gonna end less well.&lt;/p&gt;
&lt;p&gt;It&#39;s also a very unhealthy and non-collaborative way of approaching things. It assumes a very negative default instead of working together. And it keeps reinforcing a stereotype that only works because there&#39;s a team of people picking up the pieces once the magic disruptive engineer is done.&lt;/p&gt;
&lt;h3 id=&quot;but-its-the-only-way-to-learn&quot;&gt;But it&#39;s the only way to learn&lt;/h3&gt;
&lt;p&gt;Now you might say &quot;Hold up there. Breaking things is the only way to learn. You don&#39;t know a technology until you&#39;ve seen it break.&quot; And I partly agree with you there. However there is a big difference between doing gamedays where things are turned off and shut down in a controlled environment, where everybody got a heads up this is going on, and systems are observed as a team to learn how they behave. This is a great way to learn about technology. And I encourage everyone to do this. Equally if things &lt;em&gt;do&lt;/em&gt; break it&#39;s paramount to investigate those incidents in a blameless way to maximize the things to learn from it.&lt;/p&gt;
&lt;p&gt;However: Just testing in prod. Not bothering to write unit tests. Not going through staging before going to prod. Rolling out a change to all servers at once just to save some time. Those are the things no one learns a lot from. Other than the fact that you can quickly make a day awful for a bunch of people. And that you might be a shitty coworker.&lt;/p&gt;
&lt;p&gt;Let me be very explicit. I don&#39;t think you can &lt;em&gt;prevent&lt;/em&gt; every failure from happening. I don&#39;t think people should be punished if something breaks during their daily work. Things break. There&#39;s nothing you can do about that. What I don&#39;t condone is approaching everything with the attitude that it&#39;s ok to actively break things. That it should be the default. That your need of changing something is more important than someone else&#39;s need of not being interrupted. That it&#39;s ok to lean all the way towards efficiency and away from thoroughness. This is not disruption it&#39;s just lack of empathy. The default should always be to try and not break anything. There should be a way to make it as easy as possible to catch errors early on. To test things before they go to prod. To get confidence in something without disrupting someone else&#39;s day. And if there isn&#39;t, maybe this is something to spend time on making better first. It beats breaking things by a long shot. And is actually something to be proud of.&lt;/p&gt;
</content>
</entry>
<entry> 
          <title>Take Pride in Your Code</title> 
          <link href="https://unwiredcouch.com/2016/01/12/coding-pride.html" /> 
              <id>https://unwiredcouch.com/2016/01/12/coding-pride.html</id> 
          <updated>2016-01-12T00:00:00+01:00</updated> 
          <content type="html">&lt;p&gt;If you&#39;re working as a software engineer, you have very likely already heard about &lt;a href=&quot;https://en.wikipedia.org/wiki/Egoless_programming&quot;&gt;&#39;egoless programming&#39;&lt;/a&gt;. The notion that you should detach your code from your ego. That criticizing your code is not a personal attack and that at some point your code is going to get deleted. Maybe you have even gone as far as seeing a lot of your work as &quot;throw away code&quot;, because most things are supposed to help you in the moment and not last forever. And these are all good things to learn and internalize. And definitely traits every programmer should have. However as I &lt;a href=&quot;https://twitter.com/mrtazz/status/674229082389938176&quot;&gt;tweeted some weeks ago&lt;/a&gt;, I&#39;m convinced the biggest trick the devil ever pulled there is convincing everyone you shouldn&#39;t take pride in your code. Which so often leads to half finished proof of concepts stuffed into a git repo. Repositories whose README might as well just say &quot;works for me&quot;. And of course most of the time there aren&#39;t any tests, so when you want to make things better, you have no idea where to start. And often enough the justification is just something like &quot;I needed this code and maybe it&#39;s useful to someone else&quot; or &quot;it&#39;s pretty simple, it would have taken me longer to write tests than the actual code&quot;.&lt;/p&gt;
&lt;p&gt;And I think this doesn&#39;t have to be. All of this talk about egoless programming and throwaway code doesn&#39;t mean you can&#39;t take pride in what you create. As a programmer (and that includes ops people, security engineers, designers, etc - if you commit to a repo, you&#39;re a programmer; don&#39;t let anyone take this away from you) you now have access to a myriad of wonderful tools and services that make it &lt;a href=&quot;https://twitter.com/mrtazz/status/673585181001928704&quot;&gt;so much fun to write and use software&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;the-readme&quot;&gt;The README&lt;/h3&gt;
&lt;p&gt;I almost feel like this goes without saying, but you should take some time to write a proper README. It might take 15 or 30 minutes for you to write it. But if 2 other people don&#39;t have to spend 10-20 minutes figuring out how your project is supposed to be used or if it even solves their problem, it has already saved time. The usual things like usage examples and installation instructions should go in there. Plus as you probably know, GitHub shows READMEs very prominently in a nicely rendered way. So your project already feels a lot nicer to use.&lt;/p&gt;
&lt;p&gt;And while you&#39;re there, also create a &lt;code&gt;CONTRIBUTING.md&lt;/code&gt;. GitHub will show it whenever someone is creating a pull request. So you can put some information in there how you would like to receive contributions which can act as some helpful guidelines and make it a lot less scary and awkward to contribute.&lt;/p&gt;
&lt;h3 id=&quot;unit-tests-and-code-coverage&quot;&gt;Unit Tests and Code Coverage&lt;/h3&gt;
&lt;p&gt;It&#39;s &lt;a href=&quot;https://twitter.com/mrtazz/statuses/665167264971415552&quot;&gt;no&lt;/a&gt; &lt;a href=&quot;https://twitter.com/mrtazz/statuses/667097579465875456&quot;&gt;secret&lt;/a&gt; that I&#39;m a fan of writing tests. And it has really become more fun over the last years as frameworks and best practices have improved. In basically all languages there exists now at least one unit testing framework that is easy to use. Some languages even come with one in their standard library. So there is no real reason to not write tests. After all you are already testing your changes manually. Why not have the computer do the tedious work? If you&#39;re looking for some introductory material on testing, we have open sourced our &lt;a href=&quot;https://codeascraft.com/2014/08/20/teaching-testing-our-testing-101-materials/&quot;&gt;Testing 101&lt;/a&gt; material we use at Etsy to teach testing. The point here is not that you will never have bugs in your code because you write tests. You are gonna reduce the number of bugs for sure. But more importantly it provides &lt;em&gt;some&lt;/em&gt; confidence factors for contribution and sets a visible expectation of what things are being automatically tested. Beyond that it provides example code for how to use your code and codifies the intent you had while writing the original functions. It also automatically serves as a first client for your API outside of the intended use case the code was written for. Thus often uncovering a good chunk of design problems.&lt;/p&gt;
&lt;p&gt;And while you&#39;re at it, add code coverage as well. Coverage is one of those tools that most people either love or hate. But the main point for me is that it sets expectations for which parts of your code are regularly exercised through tests. Not more not less. It&#39;s also not a simple way to make sure you never have bugs. It can&#39;t, as it&#39;s a tool that is concerned with syntax and not semantics of your code. But what it can do is make you think about code paths more explicitly. And through that make you think more about how to test things. And also add instructions about how to run the tests into the &lt;code&gt;CONTRIBUTING.md&lt;/code&gt; file so prospective contributors don&#39;t have to guess or search.&lt;/p&gt;
&lt;h3 id=&quot;continuous-integration&quot;&gt;Continuous Integration&lt;/h3&gt;
&lt;p&gt;Once you have tests, the next logical step is to run them on a continuous integration service. I love &lt;a href=&quot;https://travis-ci.org&quot;&gt;Travis CI&lt;/a&gt; for this but there are many others out there. Most services now support GitHub pull request status updates which makes it so much less work to maintain external contributions to your project as you&#39;ll immediately see whether or not the pull request passes tests. But the most important bit about hooking up a CI system to run your tests are the fact that you&#39;ll know it works somewhere else besides your laptop. Plus it gives you a platform to trigger many other useful things (which I will talk about in a bit) after your tests have successfully run. And for that you can even just use the Jenkins setup you probably already have at work or any other CI setup really.&lt;/p&gt;
&lt;h3 id=&quot;code-style-and-static-analysis&quot;&gt;Code style and Static Analysis&lt;/h3&gt;
&lt;p&gt;Another thing I really enjoy is the renewed rise of static code analysis tools. And I&#39;ll just throw code style checkers in that same bucket. I&#39;ve met quite a lot of people who hate coding style checkers. The arguments usually go like this: &quot;if you can&#39;t read an if statement with a missing space before the curly brace I don&#39;t want you to write production code anyways&quot;. It&#39;s amazing how many people have strong opinions on things they claim to not matter. The point here is not so much the correct way of writing code but rather a consistent way. Chances are your code is being read by a good number of people, depending on how important/popular it is. Having a consistent style makes it easier to read. Code without style guidelines can be like reading a book where every page was printed in a different font. It doesn&#39;t matter for functionality but it would be a lot more annoying to read. Plus there is literally almost no overhead. Most languages have editor plugins now that will format text for you, some languages even come with tooling. But what it shows is that you care about this code to be readable and accessible. And that you have an easy way of making these coding styles visible and applicable. Static analysis is usually a less contestant topic. There are usually a lot of things that aren&#39;t immediate problems but are helpful fixes. And it&#39;s as well a sign of you caring about the quality of your code.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://codeclimate.com&quot;&gt;Codeclimate&lt;/a&gt; is a wonderful service I use to do this. It has static analysis plugins for a lot of languages and is super easy to set up. It integrates with the Github status API and shows changes for every commit and pull request. That way you can have a computer enforce things like indents, formatting, and problems that a static analyzer can find and you can concentrate on the logic and spirit of the change.&lt;/p&gt;
&lt;h3 id=&quot;packaging-and-deployment&quot;&gt;Packaging and Deployment&lt;/h3&gt;
&lt;p&gt;These are topics very dear to my heart. A good packaging and deployment setup makes the user experience of software so much better. Not having to think about where to copy that one file, no need to curlbash some weird script, having things come from the package manager you already use. All those things make it a wonderful experience to get started on a piece of software. And the state of things there also only has gotten better over the years. A lot of the language specific package managers now have nice tooling around creating and uploading install packages for their platform. Some like &lt;a href=&quot;https://packagist.org/&quot;&gt;packagist&lt;/a&gt; even go so far as to just fetch things for you from GitHub and create releases on tags automatically. There is literally no reason to not have your PHP project on there. But even ruby gems and Python modules you can upload easily in an automatic way from your CI system. Travis CI has a whole section on deployments and integrations with most of the popular services. So do other CI platforms. &lt;a href=&quot;https://github.com/jordansissel/fpm&quot;&gt;fpm&lt;/a&gt; has made it ridiculously easy to build packages for Linux. And with &lt;a href=&quot;https://packagecloud.io/&quot;&gt;packagecloud&lt;/a&gt; you can host them in an amazingly accessible and user friendly way. You can even have your packages built and uploaded from your CI system as well with something like this:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb1&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-1&quot; title=&quot;1&quot;&gt;&lt;span class=&quot;va&quot;&gt;NAME=&lt;/span&gt;restclient-cpp&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-2&quot; title=&quot;2&quot;&gt;&lt;span class=&quot;ex&quot;&gt;VERSION&lt;/span&gt; = &lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;shell&lt;/span&gt; git describe --tags --always --dirty&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-3&quot; title=&quot;3&quot;&gt;&lt;span class=&quot;ex&quot;&gt;BUILDER&lt;/span&gt; = &lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;shell&lt;/span&gt; echo &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; config user.name&lt;span class=&quot;kw&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;st&quot;&gt; &amp;lt;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; config user.email&lt;span class=&quot;kw&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-4&quot; title=&quot;4&quot;&gt;&lt;span class=&quot;ex&quot;&gt;PKG_RELEASE&lt;/span&gt; ?= 1&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-5&quot; title=&quot;5&quot;&gt;&lt;span class=&quot;va&quot;&gt;PROJECT_URL=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;https://github.com/mrtazz/&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;NAME&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-6&quot; title=&quot;6&quot;&gt;&lt;span class=&quot;va&quot;&gt;FPM_FLAGS=&lt;/span&gt; &lt;span class=&quot;ex&quot;&gt;--name&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;NAME&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt; --version &lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;VERSION&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt; --iteration &lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;PKG_RELEASE&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt; \&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-7&quot; title=&quot;7&quot;&gt;           --epoch 1 --license MIT --maintainer &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;BUILDER&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-8&quot; title=&quot;8&quot;&gt;           &lt;span class=&quot;ex&quot;&gt;--url&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;PROJECT_URL&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt; --vendor mrtazz \&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-9&quot; title=&quot;9&quot;&gt;           --description &lt;span class=&quot;st&quot;&gt;&amp;quot;C++ client for making HTTP/REST requests&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-10&quot; title=&quot;10&quot;&gt;           &lt;span class=&quot;ex&quot;&gt;--depends&lt;/span&gt; curl usr&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-11&quot; title=&quot;11&quot;&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-12&quot; title=&quot;12&quot;&gt;&lt;span class=&quot;co&quot;&gt;# build rpm and deb&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-13&quot; title=&quot;13&quot;&gt;&lt;span class=&quot;ex&quot;&gt;fpm&lt;/span&gt; -t rpm -s dir &lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;FPM_FLAGS&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-14&quot; title=&quot;14&quot;&gt;&lt;span class=&quot;ex&quot;&gt;fpm&lt;/span&gt; -t deb -s dir &lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;FPM_FLAGS&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-15&quot; title=&quot;15&quot;&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-16&quot; title=&quot;16&quot;&gt;&lt;span class=&quot;co&quot;&gt;# deploy to package cloud&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-17&quot; title=&quot;17&quot;&gt;&lt;span class=&quot;ex&quot;&gt;package_cloud&lt;/span&gt; push mrtazz/&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;NAME&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;/el/7 *.rpm&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-18&quot; title=&quot;18&quot;&gt;&lt;span class=&quot;ex&quot;&gt;package_cloud&lt;/span&gt; push mrtazz/&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;NAME&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;/debian/wheezy *.deb&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb1-19&quot; title=&quot;19&quot;&gt;&lt;span class=&quot;ex&quot;&gt;package_cloud&lt;/span&gt; push mrtazz/&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;NAME&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;/ubuntu/trusty *.deb&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or use their integrated &lt;a href=&quot;https://docs.travis-ci.com/user/deployment/packagecloud&quot;&gt;deployment provider&lt;/a&gt; which his even less setup work.&lt;/p&gt;
&lt;h3 id=&quot;documentation-deploy&quot;&gt;Documentation Deploy&lt;/h3&gt;
&lt;p&gt;And speaking of automatic build and deploy. The same goes for documentation. One of the most genius features of GitHub in my mind is the fact that every repository can have a &lt;code&gt;gh-pages&lt;/code&gt; branch whose contents are getting published as a website under &lt;code&gt;http://username.github.io/reponame&lt;/code&gt;. This makes it extremely easy to host a documentation page for your project. And with GitHub&#39;s CNAME support you can even have a custom domain for your project point to it. The fact that it&#39;s just another branch in your repository means that you can easily automate the deployment of docs alongside your code for example from (you probably guessed it by now ) your CI system. Thanks to GitHub pages this is as easy as:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb2&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-1&quot; title=&quot;1&quot;&gt;&lt;span class=&quot;co&quot;&gt;# generate docs&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-2&quot; title=&quot;2&quot;&gt;&lt;span class=&quot;fu&quot;&gt;install&lt;/span&gt; -d docs&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-3&quot; title=&quot;3&quot;&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;projecturl: &lt;/span&gt;&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;PROJECT_URL&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/_config.yml&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-4&quot; title=&quot;4&quot;&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;basesite: http://www.unwiredcouch.com&amp;quot;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/_config.yml&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-5&quot; title=&quot;5&quot;&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;markdown: redcarpet&amp;quot;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/_config.yml&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-6&quot; title=&quot;6&quot;&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;---&amp;quot;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; docs/index.md&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-7&quot; title=&quot;7&quot;&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;layout: project&amp;quot;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/index.md&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-8&quot; title=&quot;8&quot;&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;title: &lt;/span&gt;&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;NAME&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/index.md&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-9&quot; title=&quot;9&quot;&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;---&amp;quot;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/index.md&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-10&quot; title=&quot;10&quot;&gt;&lt;span class=&quot;fu&quot;&gt;cat&lt;/span&gt; README.md &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; docs/index.md&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-11&quot; title=&quot;11&quot;&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-12&quot; title=&quot;12&quot;&gt;&lt;span class=&quot;co&quot;&gt;# deploy to github&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-13&quot; title=&quot;13&quot;&gt;&lt;span class=&quot;bu&quot;&gt;cd&lt;/span&gt; docs&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-14&quot; title=&quot;14&quot;&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; init&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-15&quot; title=&quot;15&quot;&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; remote add upstream &lt;span class=&quot;st&quot;&gt;&amp;quot;https://&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;${GH_TOKEN}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;@github.com/mrtazz/&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;NAME&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;.git&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-16&quot; title=&quot;16&quot;&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; submodule add https://github.com/mrtazz/jekyll-layouts.git ./_layouts&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-17&quot; title=&quot;17&quot;&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; submodule update --init&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-18&quot; title=&quot;18&quot;&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; fetch upstream &lt;span class=&quot;kw&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; reset upstream/gh-pages&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-19&quot; title=&quot;19&quot;&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; config user.name &lt;span class=&quot;st&quot;&gt;&amp;#39;Daniel Schauenberg&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-20&quot; title=&quot;20&quot;&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; config user.email d@unwiredcouch.com&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-21&quot; title=&quot;21&quot;&gt;&lt;span class=&quot;fu&quot;&gt;touch&lt;/span&gt; . &lt;span class=&quot;kw&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; add -A .&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-22&quot; title=&quot;22&quot;&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; commit -m &lt;span class=&quot;st&quot;&gt;&amp;quot;rebuild pages at &lt;/span&gt;&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;VERSION&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class=&quot;sourceLine&quot; id=&quot;cb2-23&quot; title=&quot;23&quot;&gt;&lt;span class=&quot;fu&quot;&gt;git&lt;/span&gt; push -q upstream HEAD:gh-pages&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you run this from Travis CI with an encrypted GH_TOKEN environment variable, make sure to suppress command echo-ing for the &lt;code&gt;git remote add&lt;/code&gt; command as it will otherwise write your token to the log in plain text.&lt;/p&gt;
&lt;p&gt;And even if you just start with publishing your README, you have a nice website in place already to build upon. Maybe add doxygen or other reference generation to it. Add a better getting started guide. Maybe someone else contributes their notes. It&#39;s more likely the easier it is to do. And it makes documentation contributions look more like the first class contribution they are. And less like a nice side addition. Which is something almost every project can benefit from.&lt;/p&gt;
&lt;h3 id=&quot;build-and-automation&quot;&gt;Build and Automation&lt;/h3&gt;
&lt;p&gt;With all those wonderful things in place and hooked up, you also want to optimize for the common part of contributing. The local feedback loop. So while it is awesome to have all those services hooked up, it should also be obvious how to run and test them while working on something. This is where build automation via a tool like &lt;code&gt;make&lt;/code&gt; comes into play. If you don&#39;t have to look at your Travis config how to run tests but instead can just run &lt;code&gt;make test&lt;/code&gt; or &lt;code&gt;make coverage&lt;/code&gt; to get coverage information or even &lt;code&gt;make packages&lt;/code&gt; to have debs and rpms build locally it&#39;s a lot more fun to contribute. And it&#39;s not that much more work. When you hook up those things anyways, you can then just run the make commands from your CI system as well. Which also makes it a lot easier to debug if it goes wrong.&lt;/p&gt;
&lt;h3 id=&quot;show-it-off&quot;&gt;Show it off&lt;/h3&gt;
&lt;p&gt;And finally please let everyone know that you have all those things in place for your project. Most CI systems and other services now support an HTML embedded badge that shows the build status, code coverage percentage or static analysis results in a little image. It is green when things are ok and red or yellow otherwise. Which lets everyone know the current status of your project immediately when loading the README on GitHub or the website of your project. For everything else there is &lt;a href=&quot;http://shields.io/&quot;&gt;shields.io&lt;/a&gt; which lets you create custom badges via a simple URL structure so you can have the license you use, the location of the packages and other things that are not red/green right up there.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/coding-pride/yagd_badges.png&quot; alt=&quot;yagd badges&quot; /&gt; &lt;img src=&quot;/images/coding-pride/pocketcleaner_badges.png&quot; alt=&quot;pocketcleaner badges&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;do-i-really-have-to-do-all-of-this&quot;&gt;Do I really have to do all of this?&lt;/h3&gt;
&lt;p&gt;I&#39;ve given a lot of examples for things you can or should do to make your project nicer to use. And there are a myriad more, Heroku deploy buttons, npm dependency checkers, slack links, etc. I&#39;ve mostly focused on a very specific set of things I use regularly for my projects. And it&#39;s also very much focused on open source repositories or at least repositories hosted on Github.&lt;/p&gt;
&lt;p&gt;I&#39;m very aware that not all of these things always apply to or make sense for a project. Some languages don&#39;t have the support of your coverage platform. You want to use another CI service. Your code is hosted in your corporate network and you don&#39;t think you have the time to set all of these things up.&lt;/p&gt;
&lt;p&gt;The real answer here is to always try to strive for this. A lot of setups can literally be copy and pasted once you&#39;ve done it for one project. And again while all the services mentioned are public ones, there are a lot of integrations you can emulate in house with your existing CI and deployment system and some HTML. If you only do a third of the things I described here your project will already be in much better shape. And people will be more happy to (have to) use your code. Which in my mind is something to be proud of.&lt;/p&gt;
</content>
</entry>
<entry> 
          <title>My 2015 Reading List</title> 
          <link href="https://unwiredcouch.com/2015/12/31/reading-list.html" /> 
              <id>https://unwiredcouch.com/2015/12/31/reading-list.html</id> 
          <updated>2015-12-31T00:00:00+01:00</updated> 
          <content type="html">&lt;p&gt;This year has been really good for reading for me. Starting off from &lt;a href=&quot;https://unwiredcouch.com/2014/12/31/reading-list.html&quot;&gt;last year&#39;s list&lt;/a&gt; and the 5-ish books I read in 2014, I made it to 16 this year. Some of them were very short but nonetheless an improvement. One of my goals for 2015 was to read more and I definitely managed to accomplish that. My goal for 2016 is to read more than 20 books. If you&#39;re interested in keeping up to date over the year, I usually post my progress and reviews on &lt;a href=&quot;https://www.goodreads.com/mrtazz&quot;&gt;Goodreads&lt;/a&gt; as well.&lt;/p&gt;
&lt;p&gt;So without further ado, here&#39;s my reading list for 2015:&lt;/p&gt;
&lt;h3 id=&quot;the-whole-womanwhole_woman-by-germaine-greer&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Whole-Woman-Germaine-Greer-ebook/dp/B0026LTNDG&quot;&gt;The Whole Woman&lt;/a&gt; by Germaine Greer&lt;/h3&gt;
&lt;p&gt;As mentioned &lt;a href=&quot;https://unwiredcouch.com/2014/12/31/reading-list.html&quot;&gt;last year&lt;/a&gt; I started reading this book in 2014 and finished it early 2015. I overall liked it and it was really good in giving me different ways to think about feminism and how the whole system works together to enable sexism and exploitation. It&#39;s also a good resource to understand better how closely related feminism and capitalism really are. However it comes with a really serious trigger warning. Germaine Greer is known to have very transphobic/cissexist views and this book is no exception. It is restricted to one chapter but those opinions - which I don&#39;t share at all - are definitely in there. So if this is a trigger for you, it&#39;s probably better to skip this book.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The pattern of devaluing women&#39;s contribution is as old as human civilization&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;feminism-is-for-everybodyhooks_feminism-by-bell-hooks&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Feminism-Everybody-Passionate-bell-hooks-ebook/dp/B00OCKEF8W&quot;&gt;Feminism is for Everybody&lt;/a&gt; by Bell Hooks&lt;/h3&gt;
&lt;p&gt;I&#39;ve known about this book for a while now, but up until early 2015 it was only available in print. And since I don&#39;t really like owning physical books and read exclusively on my Kindle and iPhone I hadn&#39;t bought it yet. So when I found out there is a Kindle version now, I immediately bought it. As expected, the book is really good and gives a good primer on feminism and the historical context from the author&#39;s perspective. It reads less extreme to me as Greer which is very much in line with Hooks&#39; other writing. Definitely highly recommended for learning more about feminism.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Feminism is a movement to end sexism, sexist exploitation, and oppression.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;designing-for-performancedfp-by-lara-hogan&quot;&gt;&lt;a href=&quot;http://designingforperformance.com/&quot;&gt;Designing for Performance&lt;/a&gt; by Lara Hogan&lt;/h3&gt;
&lt;p&gt;My coworker &lt;a href=&quot;https://twitter.com/lara_hogan&quot;&gt;Lara&lt;/a&gt; wrote this book last year and it was a lot of fun watching her process and how she knocked out that book. Since then it was on my list of books to read. Especially since I tend to shy away from frontend things in my day job and want to get better at not doing that. The book is a wonderful introduction into web performance especially from a design view. It gives very solid technical details on a lot of things like browser rendering and image formats that I only had very superficial knowledge of before. I really enjoyed it and the book lead me to &lt;a href=&quot;https://unwiredcouch.com/2015/07/24/frontend-performance.html&quot;&gt;reduce the page weight of this blog by 92%&lt;/a&gt; which was tons of fun to do as well.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The largest hurdle to creating and maintaining stellar site performance is the culture of your organization.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;manage-your-day-to-dayday_to_day-by-jocelyn-glei&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Manage-Your-Day---Day-Creative-ebook/dp/B00B77UE4W&quot;&gt;Manage your Day-to-Day&lt;/a&gt; by Jocelyn Glei&lt;/h3&gt;
&lt;p&gt;This book sparked my interest while I was looking for improving my daily routines. I was often just starting the day as it happened often leaving me feel disorganized, unproductive, and imbalanced. Reading &quot;Manage your Day-to-Day&quot; gave me a lot of ideas of what things to try and add to my daily routine. And also to try and even have a daily routine. Something I picked up again through this book was journaling and while it has been on and off for the last couple of months I really enjoy it. The book was not mind blowing for me but I enjoyed reading it and definitely would recommend it if you are looking for inspiration for your daily routine.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It takes willpower to switch off the world, even for an hour.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;leading-snowflakessnowflakes-by-oren-ellenbogen&quot;&gt;&lt;a href=&quot;http://leadingsnowflakes.com/&quot;&gt;Leading Snowflakes&lt;/a&gt; by Oren Ellenbogen&lt;/h3&gt;
&lt;p&gt;I&#39;ve heard about this book ever since it was released and a lot of people I know speak very highly of it. And they weren&#39;t wrong, I basically devoured the book in a weekend. It&#39;s very well written and has a ton of actionable advice for engineers becoming managers. But I would argue that this description really limits the value of the book. I have no intention to become a manager at the moment however the book was really interesting and helpful for me. I think it&#39;s a great read for anyone looking to grow more into a leadership position.&lt;/p&gt;
&lt;h3 id=&quot;the-highly-sensitive-personhighly_sensitive-by-elaine-n-aron&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Highly-Sensitive-Person-Elaine-Aron-ebook/dp/B00GT1YES8&quot;&gt;The Highly Sensitive Person&lt;/a&gt; by Elaine N. Aron&lt;/h3&gt;
&lt;p&gt;I had no idea about the concept of highly sensitive people until I read &lt;a href=&quot;http://m.huffpost.com/us/entry/4810794&quot;&gt;this article&lt;/a&gt;. It has a pretty click-baity headline but it really hit home for me. So I decided to learn more about it and this book was the most prominent resource to pop up in my search. It&#39;s a really good book with a lot of great psychological insights and explicit case studies. At times the way high sensitivity was described was a bit too feel-good for my taste. At other times I would almost throw my kindle across the room as the author managed to really sneak up on and hijack my sensitivity. The book focuses a lot on what usually goes wrong during childhood for highly sensitive people and makes it a point to relive memories and traumas through the lense of high sensitivity. This is a practice I really enjoyed although it felt a bit much to me at times as I consider my childhood to have been a happy one. On the other hand I started to do this practice with every day situations at work to help me understand why I feel what I feel in different situations. I identify myself as a highly sensitive person and the book was an extremely good read to help me understand better what this could mean for me and my days.&lt;/p&gt;
&lt;h3 id=&quot;recoding-genderrecoding_gender-by-janet-abbate&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Recoding-Gender-Changing-Participation-Computing-ebook/dp/B009Z3U46S&quot;&gt;Recoding Gender&lt;/a&gt; by Janet Abbate&lt;/h3&gt;
&lt;p&gt;I have a very complex relationship with the profession of &quot;software engineering&quot; and how it&#39;s often defined in a non-inclusive way and as the profession of the golden children of society. Part of that is that I had always known a bit about the origins of programming and that a majority of programmers used to be women. But I didn&#39;t know a lot about it which is why I was excited to read this book. And it was great! The book walks you through the beginnings before and during WWII and what programming meant back then. It discusses how the emerging industry in this field changed job prospects and economic chances for women. But it also discusses how the image of a programmer changed as more and more men participated. It&#39;s full of historical facts and documents and a more than wonderful read. It sparked a lot of thoughts for me and changed the way I think about my profession even more.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;the traits that managers found most problematic in programmers were those stereotypically associated with men&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;you-had-me-at-hello-worldhello_world-by-dona-sarkar&quot;&gt;&lt;a href=&quot;http://www.amazon.com/You-Had-Hello-World-Mentoring-ebook/dp/B0147SC2WO&quot;&gt;You had me at &#39;Hello World&#39;&lt;/a&gt; by Dona Sarkar&lt;/h3&gt;
&lt;p&gt;I found this book through &lt;a href=&quot;https://twitter.com/skamille&quot;&gt;Camille&lt;/a&gt; tweeting about the fact that she was also interviewed for it. &quot;You had me at &#39;Hellow World&#39;&quot; is a collection of interviews with industry leaders from successful companies about the many aspects of leadership and mentoring. It&#39;s a pretty lightweight read and a great resource to get some insight how successful people talk about those topics. It does a great job in conveying how important skills outside of writing code are. And it provides good examples of how to use those for your advantage.&lt;/p&gt;
&lt;h3 id=&quot;nonviolent-communicationnonviolent_comm-by-marshall-b-rosenberg&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Nonviolent-Communication-Language-Life-Changing-Relationships-ebook/dp/B014OISVU4&quot;&gt;Nonviolent Communication&lt;/a&gt; by Marshall B. Rosenberg&lt;/h3&gt;
&lt;p&gt;This has been recommended by many people I work with as a wonderful resource about positive human communication. And as - especially in a growing engineering org - communication is one of the most important skills to try to master, I decided to finally read this one. It&#39;s a very interesting book with an approach to communication that is rarely taught especially not to men. It focuses on a collaborative rather than a competitive style of communication and the goal to reach agreements over winning arguments. The examples in the book are often pretty extreme coming from the author&#39;s work as a diplomat. And even though those are great to demonstrate how this way of communicating can work in the most extreme cases, it also shifts its focus a lot on explicit diplomatic style discussions. There are more examples that are more directed towards every day situations and even though the author is very explicit about this being useful in regular work meetings as well, I had a very hard time understanding how to practically apply those lessons in a meeting for example. That being said however it made me think a lot more about the way I communicate and what I&#39;m saying versus what I want to say. I have also applied that way of communicating successfully at least once since reading the book. And I look forward to try it out more.&lt;/p&gt;
&lt;h3 id=&quot;the-retrospective-handbookretrospective-by-patrick-kua&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Retrospective-Handbook-guide-agile-teams-ebook/dp/B00916BRVU&quot;&gt;The Retrospective Handbook&lt;/a&gt; by Patrick Kua&lt;/h3&gt;
&lt;p&gt;At work we have a group of people which I&#39;m part of that work on making sure we have good frameworks in place for blameless postmortems and organizational learning as a whole. Part of that is moving past only investigating failure (via postmortems) and also look into investigating successes (via retrospectives). So in a similar way to how I&#39;ve spent time understanding the unhelpful concept of human error, I wanted to learn more about the theoretical concepts of successful retrospectives. Unfortunately this was completely the wrong book for this. It is a great and very practical read for retrospectives in the agile sense and how to run successful meetings in general. However I wasn&#39;t looking for that so I constantly kept thinking when we are going to dive into the meaty, theoretical stuff. This is in no way the authors fault and I would highly recommend the book as inspiration for improving your meetings. But for the theoretical underpinnings of retrospectives as an organizational learning tool I&#39;m still on the lookout. Let me know if you have recommendations :).&lt;/p&gt;
&lt;h3 id=&quot;cybersexism-sex-gender-and-power-on-the-internetcybersexism-by-laurie-penny&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Cybersexism-Sex-Gender-Power-Internet-ebook/dp/B00EO24J3O&quot;&gt;Cybersexism: Sex, Gender and Power on the Internet&lt;/a&gt; by Laurie Penny&lt;/h3&gt;
&lt;p&gt;This short book by Laurie Penny is a very good read about sexism in the age of social networks and the omnipresent Internet. It does a great job at talking about how a lot of familiar concepts of &quot;offline sexism&quot; are reinvented online and no news to women. It&#39;s short and insightful enough to recommend reading it without hesitation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Perhaps one reason that women writers and technologists have, so far, the calmest and most comprehensive understanding of what surveillance technology really does to the human condition is that women grow up being watched.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;the-boy-kingsboy_kings-by-katherine-losse&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Boy-Kings-Journey-Social-Network-ebook/dp/B007MAXH38&quot;&gt;The Boy Kings&lt;/a&gt; by Katherine Losse&lt;/h3&gt;
&lt;p&gt;The biography of Kate Losse about her time at (earl stage) Facebook is in my mind a must read for any software engineer and especially if you&#39;re a man. It gives an extremely good insight view into what happens when young men are suddenly in charge of a ton of money. But more importantly it talks very bluntly about how engineers are treated differently from most other employees for our supposed gift to turn any idea into gold with code.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Technology carries with it all the biases of the people who make it, so simply making the world more technical was not going to save us.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;the-art-of-mindfulnessmindfulness-by-thích-nhất-hạnh&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Art-Mindfulness-HarperOne-Select-Selects-ebook/dp/B005HG4H24&quot;&gt;The Art of Mindfulness&lt;/a&gt; by Thích Nhất Hạnh&lt;/h3&gt;
&lt;p&gt;This is another super short read and the de-facto introductory book to mindfulness meditation. There&#39;s not a lot to say here. It&#39;s good, give it a read as it&#39;s short enough to not matter if you end up not liking it. I started meditating regularly after reading it and it has been a great experience.&lt;/p&gt;
&lt;h3 id=&quot;men-explain-things-to-memen_explain-by-rebecca-solnit&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Men-Explain-Things-Rebecca-Solnit-ebook/dp/B00IWGQ8PU&quot;&gt;Men Explain Things to Me&lt;/a&gt; by Rebecca Solnit&lt;/h3&gt;
&lt;p&gt;This collection of essays titled for the aggressive tendency of men to always have to explain things to women while assuming they have no idea what they are talking about. The first essay brings this to a point by telling a story of a party where a man mansplains to the author the book she herself wrote. Without having actually read it. The book than continues with more essays that talk about a lot more darker things like discussing domestic violence. The over arching theme is that the credibility of and respect towards women is continuously diminished to maintain the status quo and its power imbalance. Some of the essays towards the end of the book are not easy to read but it&#39;s more than worth it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Credibility is a basic survival tool.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;dont-make-me-thinkdont_make_think-by-steve-krug&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Dont-Make-Think-Revisited-Usability-ebook/dp/B00HJUBRPG&quot;&gt;Don&#39;t Make Me Think&lt;/a&gt; by Steve Krug&lt;/h3&gt;
&lt;p&gt;I&#39;m one of those engineers who used to happily claim to not have any frontend skills and just not be good at design. I came to loathe this thinking over the years and decided that if I can&#39;t do something I want to learn at least the basics. This is one of the reasons why I read &quot;Designing for Performance&quot; as mentioned above. Thankfully I also work with a ton of talented designers and one of them is &lt;a href=&quot;https://twitter.com/harllee&quot;&gt;Jessica Harllee&lt;/a&gt;. I talked to her about suggestions to get started with learning about design. And she said I should read &quot;Don&#39;t make me think&quot;. And she wasn&#39;t wrong. The book is a wonderful introduction into usability and design. The beauty of it is that while reading it, all of the things mentioned are total no-brainers. But you have to remember it while designing things. The other interesting thing for me was that while all of the examples in the book are web based (with some brief stints into mobile) I could totally think of CLI apps I&#39;ve written in the past that totally do the wrong thing design-wise. Definitely a recommended read.&lt;/p&gt;
&lt;h3 id=&quot;the-internet-of-garbageinternet_garbage-by-sarah-jeong&quot;&gt;&lt;a href=&quot;http://www.amazon.com/Internet-Garbage-Sarah-Jeong-ebook/dp/B011JAV030&quot;&gt;The Internet of Garbage&lt;/a&gt; by Sarah Jeong&lt;/h3&gt;
&lt;p&gt;In this book Sarah Jeong - a journalist trained as a lawyer at Harvard Law School - talks about the problem of online harassment. It&#39;s another short but really good one. I&#39;ve learned a ton about copyright law and the limitations of current legislation when it comes to online harassment. But also things that do work and what things could be attempted. It&#39;s a very sobering look at the current state of social networks, online harassment and tooling and legislation to help fight it. Definitely worth a read if you spend any time on the internet.&lt;/p&gt;
</content>
</entry>
</feed>
